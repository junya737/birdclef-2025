{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "from module import config_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.PROCESSED_DIR = \"\"\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # 全modelの保存先\n",
    "            self.model_path = self.models_dir # 各モデルの保存先．学習時に動的に変更．\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_DURATION = 5 # データセット作成時のウィンドウサイズ\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 16\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 16  # 並列処理のスレッド数 16くらいでいい\n",
    "        self.N_JOBS_DURATION = 47\n",
    "        \n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeしないならTrue\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "        self.num_rare_samples = 10 # これ以下のサンプル数のspeciesはrare speciesとして扱う\n",
    "        self.is_crop_aug = False\n",
    "        self.num_prune_samples = 1000 # サンプル数をこれ以下にprune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = DatasetConfig(kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: OFF\n",
      "Max samples to process: ALL\n",
      "Loading taxonomy data...\n",
      "Loading training metadata...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{config.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{config.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 unique species\n",
      "Total samples to process: 28564 out of 28564 available\n",
      "Samples by class:\n",
      "class\n",
      "Aves        27648\n",
      "Amphibia      583\n",
      "Mammalia      178\n",
      "Insecta       155\n",
      "Name: count, dtype: int64\n",
      "✅ Added 'duration_sec'. Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "label_list = sorted(train_df['primary_label'].unique())\n",
    "label_id_list = list(range(len(label_list)))\n",
    "label2id = dict(zip(label_list, label_id_list))\n",
    "id2label = dict(zip(label_id_list, label_list))\n",
    "\n",
    "print(f'Found {len(label_list)} unique species')\n",
    "working_df = train_df.copy()\n",
    "working_df['target'] = working_df.primary_label.map(label2id)\n",
    "working_df['filepath'] = config.RAW_DIR + '/train_audio/' + working_df.filename\n",
    "working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "working_df[\"crop_strategy\"] = \"center\"\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')\n",
    "print(f'Samples by class:')\n",
    "print(working_df['class'].value_counts())\n",
    "\n",
    "# 音源の長さをロードして追加．\n",
    "duration_df = pd.read_csv(\"../data/processed/train_duration.csv\")\n",
    "working_df = working_df.merge(duration_df, on=\"filename\", how=\"left\")\n",
    "\n",
    "missing = working_df[\"duration_sec\"].isna().sum()\n",
    "print(f\"✅ Added 'duration_sec'. Missing values: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 全音源の長さを計算\n",
    "# def get_duration(filepath, sr):\n",
    "#     try:\n",
    "#         audio, _ = librosa.load(filepath, sr=sr)\n",
    "#         return len(audio) / sr\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Could not load {filepath}: {e}\")\n",
    "#         return np.nan\n",
    "\n",
    "# print(\"🔄 Calculating durations with parallel processing...\")\n",
    "\n",
    "# # tqdm 対応\n",
    "# filepaths = working_df['filepath'].tolist()\n",
    "# durations = Parallel(n_jobs=config.N_JOBS_DURATION)(\n",
    "#     delayed(get_duration)(fp, config.FS) for fp in tqdm(filepaths)\n",
    "# )\n",
    "\n",
    "# working_df['duration_sec'] = durations\n",
    "# print(\"✅ Added 'duration_sec' column to working_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"valid_start_sec\"] = 0\n",
    "working_df[\"valid_end_sec\"] = working_df[\"duration_sec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手動で人の声除去\n",
    "\n",
    "# 4. 特定のファイルの valid_start_sec を変更\n",
    "# 特定のファイル（最初にスペイン語が含まれる）\n",
    "spanish_intro_filenames = [\n",
    "    '50186/CSA28885.ogg',\n",
    "    '52884/CSA14875.ogg'\n",
    "]\n",
    "# valid_start_sec を 4.0 に変更\n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(spanish_intro_filenames),\n",
    "    'valid_start_sec'\n",
    "] = 4.0\n",
    "\n",
    "\n",
    "# 途中で人の声のみになるので除去\n",
    "voice_only_ranges = {\n",
    "    '476537/CSA35459.ogg': 134,  # 2分14秒 = 134秒\n",
    "    '476537/CSA35461.ogg': 259,  # 4分19秒 = 259秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Eliana Barona- Cortés　の音源．話している部分．いらない部分\n",
    "# 24292/CSA34649.ogg 2min8以降\n",
    "# 24292/CSA34651.ogg 1min33以降\n",
    "# 50186/CSA34622.ogg 21s以降\n",
    "# 50186/CSA34678.ogg 43s以降\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA34649.ogg': 128,   # 2分8秒 = 128秒\n",
    "    '24292/CSA34651.ogg': 93,    # 1分33秒 = 93秒\n",
    "    '50186/CSA34622.ogg': 21,    # 21秒\n",
    "    '50186/CSA34678.ogg': 43,    # 43秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "# Alexandra Butrago-Cardona の音源チェック\n",
    "# 話している部分．いらない部分\n",
    "# 24292/CSA35021.ogg 36s以降\n",
    "# 52884/CSA34947.ogg 13s以降\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA35021.ogg': 36,    # 36秒\n",
    "    '52884/CSA34947.ogg': 13,     # 13秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Fabio A. Sarria-S の音声は 0〜7秒 だけ使用可能に設定．後半はただの説明なので\n",
    "fabio_filenames = train_df.loc[\n",
    "    train_df['author'] == \"Fabio A. Sarria-S\", 'filename'\n",
    "].tolist()\n",
    "# \n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(fabio_filenames), 'valid_end_sec'\n",
    "] = 7.0\n",
    "\n",
    "#  Fabioの解説で，必ずしも7secではないもの\n",
    "fabio_override = {\n",
    "    \"48124/CSA36346.ogg\": 24.0,\n",
    "    \"52884/CSA36344.ogg\": 55.0,\n",
    "    \"52884/CSA36342.ogg\": 14.0,  # ← 追加分\n",
    "}\n",
    "\n",
    "for fname, end_sec in fabio_override.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# crop戦略は基本center\n",
    "working_df[\"crop_strategy\"] = \"center\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_zoneを準備（すでに\"checked\"のみ、重複除去済み）\n",
    "safe_zone = pd.read_csv(\"../data/processed/safe_zones/safe_zone_0428.csv\")\n",
    "safe_zone = safe_zone[safe_zone[\"check\"] == \"checked\"]\n",
    "safe_zone = safe_zone.drop_duplicates(subset=[\"filename\"])\n",
    "\n",
    "# start, endをfloatに変換\n",
    "safe_zone[\"start\"] = pd.to_numeric(safe_zone[\"start\"], errors=\"coerce\")\n",
    "safe_zone[\"end\"] = pd.to_numeric(safe_zone[\"end\"], errors=\"coerce\")\n",
    "\n",
    "# safe_zoneから必要なカラムだけ持ってくる\n",
    "safe_zone_update = safe_zone[[\"filename\", \"start\", \"end\"]]\n",
    "\n",
    "# working_dfも用意されている想定\n",
    "\n",
    "# working_dfにsafe_zoneのstart, endをマージする\n",
    "working_df = working_df.merge(safe_zone_update, on=\"filename\", how=\"left\")\n",
    "\n",
    "# start, endが存在するものについて、valid_start_sec, valid_end_secを書き換え\n",
    "working_df[\"valid_start_sec\"] = working_df[\"start\"].combine_first(working_df[\"valid_start_sec\"])\n",
    "working_df[\"valid_end_sec\"] = working_df[\"end\"].combine_first(working_df[\"valid_end_sec\"])\n",
    "\n",
    "# 使い終わったstart, endカラムを消す（必要なら）\n",
    "working_df = working_df.drop(columns=[\"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Marked 0 samples as invalid (over 1000 per label)\n"
     ]
    }
   ],
   "source": [
    "working_df[\"is_valid_audio\"] = True\n",
    "\n",
    "# ラベルごとに処理\n",
    "for label, group in working_df.groupby('primary_label'):\n",
    "    if len(group) > config.num_prune_samples:\n",
    "        # ランダムに500件を残す（残りをis_valid_audio=Falseに）\n",
    "        keep_indices = group.sample(n=config.num_prune_samples, random_state=config.seed).index\n",
    "        drop_indices = group.index.difference(keep_indices)\n",
    "        working_df.loc[drop_indices, 'is_valid_audio'] = False\n",
    "        print(label)\n",
    "\n",
    "print(f\"✅ Marked {(~working_df['is_valid_audio']).sum()} samples as invalid (over {config.num_prune_samples} per label)\")\n",
    "\n",
    "\n",
    "# # # === 2. 除去対象ファイルを False に上書き ===\n",
    "# fabio_remove_filenames = [\n",
    "#     '1139490/CSA36385.ogg',\n",
    "#     '1462737/CSA36369.ogg',\n",
    "#     '1462737/CSA36380.ogg',\n",
    "#     '1462737/CSA36381.ogg',\n",
    "#     '1462737/CSA36386.ogg',\n",
    "#     '1462737/CSA36391.ogg',\n",
    "#     '1462737/CSA36395.ogg',\n",
    "#     '963335/CSA36374.ogg',\n",
    "#     '963335/CSA36375.ogg',\n",
    "# ]\n",
    "# working_df.loc[working_df[\"filename\"].isin(fabio_remove_filenames), \"is_valid_audio\"] = False\n",
    "\n",
    "# ノイズ除去するファイルを指定\n",
    "working_df[\"apply_denoise\"] = False\n",
    "\n",
    "# fabio_denoise_filenames = [\n",
    "#     '1462711/CSA36371.ogg',\n",
    "#     '1462711/CSA36379.ogg',\n",
    "#     '963335/CSA36372.ogg',\n",
    "#     '963335/CSA36377.ogg',\n",
    "# ]\n",
    "\n",
    "# working_df.loc[working_df[\"filename\"].isin(fabio_denoise_filenames), \"apply_denoise\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of augmentations: 0\n"
     ]
    }
   ],
   "source": [
    "# augmentationのための処理．各音源でどれくらい増やすのかを事前に決定\n",
    "\n",
    "# 初期化\n",
    "working_df['n_augment'] = 0\n",
    "working_df['multi_crop'] = False\n",
    "\n",
    "target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "# valid_end_sec が None なら duration_sec に補完\n",
    "working_df['valid_end_sec'] = working_df.apply(\n",
    "    lambda row: row['duration_sec'] if pd.isna(row['valid_end_sec']) else row['valid_end_sec'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# valid_start_sec が None なら 0 に補完（念のため）\n",
    "working_df['valid_start_sec'] = working_df['valid_start_sec'].fillna(0)\n",
    "\n",
    "# rareなラベルを抽出\n",
    "label_counts = working_df['primary_label'].value_counts().rename_axis(\"label\").reset_index(name=\"sample_count\")\n",
    "rare_labels = label_counts[label_counts['sample_count'] < config.num_rare_samples]['label'].tolist()\n",
    "\n",
    "# ✅ rare種ごとに crop 数を割り当てる\n",
    "for rare_label in rare_labels:\n",
    "    base_rows = working_df[working_df['primary_label'] == rare_label]\n",
    "    n_exist = len(base_rows)\n",
    "    n_needed = config.num_rare_samples - n_exist\n",
    "    n_aug_per_sample = math.ceil(n_needed / n_exist)\n",
    "\n",
    "    for idx, row in base_rows.iterrows():\n",
    "        usable_duration_sec = row['valid_end_sec'] - row['valid_start_sec']\n",
    "        usable_samples = int(usable_duration_sec * config.FS)\n",
    "\n",
    "        # 少なくとも2倍にする\n",
    "        max_possible = usable_samples // target_samples\n",
    "        n_actual = min(n_aug_per_sample, max_possible)\n",
    "\n",
    "        if n_actual > 0:\n",
    "            working_df.at[idx, 'multi_crop'] = True\n",
    "            working_df.at[idx, 'n_augment'] = n_actual\n",
    "            \n",
    "            \n",
    "if not config.is_crop_aug:\n",
    "    working_df['n_augment'] = 0\n",
    "    working_df['multi_crop'] = False\n",
    "\n",
    "# num_augmented\n",
    "print(f\"Total number of augmentations: {working_df['n_augment'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_strategyに基づいて音声データを切り出す\n",
    "# 現状centerしか使ってないのであまり意味がないコード．\n",
    "def crop_audio(audio_data: np.ndarray, target_samples: int, strategy='center'):\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    if total_samples < target_samples:\n",
    "        n_copy = math.ceil(target_samples / total_samples)\n",
    "        audio_data = np.concatenate([audio_data] * n_copy)\n",
    "        total_samples = len(audio_data)\n",
    "\n",
    "    if strategy == 'head':\n",
    "        # 1秒遅らせて開始（ただし収まらない場合は0から）\n",
    "        buffer = int(1.0 * config.FS)\n",
    "        start_idx = min(buffer, total_samples - target_samples)\n",
    "    elif strategy == 'tail':\n",
    "        start_idx = total_samples - target_samples\n",
    "    elif strategy == 'center':\n",
    "        start_idx = total_samples // 2 - target_samples // 2\n",
    "    elif strategy == 'random':\n",
    "        max_start = total_samples - target_samples\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "    elif isinstance(strategy, (float, int)):\n",
    "        start_idx = int(strategy * config.FS)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "    end_idx = start_idx + target_samples\n",
    "    return audio_data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# audioをmelに変換\n",
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音源をmelに変える処理．並列化に対応\n",
    "def process_row(row):\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        mel_list = []\n",
    "        name_list = []\n",
    "\n",
    "        # === 有効範囲を秒 → サンプルに変換 ===\n",
    "        valid_start_sec = row.get(\"valid_start_sec\", 0)\n",
    "        valid_end_sec = row.get(\"valid_end_sec\", None)\n",
    "        duration_sec = len(audio_data) / config.FS\n",
    "\n",
    "        if pd.isna(valid_end_sec) or valid_end_sec is None:\n",
    "            valid_end_sec = duration_sec\n",
    "\n",
    "        valid_start_sample = int(valid_start_sec * config.FS)\n",
    "        valid_end_sample = int(valid_end_sec * config.FS)\n",
    "\n",
    "        usable_audio = audio_data[valid_start_sample:valid_end_sample]\n",
    "        total_usable_samples = len(usable_audio)\n",
    "\n",
    "        # === オリジナル clip ===\n",
    "        strategy = row.crop_strategy\n",
    "        try:\n",
    "            strategy = float(strategy)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        clip = crop_audio(usable_audio, target_samples, strategy=\"center\")  # strategyはcenter固定 or 任意でも可\n",
    "        if len(clip) < target_samples:\n",
    "            clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "        mel = audio2melspec(clip)\n",
    "        if mel.shape != config.TARGET_SHAPE:\n",
    "            mel = cv2.resize(mel, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        mel_list.append(mel.astype(np.float32))\n",
    "        name_list.append(row.samplename)\n",
    "\n",
    "        # === n_augment に応じて crop ===\n",
    "        n_aug = int(row.get(\"n_augment\", 0))\n",
    "        if n_aug <= 0:\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "\n",
    "        interval = max((total_usable_samples - target_samples) // (n_aug + 1), 1)\n",
    "\n",
    "        for i in range(n_aug):\n",
    "            start_idx = min(i * interval, total_usable_samples - target_samples)\n",
    "            clip = usable_audio[start_idx: start_idx + target_samples]\n",
    "            if len(clip) < target_samples:\n",
    "                clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "            mel_crop = audio2melspec(clip)\n",
    "            if mel_crop.shape != config.TARGET_SHAPE:\n",
    "                mel_crop = cv2.resize(mel_crop, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "            mel_list.append(mel_crop.astype(np.float32))\n",
    "            name_list.append(f\"{row.samplename}_crop{i}\")\n",
    "\n",
    "        return list(zip(name_list, mel_list)), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 3\n",
      "Errors:\n",
      "  ../data/raw//train_audio/65448/iNat273090.ogg: division by zero\n",
      "  ../data/raw//train_audio/amekes/iNat522503.ogg: division by zero\n",
      "  ../data/raw//train_audio/amekes/iNat522505.ogg: division by zero\n"
     ]
    }
   ],
   "source": [
    "# mel変換を並列化\n",
    "results = Parallel(n_jobs=config.N_JOBS)(\n",
    "    delayed(process_row)(row) for _, row in working_df.iloc[:total_samples].iterrows()\n",
    ")\n",
    "\n",
    "# 結果の整理\n",
    "all_bird_data = {}\n",
    "errors = []\n",
    "\n",
    "for result, err in results:\n",
    "    if result is not None:\n",
    "        for name, mel in result:\n",
    "            all_bird_data[name] = mel\n",
    "    if err is not None:\n",
    "        errors.append(err)\n",
    "        \n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "if errors:\n",
    "    print(\"Errors:\")\n",
    "    for filepath, error in errors:\n",
    "        print(f\"  {filepath}: {error}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ working_df_augmented created with 0 augmented rows.\n"
     ]
    }
   ],
   "source": [
    "# working_dfにaugmentしたデータ情報を追加\n",
    "augmented_rows = []\n",
    "\n",
    "for _, row in working_df.iterrows():\n",
    "    n_aug = int(row.get('n_augment', 0))\n",
    "    if n_aug > 0:\n",
    "        for i in range(n_aug):\n",
    "            new_row = row.copy()\n",
    "            new_row['samplename'] = f\"{row.samplename}_crop{i}\"\n",
    "            augmented_rows.append(new_row)\n",
    "\n",
    "# DataFrameにまとめる\n",
    "augmented_rows = pd.DataFrame(augmented_rows)\n",
    "working_df_augmented = pd.concat([working_df, augmented_rows], ignore_index=True)\n",
    "print(f\"✅ working_df_augmented created with {len(augmented_rows)} augmented rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 事前にfoldを決めておく．5fold．\n",
    "\n",
    "\n",
    "# working_df_augmented['group_id'] = working_df_augmented['samplename'].map(lambda x: x.split('_crop')[0])\n",
    "\n",
    "# # fold 列を初期化\n",
    "# working_df_augmented['fold'] = -1\n",
    "\n",
    "# # ✅ stratify + group 両立！\n",
    "# sgkf = StratifiedGroupKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "# groups = working_df_augmented['group_id']\n",
    "# labels = working_df_augmented['primary_label']\n",
    "\n",
    "# for fold_id, (_, val_idx) in enumerate(sgkf.split(working_df_augmented, labels, groups=groups)):\n",
    "#     working_df_augmented.loc[val_idx, 'fold'] = fold_id\n",
    "\n",
    "# fold を固定する\n",
    "train_0419 = pd.read_csv(\"../data/processed/mel_cleaned_0419/train.csv\")\n",
    "# crop前の fold 情報を辞書化\n",
    "fold_map = train_0419.set_index(\"samplename\")[\"fold\"].to_dict()\n",
    "\n",
    "# crop後の working_df_augmented に fold をマッピング\n",
    "working_df_augmented[\"group_id\"] = working_df_augmented[\"samplename\"].map(lambda x: x.split(\"_crop\")[0])\n",
    "working_df_augmented[\"fold\"] = working_df_augmented[\"group_id\"].map(fold_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Removed 0 rows marked as invalid audio.\n",
      "✅ Final training set size: 28564\n"
     ]
    }
   ],
   "source": [
    "# === 無効な音源を除外（fold付与後） ===\n",
    "working_df_filtered = working_df_augmented[working_df_augmented[\"is_valid_audio\"]].reset_index(drop=True)\n",
    "\n",
    "print(f\"📉 Removed {len(working_df_augmented) - len(working_df_filtered)} rows marked as invalid audio.\")\n",
    "print(f\"✅ Final training set size: {len(working_df_filtered)}\")\n",
    "\n",
    "working_df_augmented = working_df_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Mel-spectrograms saved to: ../data/processed/melspec_20250428_1706/birdclef2025_melspec_5sec_256_256.npy\n",
      "📦 File size: 7142.73 MB\n",
      "📐 Example shape: (256, 256)\n",
      "📝 Config saved to: ../data/processed/melspec_20250428_1706/config.csv\n",
      "📝 Augmented training metadata saved to: ../data/processed/melspec_20250428_1706/train.csv\n",
      "📊 Total rows: 28564\n"
     ]
    }
   ],
   "source": [
    "# melとworking_dfを保存．working_dfはtrain.csvとして保存\n",
    "\n",
    "# 4mins\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JST時刻でディレクトリ作成 ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# ✅ 保存先フォルダを debug に応じて分岐\n",
    "if config.debug:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melスペクトログラムの保存 ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\n✅ Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"📦 File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"📐 Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configの保存 ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(config).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"📝 Config saved to: {config_path}\")\n",
    "\n",
    "\n",
    "# ✅ train.csv として保存\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df_augmented.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"📝 Augmented training metadata saved to: {train_csv_path}\")\n",
    "print(f\"📊 Total rows: {len(working_df_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fold一致: 28564 / 28564 (100.00%)\n",
      "🎉 Fold assignment is consistent across all records.\n"
     ]
    }
   ],
   "source": [
    "# train_0419: samplename → fold のマップを作成\n",
    "fold_map = train_0419.set_index(\"samplename\")[\"fold\"].to_dict()\n",
    "\n",
    "# working_df_augmented 側の元 clip に対するfold\n",
    "working_df_augmented[\"group_id\"] = working_df_augmented[\"samplename\"].map(lambda x: x.split(\"_crop\")[0])\n",
    "working_df_augmented[\"fold_from_train0419\"] = working_df_augmented[\"group_id\"].map(fold_map)\n",
    "\n",
    "# 比較：fold列とfold_from_train0419列が一致しているか\n",
    "match = (working_df_augmented[\"fold\"] == working_df_augmented[\"fold_from_train0419\"])\n",
    "num_total = len(working_df_augmented)\n",
    "num_match = match.sum()\n",
    "\n",
    "print(f\"✅ Fold一致: {num_match} / {num_total} ({100*num_match/num_total:.2f}%)\")\n",
    "\n",
    "# 100%一致していないときの差分を表示（デバッグ用）\n",
    "if num_match != num_total:\n",
    "    mismatches = working_df_augmented[~match][[\"samplename\", \"group_id\", \"fold\", \"fold_from_train0419\"]]\n",
    "    print(\"❌ Fold mismatch detected!\")\n",
    "    display(mismatches.head())\n",
    "else:\n",
    "    print(\"🎉 Fold assignment is consistent across all records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabioの解説　必ずしも7secではない\n",
    "# 48124/CSA36346.ogg 24sec以降\n",
    "# 52884/CSA36344.ogg 55sec以降\n",
    "# 52884/CSA36342.ogg 14sec以降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>filename</th>\n",
       "      <th>author</th>\n",
       "      <th>valid_end_sec</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>963335</td>\n",
       "      <td>963335/CSA36372.ogg</td>\n",
       "      <td>Fabio A. Sarria-S</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108.242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>963335</td>\n",
       "      <td>963335/CSA36374.ogg</td>\n",
       "      <td>Fabio A. Sarria-S</td>\n",
       "      <td>8.0</td>\n",
       "      <td>103.571344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>963335</td>\n",
       "      <td>963335/CSA36375.ogg</td>\n",
       "      <td>Fabio A. Sarria-S</td>\n",
       "      <td>8.0</td>\n",
       "      <td>106.700375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>963335</td>\n",
       "      <td>963335/CSA36377.ogg</td>\n",
       "      <td>Fabio A. Sarria-S</td>\n",
       "      <td>7.0</td>\n",
       "      <td>107.488969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>963335</td>\n",
       "      <td>963335/CSA36393.ogg</td>\n",
       "      <td>Fabio A. Sarria-S</td>\n",
       "      <td>7.0</td>\n",
       "      <td>97.343281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    primary_label             filename             author  valid_end_sec  \\\n",
       "911        963335  963335/CSA36372.ogg  Fabio A. Sarria-S            8.0   \n",
       "912        963335  963335/CSA36374.ogg  Fabio A. Sarria-S            8.0   \n",
       "913        963335  963335/CSA36375.ogg  Fabio A. Sarria-S            8.0   \n",
       "914        963335  963335/CSA36377.ogg  Fabio A. Sarria-S            7.0   \n",
       "915        963335  963335/CSA36393.ogg  Fabio A. Sarria-S            7.0   \n",
       "\n",
       "     duration_sec  \n",
       "911    108.242500  \n",
       "912    103.571344  \n",
       "913    106.700375  \n",
       "914    107.488969  \n",
       "915     97.343281  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 19\n",
    "idx_list = working_df[working_df[\"collection\"] == \"CSA\"][\"primary_label\"].unique()\n",
    "df = working_df[working_df[\"primary_label\"] == f\"{idx_list[i]}\"][[\"primary_label\", \"filename\", \"author\", \"valid_end_sec\", \"duration_sec\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSAチェック\n",
    "# 最後にスペイン語が含まれていないlabel\n",
    "# 1564122, 50186/CSA28885.ogg, 523060\n",
    "# 52884/CSA14875.ogg\n",
    "# 548639\n",
    "# 714022\n",
    "# 868458\n",
    "\n",
    "\n",
    "\n",
    "# スペイン語最初に含まれる 4secくらい\n",
    "# 50186/CSA28885.ogg\n",
    "# 52884/CSA14875.ogg\n",
    "\n",
    "\n",
    "\n",
    "# 話してる人\n",
    "# Eliana Barona- Cortés\n",
    "# Alexandra Butrago-Cardona\n",
    "# Fabio A. Sarria-S\n",
    "\n",
    "# 人の声だけの箇所\n",
    "# 24292/CSA34649.ogg 2min48移行\n",
    "# 24292/CSA34651.ogg 1min34移行\n",
    "# 476537/CSA35459.ogg 2min14移行\n",
    "# 476537/CSA35461.ogg 4min19移行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_label\n",
       "grekis     990\n",
       "compau     808\n",
       "trokin     787\n",
       "roahaw     709\n",
       "banana     610\n",
       "          ... \n",
       "64862        2\n",
       "81930        2\n",
       "41778        2\n",
       "42087        2\n",
       "1139490      2\n",
       "Name: count, Length: 206, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 棒グラフ\n",
    "\n",
    "working_df_augmented[\"primary_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_valid_ranges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 人の声がない範囲を取得\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m valid_range_df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_valid_ranges\u001b[49m(df)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m valid_range_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_end_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_start_sec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_valid_ranges' is not defined"
     ]
    }
   ],
   "source": [
    "humanvoice_df = pd.read_csv(\"../data/processed/human_voice/human_voice_0425.csv\")\n",
    "df = working_df[working_df[\"filename\"].isin(humanvoice_df[\"filename\"])]\n",
    "df = df[df[\"collection\"] != \"CSA\"]\n",
    "# 秒数が長いものには人の声が入っている可能性があるので対象とする\n",
    "df = df[df[\"duration_sec\"] > 7]\n",
    "\n",
    "# 人の声がない範囲を取得\n",
    "valid_range_df = extract_valid_ranges(df)\n",
    "df = valid_range_df.copy()\n",
    "df = df[(df[\"valid_end_sec\"] - df[\"valid_start_sec\"] <= 5)]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanvoice_df = pd.read_csv(\"../data/processed/human_voice/human_voice_0425.csv\")\n",
    "df = working_df[working_df[\"filename\"].isin(humanvoice_df[\"filename\"])]\n",
    "df = df[df[\"collection\"] != \"CSA\"]\n",
    "# 秒数が長いものには人の声が入っている可能性があるので対象とする\n",
    "df = df[df[\"duration_sec\"] > 7]\n",
    "\n",
    "# 人の声がない範囲を取得\n",
    "valid_range_df = extract_valid_ranges(df)\n",
    "df = valid_range_df.copy()\n",
    "df = df[(df[\"valid_end_sec\"] - df[\"valid_start_sec\"] >= 3) & (df[\"valid_end_sec\"] - df[\"valid_start_sec\"] <= 5)]\n",
    "print(len(df))\n",
    "utils_lib.plot_and_play_audio(\"tropar/iNat1231453.ogg\", config.train_datadir)\n",
    "\n",
    "\n",
    "# 7sでフィルター．除去した後の音声の長さが3s以上5s以下のものを評価．26分かかった．全124件\n",
    "# 書いてない音源は全durationが使えるという意味\n",
    "\n",
    "# 21211/XC882654.ogg 3.7s以降\n",
    "#  22976/iNat1192434.ogg 6s以降\n",
    "# 517119/iNat1282698.ogg 人の声．保留\n",
    "#  67252/iNat1257838.ogg 全く同じ音源あり．消す\n",
    "# amekes/iNat863228.ogg 人の声．4s以降\n",
    "# amekes/iNat863229.ogg 人の声．保留\n",
    "# banana/iNat483177.ogg 人の声．保留\n",
    "# bkmtou1/iNat1073839.ogg 人の声．保留．1.5ｓ付近にノイズあり\n",
    "# bkmtou1/iNat959239.ogg 4s以降\n",
    "# blkvul/XC324818.ogg 人の声．保留\n",
    "# cargra1/iNat969137.ogg 全部人の声．消す Valentina\n",
    "# chbant1/iNat922630.ogg 音がかすか．人の声．保留\n",
    "# colcha1/iNat583631.ogg 全く同じ音源あり．消す \n",
    "# compau/iNat346502.ogg 人の声．音楽．保留\n",
    "# crcwoo1/XC9296.ogg 2.5s以前．\n",
    "# greibi1/iNat624338.ogg 人の声．保留\n",
    "# grekis/iNat388305.ogg 8s以降\n",
    "#  grekis/iNat979187.ogg 9sから12ｓ\n",
    "#  grepot1/XC416484.ogg 4s以前\n",
    "# rufmot1/XC403364.ogg ノイズがすごい\n",
    "# trokin/iNat1240220.ogg ゴソゴソ．保留\n",
    "\n",
    "\n",
    "# 7sでフィルター．除去した後の音声の長さが3s以下のものを評価．全72件. 20分かかった\n",
    "# 書いてない音源は全durationが使えるという意味\n",
    "\n",
    "# 除去すべき場所を書いていく．\n",
    "#  21211/XC882650.ogg 9s以降\n",
    "# 65448/iNat273090.ogg 9s以前\n",
    "# amekes/iNat522505.ogg 人の歌い声．消していい．\n",
    "# banana/XC437586.ogg 4sから6.5s\n",
    "#  banana/XC524992.ogg 10以降\n",
    "# blchaw1/iNat629789.ogg 15s以前\n",
    "# grekis/iNat972136.ogg 人の声あり．消していい\n",
    "# grekis/iNat998004.ogg 2s以前\n",
    "#  laufal1/iNat19124.ogg 12s以降\n",
    "# laufal1/iNat428603.ogg 人の声あり．保留\n",
    "#  laufal1/iNat469782.ogg 人の声あり．保留\n",
    "# pirfly1/XC309684.ogg 3sから9s\n",
    "\n",
    "# rosspo1/iNat307857.ogg  全部人の声．消す\n",
    "# saffin/iNat307815.ogg 全部人の声．消す．author:  Abraham CA\n",
    "# trokin/XC879492.ogg かなり人の声あり．保留\n",
    "# trokin/iNat537466.ogg trokin/XC879492.ogg と同じ音声．消す\n",
    "#  tropar/iNat1231453.ogg 2sから4s\n",
    "#  watjac1/XC43803.ogg 人の声．保留\n",
    "#  wbwwre1/iNat1224010.ogg 人の声．保留\n",
    "#  wbwwre1/iNat1224011.ogg wbwwre1/iNat1224010.oggと同じ．消す．\n",
    "\n",
    "\n",
    "# 除去ミス\n",
    "# 555142/iNat761666.ogg OK\n",
    "# 65448/iNat273090.ogg ほぼ人の声．9s以降OK\n",
    "# 65448/iNat313963.ogg OK\n",
    "# 65962/iNat1109807.ogg OK\n",
    "# 65962/iNat382337.ogg OK\n",
    "# 67252/XC952184.ogg  OK\n",
    "# 67252/iNat1257838.ogg "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
