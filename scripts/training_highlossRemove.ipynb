{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cuda:0\n",
      "['sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFModelForTrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        # Ê¥ªÊÄßÂåñÈñ¢Êï∞‰∏çÂú®Ôºé\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "class BirdCLEFModelForTrain_Coat(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # CoaTÂ∞ÇÁî®: drop_path_rate„Çí0„Å´„Åô„Çã\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.0  # <= „Åì„Åì„Çí0.0„Å´ÔºÅ\n",
    "        )\n",
    "        \n",
    "        # CoaT„ÅØ reset_classifier „ÅåÂøÖË¶Å\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')  # <= global_pool='avg'\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BirdCLEFModelForTrain_Swin(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        backbone_out = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)  # 2D„Éó„Éº„É™„É≥„Ç∞„Å´Â§âÊõ¥ÔºÅÔºÅ\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if features.ndim == 4:\n",
    "            # CNNÁ≥ª (B, C, H, W)\n",
    "            features = self.pooling(features)\n",
    "            features = features.flatten(1)\n",
    "        elif features.ndim == 3:\n",
    "            # TransformerÁ≥ª (B, N, C)\n",
    "            features = features.mean(dim=1)\n",
    "        elif features.ndim == 2:\n",
    "            # „ÇÇ„ÅÜ (B, C) „Å´„Å™„Å£„Å¶„ÇãÔºà‰æã„Åà„Å∞ SwinTinyÔºâ\n",
    "            pass  # ‰Ωï„ÇÇÂä†Â∑•„Åó„Å™„ÅÑ\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n",
    "\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            self.train_csv = \"/kaggle/input/dataset-0419/melspec_20250419_1808/train.csv\"\n",
    "            self.spectrogram_npy = \"/kaggle/input/dataset-0419/melspec_20250419_1808/birdclef2025_melspec_5sec_256_256.npy\"\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # ÂÖ®model„ÅÆ‰øùÂ≠òÂÖà\n",
    "            self.model_path = self.models_dir # ÂêÑ„É¢„Éá„É´„ÅÆ‰øùÂ≠òÂÖàÔºéÂ≠¶ÁøíÊôÇ„Å´ÂãïÁöÑ„Å´Â§âÊõ¥Ôºé\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensemble_7sec_pseudoth0.5/pseudo_label.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/train_soundscapes_0407/train_soundscapes_melspecs.npy\"\n",
    "\n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            self.train_csv = '../data/processed/mel_safezone1000_head_hoplength512//train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_safezone1000_head_hoplength512/birdclef2025_melspec_5sec_256_256.npy'\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = \"efficientnet_b0\" # tf_efficientnetv2_b3   efficientnet_b0\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainerÂÜÖÈÉ®„ÅßÊ±∫„Åæ„Çã„ÅÆ„Åß„Åì„Åì„Åß„ÅØÊåáÂÆö„Åó„Å™„ÅÑÔºé\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "            self.label_smoothing = 0.05\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0]\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # „É¨„Ç¢Á®Æ„ÅØÂÖ®ÈÉ®train fold„Å´„Åô„Çã\n",
    "            self.aug_prob = 0.5 # spec augment„ÅÆÁ¢∫Áéá\n",
    "            \n",
    "            # mixup„ÅÆË®≠ÂÆö\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha = 0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labels„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            \n",
    "            \n",
    "            ## ÁèæÁä∂‰Ωø„Å£„Å¶„Å™„ÅÑÔºé\n",
    "            # self.mixup_alpha_real = 0.5\n",
    "            # self.mixup_alpha_pseudo = 0.5\n",
    "            self.use_pseudo_mixup = False  # pseudo lable„Åßmixup„Åô„Çã„Åã„Å©„ÅÜ„Åã\n",
    "            # self.pseudo_mix_prob = 0.4  # mixup„Åßpseudo lable„Çí‰Ωø„ÅÜÁ¢∫Áéá\n",
    "            # self.pseudo_conf_threshold = 0.5\n",
    "\n",
    "            ###\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=False)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train„ÅÆÂá¶ÁêÜ„Çí„ÇØ„É©„Çπ„ÅßÂÆüË°åÔºé\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # label„Å®index„ÅÆÂØæÂøú\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"üì• Loading pseudo label CSV and melspecs...\")\n",
    "\n",
    "        # row_id „Çí index „Å´„Åó„Å¶Ë™≠„ÅøËæº„ÇÄÔºà‚Üê „Åì„Åì„Åå„Éù„Ç§„É≥„ÉàÔºÅÔºâ\n",
    "        self.pseudo_df = pd.read_csv(self.cfg.pseudo_label_csv, index_col=\"row_id\")\n",
    "\n",
    "        # ‰ø°È†ºÂ∫¶„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Ôºà‰æã: ÊúÄÂ§ßÂÄ§„Åå 0.5 Êú™Ê∫Ä„ÅÆË°å„ÇíÈô§„ÅèÔºâ\n",
    "        confidence_threshold = self.cfg.pseudo_conf_threshold\n",
    "        max_probs = self.pseudo_df.max(axis=1)\n",
    "        self.pseudo_df = self.pseudo_df[max_probs > confidence_threshold]\n",
    "        self.pseudo_df = self.pseudo_df.reset_index(drop=False)\n",
    "        print(f\"‚úÖ Filtered pseudo labels: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # melspec „ÅØ key „Åå row_id „ÅÆ dict „ÇíÊÉ≥ÂÆö\n",
    "        self.pseudo_melspecs = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True)\n",
    "        print(f\"‚úÖ Loaded pseudo mel-spectrograms: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                    df=train_df,\n",
    "                    cfg=self.cfg,\n",
    "                    spectrograms=self.spectrograms,\n",
    "                    mode=\"train\",\n",
    "                    label2idx=self.label2index,\n",
    "                    idx2label=self.index2label \n",
    "                    )\n",
    "            \n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # üëá ROC AUC „ÅØ„Éê„Ç§„Éä„É™„É©„Éô„É´„ÇíÂøÖË¶Å„Å®„Åô„Çã„ÅÆ„Åß„ÄÅsoft label„Çí2ÂÄ§Âåñ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „Éê„Ç§„Éä„É™ÂåñÔºàÈÄ£Á∂öÂÄ§„Åß„ÇÇint„Åß„ÇÇÂÆâÂÖ®Ôºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # „Ç®„É©„ÉºÂá∫„Åü„Å®„Åç„ÇÇÂÆâÂøÉ\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „É©„Éô„É´„Çí„Éê„Ç§„Éä„É™ÂåñÔºàsoft labelÂØæÂøúÔºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csv„ÅÆfold„Çí‰Ωø„ÅÜÔºé\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "            # coat„ÅåÊñáÂ≠óÂàó„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞\n",
    "            if 'coat' in self.cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Coat(self.cfg).to(self.cfg.device)\n",
    "            \n",
    "            elif 'swin' in self.cfg.model_name:\n",
    "                print(\"Using Swin model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Swin(self.cfg).to(self.cfg.device)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "                \n",
    "                \n",
    "                \n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # „Çπ„Ç≥„Ç¢ÂèñÂæó\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwise„Çπ„Ç≥„Ç¢„ÇíÈô§Â§ñ„Åó„Åü val_metrics „ÅÆ„É≠„Ç∞\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # „É≠„Ç∞Áî®„Çπ„Ç≥„Ç¢„ÅÆÊõ¥Êñ∞Ôºàclasswise„ÅØÈô§Â§ñÔºâ\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "           \n",
    "                \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É¨„Ç¢Á®Æ„ÅØfold=-1„Å´„Åô„ÇãÔºé\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # ÂêÑ„É©„Éô„É´„ÅÆÂá∫ÁèæÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„ÅÆ„Éá„Éº„Çø„Å†„Åë fold = -1 „Å´‰∏äÊõ∏„Åç\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_loss_df = pd.read_csv(\"../data/processed/high_loss_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "Excluded high-loss samples from file: 686 samples removed.\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_20250521_2357\n",
      "{0: '1139490', 1: '1192948', 2: '1194042', 3: '126247', 4: '1346504', 5: '134933', 6: '135045', 7: '1462711', 8: '1462737', 9: '1564122', 10: '21038', 11: '21116', 12: '21211', 13: '22333', 14: '22973', 15: '22976', 16: '24272', 17: '24292', 18: '24322', 19: '41663', 20: '41778', 21: '41970', 22: '42007', 23: '42087', 24: '42113', 25: '46010', 26: '47067', 27: '476537', 28: '476538', 29: '48124', 30: '50186', 31: '517119', 32: '523060', 33: '528041', 34: '52884', 35: '548639', 36: '555086', 37: '555142', 38: '566513', 39: '64862', 40: '65336', 41: '65344', 42: '65349', 43: '65373', 44: '65419', 45: '65448', 46: '65547', 47: '65962', 48: '66016', 49: '66531', 50: '66578', 51: '66893', 52: '67082', 53: '67252', 54: '714022', 55: '715170', 56: '787625', 57: '81930', 58: '868458', 59: '963335', 60: 'amakin1', 61: 'amekes', 62: 'ampkin1', 63: 'anhing', 64: 'babwar', 65: 'bafibi1', 66: 'banana', 67: 'baymac', 68: 'bbwduc', 69: 'bicwre1', 70: 'bkcdon', 71: 'bkmtou1', 72: 'blbgra1', 73: 'blbwre1', 74: 'blcant4', 75: 'blchaw1', 76: 'blcjay1', 77: 'blctit1', 78: 'blhpar1', 79: 'blkvul', 80: 'bobfly1', 81: 'bobher1', 82: 'brtpar1', 83: 'bubcur1', 84: 'bubwre1', 85: 'bucmot3', 86: 'bugtan', 87: 'butsal1', 88: 'cargra1', 89: 'cattyr', 90: 'chbant1', 91: 'chfmac1', 92: 'cinbec1', 93: 'cocher1', 94: 'cocwoo1', 95: 'colara1', 96: 'colcha1', 97: 'compau', 98: 'compot1', 99: 'cotfly1', 100: 'crbtan1', 101: 'crcwoo1', 102: 'crebob1', 103: 'cregua1', 104: 'creoro1', 105: 'eardov1', 106: 'fotfly', 107: 'gohman1', 108: 'grasal4', 109: 'grbhaw1', 110: 'greani1', 111: 'greegr', 112: 'greibi1', 113: 'grekis', 114: 'grepot1', 115: 'gretin1', 116: 'grnkin', 117: 'grysee1', 118: 'gybmar', 119: 'gycwor1', 120: 'labter1', 121: 'laufal1', 122: 'leagre', 123: 'linwoo1', 124: 'littin1', 125: 'mastit1', 126: 'neocor', 127: 'norscr1', 128: 'olipic1', 129: 'orcpar', 130: 'palhor2', 131: 'paltan1', 132: 'pavpig2', 133: 'piepuf1', 134: 'pirfly1', 135: 'piwtyr1', 136: 'plbwoo1', 137: 'plctan1', 138: 'plukit1', 139: 'purgal2', 140: 'ragmac1', 141: 'rebbla1', 142: 'recwoo1', 143: 'rinkin1', 144: 'roahaw', 145: 'rosspo1', 146: 'royfly1', 147: 'rtlhum', 148: 'rubsee1', 149: 'rufmot1', 150: 'rugdov', 151: 'rumfly1', 152: 'ruther1', 153: 'rutjac1', 154: 'rutpuf1', 155: 'saffin', 156: 'sahpar1', 157: 'savhaw1', 158: 'secfly1', 159: 'shghum1', 160: 'shtfly1', 161: 'smbani', 162: 'snoegr', 163: 'sobtyr1', 164: 'socfly1', 165: 'solsan', 166: 'soulap1', 167: 'spbwoo1', 168: 'speowl1', 169: 'spepar1', 170: 'srwswa1', 171: 'stbwoo2', 172: 'strcuc1', 173: 'strfly1', 174: 'strher', 175: 'strowl1', 176: 'tbsfin1', 177: 'thbeup1', 178: 'thlsch3', 179: 'trokin', 180: 'tropar', 181: 'trsowl', 182: 'turvul', 183: 'verfly', 184: 'watjac1', 185: 'wbwwre1', 186: 'whbant1', 187: 'whbman1', 188: 'whfant1', 189: 'whmtyr1', 190: 'whtdov', 191: 'whttro1', 192: 'whwswa1', 193: 'woosto', 194: 'y00678', 195: 'yebela1', 196: 'yebfly1', 197: 'yebsee1', 198: 'yecspi2', 199: 'yectyr1', 200: 'yehbla2', 201: 'yehcar1', 202: 'yelori1', 203: 'yeofly1', 204: 'yercac1', 205: 'ywcpar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_safezone1000_head_hoplength512/birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 28558 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 22160 samples\n",
      "Validation set: 5712 samples\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f66952261e4ba784aeb8b483f990ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ca05ef58374f0a8ef99ba1db2d6921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0361, Train AUC: 0.5897, Train MAP: 0.0104\n",
      "Val Loss: 0.0256, Val AUC: 0.8139, Val MAP: 0.0851\n",
      "New best AUC: 0.8139 at epoch 1\n",
      "\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c013ea2c1ae4fd2b70fa0ec39904723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ca372d24b94912913b519d89be0d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0218, Train AUC: 0.8506, Train MAP: 0.1210\n",
      "Val Loss: 0.0186, Val AUC: 0.9118, Val MAP: 0.3059\n",
      "New best AUC: 0.9118 at epoch 2\n",
      "\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f261cad0c2413f92304bf679040aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e5df2e6bc6436eb4e385c1b0fe5906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0171, Train AUC: 0.9293, Train MAP: 0.2778\n",
      "Val Loss: 0.0162, Val AUC: 0.9348, Val MAP: 0.4359\n",
      "New best AUC: 0.9348 at epoch 3\n",
      "\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e029d107e2436283c7c4a68132f08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fafb2ea19e41a4bdf38eed0cad010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0146, Train AUC: 0.9558, Train MAP: 0.4080\n",
      "Val Loss: 0.0143, Val AUC: 0.9483, Val MAP: 0.5252\n",
      "New best AUC: 0.9483 at epoch 4\n",
      "\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf92c3baf94ee18a517f66195d3a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01185a055673474f90cb23897b454b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0128, Train AUC: 0.9741, Train MAP: 0.5125\n",
      "Val Loss: 0.0136, Val AUC: 0.9498, Val MAP: 0.5538\n",
      "New best AUC: 0.9498 at epoch 5\n",
      "\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abd87df86c04f49b8c2cbe82a1a0bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2378f8e4f9b4451e967e36f3afe39e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0114, Train AUC: 0.9808, Train MAP: 0.6017\n",
      "Val Loss: 0.0130, Val AUC: 0.9544, Val MAP: 0.5917\n",
      "New best AUC: 0.9544 at epoch 6\n",
      "\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468ba4bedd6946e29ae1cda1f54df460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c32eb5d1110416e9d3f26008956fbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0106, Train AUC: 0.9872, Train MAP: 0.6740\n",
      "Val Loss: 0.0129, Val AUC: 0.9540, Val MAP: 0.5943\n",
      "\n",
      "Best AUC for fold 0: 0.9544\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.9544\n",
      "Mean AUC: 0.9544\n",
      "============================================================\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´„ÅØmodels_{current_time}„Å´‰øùÂ≠ò„Åï„Çå„ÇãÔºé\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    before_count = len(train_df)\n",
    "    train_df = train_df[~train_df[\"filename\"].isin(high_loss_df[\"filename\"])]\n",
    "    after_count = len(train_df)\n",
    "    print(f\"Excluded high-loss samples from file: {before_count - after_count} samples removed.\")\n",
    "        \n",
    "    # taxonomy„ÅØ„É©„Éô„É´„Å®index„ÅÆÂØæÂøú„ÇíÂèñ„Çã„Åü„ÇÅ„Å´ÂøÖË¶ÅÔºé\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 6, val_auc: 0.954, train_auc: 0.981\n",
      "Missing log for fold 1: ../models/fld0_sfzn1000_hd_hl512_hghlssRmv/log_fold1.csv\n",
      "Missing log for fold 2: ../models/fld0_sfzn1000_hd_hl512_hghlssRmv/log_fold2.csv\n",
      "Missing log for fold 3: ../models/fld0_sfzn1000_hd_hl512_hghlssRmv/log_fold3.csv\n",
      "Missing log for fold 4: ../models/fld0_sfzn1000_hd_hl512_hghlssRmv/log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.954 | 0.981 | 0.592 | 0.602 | 0.013 | 0.011 | 6.00 | efficientnet_b0 | 32 | 7 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.036099</td>\n",
       "      <td>0.589679</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>0.813948</td>\n",
       "      <td>0.085089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>0.850587</td>\n",
       "      <td>0.120987</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>0.911760</td>\n",
       "      <td>0.305948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.929338</td>\n",
       "      <td>0.277848</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>0.934795</td>\n",
       "      <td>0.435863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.955820</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>0.948342</td>\n",
       "      <td>0.525205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.974106</td>\n",
       "      <td>0.512528</td>\n",
       "      <td>0.013602</td>\n",
       "      <td>0.949819</td>\n",
       "      <td>0.553804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.980820</td>\n",
       "      <td>0.601716</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.954443</td>\n",
       "      <td>0.591717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.987156</td>\n",
       "      <td>0.674003</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.953951</td>\n",
       "      <td>0.594254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000475            1.70    0.036099   0.589679   0.010448   \n",
       "1      2  0.000406            1.52    0.021835   0.850587   0.120987   \n",
       "2      3  0.000306            1.84    0.017067   0.929338   0.277848   \n",
       "3      4  0.000195            1.68    0.014618   0.955820   0.407960   \n",
       "4      5  0.000095            1.68    0.012798   0.974106   0.512528   \n",
       "5      6  0.000026            1.51    0.011437   0.980820   0.601716   \n",
       "6      7  0.000001            1.67    0.010622   0.987156   0.674003   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.025584  0.813948  0.085089  \n",
       "1  0.018626  0.911760  0.305948  \n",
       "2  0.016248  0.934795  0.435863  \n",
       "3  0.014326  0.948342  0.525205  \n",
       "4  0.013602  0.949819  0.553804  \n",
       "5  0.012957  0.954443  0.591717  \n",
       "6  0.012876  0.953951  0.594254  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir = \"../models/fld0_sfzn1000_hd_hl512_hghlssRmv/\"\n",
    "\n",
    "# „Çπ„Ç≥„Ç¢Ê†ºÁ¥çËæûÊõ∏Ôºàfold„Åî„Å®„ÅÆË®òÈå≤Ôºâ\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# ÂêÑfold„ÅÆ„Éô„Çπ„Éà„Çπ„Ç≥„Ç¢ÂèéÈõÜ\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# Âπ≥Âùá„Çπ„Ç≥„Ç¢„ÇíÊï¥ÂΩ¢Ôºà.3f„ÅßË°®Á§∫„ÄÅepoch„Å†„Åë.2fÔºâ\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv Ë™≠„ÅøËæº„Åø\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# configÊÉÖÂ†±„ÅÆÁµ±Âêà\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# MarkdownÂá∫Âäõ\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "model_dir = \"../models/fld0_sfzn1000_hd_hl512_hghlssRmv/\"\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# loss„Çí„Éó„É≠„ÉÉ„Éà\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\n",
      "ÊúÄÂ§ßË™§Â∑Æ: 5.95980167388916\n",
      "Âπ≥ÂùáË™§Â∑Æ: 1.857330560684204\n",
      "Ê®ôÊ∫ñÂÅèÂ∑Æ: 1.2556836605072021\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´Âá∫Âäõ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "\n",
    "# „É¢„Éá„É´„Éë„Çπ\n",
    "# ÊØîËºÉÂÖÉ\n",
    "model_1_path = \"../models/fold0_RemVoice0426_epch6//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_RemVoiceMan0426_epch6//model_fold0.pth\"\n",
    "\n",
    "# ÂÖ±ÈÄöË®≠ÂÆöÔºà„Åì„ÅÆcfg_inf„ÅØÂøÖÈ†àÔºâ\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÈñ¢Êï∞\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# Êé®Ë´ñÔºàÂá∫Âäõ„Å´ sigmoid „ÅåÂøÖË¶Å„Å™Â†¥Âêà„ÅØ model „Å´Âê´„Åæ„Çå„Å¶„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶ÈÅ©ÂÆúËøΩÂä†Ôºâ\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# Â∑ÆÂàÜË®àÁÆó\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\")\n",
    "print(f\"ÊúÄÂ§ßË™§Â∑Æ: {np.max(abs_diff)}\")\n",
    "print(f\"Âπ≥ÂùáË™§Â∑Æ: {np.mean(abs_diff)}\")\n",
    "print(f\"Ê®ôÊ∫ñÂÅèÂ∑Æ: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„Éù„ÉÉ„ÇØ1„Åß„Éá„Éê„ÉÉ„Ç∞„Åß„Åç„Çã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
