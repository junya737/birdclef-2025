{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n",
      "Tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebookならここを変更する．\n",
    "            self.train_csv = \"/kaggle/input/dataset-0419/melspec_20250419_1808/train.csv\"\n",
    "            self.spectrogram_npy = \"/kaggle/input/dataset-0419/melspec_20250419_1808/birdclef2025_melspec_5sec_256_256.npy\"\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # 全modelの保存先\n",
    "            self.model_path = self.models_dir # 各モデルの保存先．学習時に動的に変更．\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensemble_7sec_pseudoth0.5/pseudo_label.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/train_soundscapes_0407/train_soundscapes_melspecs.npy\"\n",
    "\n",
    "            # ローカルならここを変更する．\n",
    "            self.train_csv = '../data/processed/mel_safezone1000_head/train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_safezone1000_head/birdclef2025_melspec_5sec_256_256.npy'\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0' # tf_efficientnetv2_b3\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainer内部で決まるのでここでは指定しない．\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 128\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "            self.label_smoothing = 0.05\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0]\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # レア種は全部train foldにする\n",
    "            self.aug_prob = 0.5 # spec augmentの確率\n",
    "            \n",
    "            # mixupの設定\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha = 0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labelsを使うかどうか\n",
    "            \n",
    "            \n",
    "            ## 現状使ってない．\n",
    "            # self.mixup_alpha_real = 0.5\n",
    "            # self.mixup_alpha_pseudo = 0.5\n",
    "            self.use_pseudo_mixup = False  # pseudo lableでmixupするかどうか\n",
    "            # self.pseudo_mix_prob = 0.4  # mixupでpseudo lableを使う確率\n",
    "            # self.pseudo_conf_threshold = 0.5\n",
    "\n",
    "            ###\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=False)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainの処理をクラスで実行．\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.jsonを保存\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # labelとindexの対応\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"📥 Loading pseudo label CSV and melspecs...\")\n",
    "\n",
    "        # row_id を index にして読み込む（← ここがポイント！）\n",
    "        self.pseudo_df = pd.read_csv(self.cfg.pseudo_label_csv, index_col=\"row_id\")\n",
    "\n",
    "        # 信頼度フィルタリング（例: 最大値が 0.5 未満の行を除く）\n",
    "        confidence_threshold = self.cfg.pseudo_conf_threshold\n",
    "        max_probs = self.pseudo_df.max(axis=1)\n",
    "        self.pseudo_df = self.pseudo_df[max_probs > confidence_threshold]\n",
    "        self.pseudo_df = self.pseudo_df.reset_index(drop=False)\n",
    "        print(f\"✅ Filtered pseudo labels: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # melspec は key が row_id の dict を想定\n",
    "        self.pseudo_melspecs = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True)\n",
    "        print(f\"✅ Loaded pseudo mel-spectrograms: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                    df=train_df,\n",
    "                    cfg=self.cfg,\n",
    "                    spectrograms=self.spectrograms,\n",
    "                    mode=\"train\",\n",
    "                    label2idx=self.label2index,\n",
    "                    idx2label=self.index2label \n",
    "                    )\n",
    "            \n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # 👇 ROC AUC はバイナリラベルを必要とするので、soft labelを2値化\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # バイナリ化（連続値でもintでも安全）\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # エラー出たときも安心\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # ラベルをバイナリ化（soft label対応）\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "        scaler = GradScaler()  # ← AMP対応\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # === AMPを使ったforward-pass ===\n",
    "                with autocast(dtype=torch.bfloat16):  # ← H100向けAMP適用\n",
    "                    outputs = model(inputs)\n",
    "                    loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                    outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "\n",
    "                # === AMP対応の backward-pass ===\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                outputs = outputs.detach().to(torch.float32).cpu().numpy()\n",
    "                targets = targets.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "\n",
    "                    with autocast(dtype=torch.bfloat16):  # ← ここを追加\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "\n",
    "                    outputs = outputs.detach().to(torch.float32).cpu().numpy()\n",
    "                    targets = targets.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csvのfoldを使う．\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "\n",
    "            model = self.models_lib.BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # スコア取得\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwiseスコアを除外した val_metrics のログ\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # ログ用スコアの更新（classwiseは除外）\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "           \n",
    "                \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レア種はfold=-1にする．\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # 各ラベルの出現数をカウント\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rareなラベルをリストアップ\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rareなラベルのデータだけ fold = -1 に上書き\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_20250506_1930\n",
      "{0: '1139490', 1: '1192948', 2: '1194042', 3: '126247', 4: '1346504', 5: '134933', 6: '135045', 7: '1462711', 8: '1462737', 9: '1564122', 10: '21038', 11: '21116', 12: '21211', 13: '22333', 14: '22973', 15: '22976', 16: '24272', 17: '24292', 18: '24322', 19: '41663', 20: '41778', 21: '41970', 22: '42007', 23: '42087', 24: '42113', 25: '46010', 26: '47067', 27: '476537', 28: '476538', 29: '48124', 30: '50186', 31: '517119', 32: '523060', 33: '528041', 34: '52884', 35: '548639', 36: '555086', 37: '555142', 38: '566513', 39: '64862', 40: '65336', 41: '65344', 42: '65349', 43: '65373', 44: '65419', 45: '65448', 46: '65547', 47: '65962', 48: '66016', 49: '66531', 50: '66578', 51: '66893', 52: '67082', 53: '67252', 54: '714022', 55: '715170', 56: '787625', 57: '81930', 58: '868458', 59: '963335', 60: 'amakin1', 61: 'amekes', 62: 'ampkin1', 63: 'anhing', 64: 'babwar', 65: 'bafibi1', 66: 'banana', 67: 'baymac', 68: 'bbwduc', 69: 'bicwre1', 70: 'bkcdon', 71: 'bkmtou1', 72: 'blbgra1', 73: 'blbwre1', 74: 'blcant4', 75: 'blchaw1', 76: 'blcjay1', 77: 'blctit1', 78: 'blhpar1', 79: 'blkvul', 80: 'bobfly1', 81: 'bobher1', 82: 'brtpar1', 83: 'bubcur1', 84: 'bubwre1', 85: 'bucmot3', 86: 'bugtan', 87: 'butsal1', 88: 'cargra1', 89: 'cattyr', 90: 'chbant1', 91: 'chfmac1', 92: 'cinbec1', 93: 'cocher1', 94: 'cocwoo1', 95: 'colara1', 96: 'colcha1', 97: 'compau', 98: 'compot1', 99: 'cotfly1', 100: 'crbtan1', 101: 'crcwoo1', 102: 'crebob1', 103: 'cregua1', 104: 'creoro1', 105: 'eardov1', 106: 'fotfly', 107: 'gohman1', 108: 'grasal4', 109: 'grbhaw1', 110: 'greani1', 111: 'greegr', 112: 'greibi1', 113: 'grekis', 114: 'grepot1', 115: 'gretin1', 116: 'grnkin', 117: 'grysee1', 118: 'gybmar', 119: 'gycwor1', 120: 'labter1', 121: 'laufal1', 122: 'leagre', 123: 'linwoo1', 124: 'littin1', 125: 'mastit1', 126: 'neocor', 127: 'norscr1', 128: 'olipic1', 129: 'orcpar', 130: 'palhor2', 131: 'paltan1', 132: 'pavpig2', 133: 'piepuf1', 134: 'pirfly1', 135: 'piwtyr1', 136: 'plbwoo1', 137: 'plctan1', 138: 'plukit1', 139: 'purgal2', 140: 'ragmac1', 141: 'rebbla1', 142: 'recwoo1', 143: 'rinkin1', 144: 'roahaw', 145: 'rosspo1', 146: 'royfly1', 147: 'rtlhum', 148: 'rubsee1', 149: 'rufmot1', 150: 'rugdov', 151: 'rumfly1', 152: 'ruther1', 153: 'rutjac1', 154: 'rutpuf1', 155: 'saffin', 156: 'sahpar1', 157: 'savhaw1', 158: 'secfly1', 159: 'shghum1', 160: 'shtfly1', 161: 'smbani', 162: 'snoegr', 163: 'sobtyr1', 164: 'socfly1', 165: 'solsan', 166: 'soulap1', 167: 'spbwoo1', 168: 'speowl1', 169: 'spepar1', 170: 'srwswa1', 171: 'stbwoo2', 172: 'strcuc1', 173: 'strfly1', 174: 'strher', 175: 'strowl1', 176: 'tbsfin1', 177: 'thbeup1', 178: 'thlsch3', 179: 'trokin', 180: 'tropar', 181: 'trsowl', 182: 'turvul', 183: 'verfly', 184: 'watjac1', 185: 'wbwwre1', 186: 'whbant1', 187: 'whbman1', 188: 'whfant1', 189: 'whmtyr1', 190: 'whtdov', 191: 'whttro1', 192: 'whwswa1', 193: 'woosto', 194: 'y00678', 195: 'yebela1', 196: 'yebfly1', 197: 'yebsee1', 198: 'yecspi2', 199: 'yectyr1', 200: 'yehbla2', 201: 'yehcar1', 202: 'yelori1', 203: 'yeofly1', 204: 'yercac1', 205: 'ywcpar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_safezone1000_head/birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 28558 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 22846 samples\n",
      "Validation set: 5712 samples\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff28db619e1e4a6ebd4b7bf383c01081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 318\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    316\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(model, val_loader, criterion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# スコア取得\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 193\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.train_one_epoch\u001b[0;34m(self, model, loader, optimizer, criterion, device, scheduler)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# === AMP対応の backward-pass ===\u001b[39;00m\n\u001b[1;32m    192\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 193\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:416\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    414\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 416\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# モデルはmodels_{current_time}に保存される．\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    # taxonomyはラベルとindexの対応を取るために必要．\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Finished in 0.17 seconds\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# 大きなテンソルをGPUに載せて計算\n",
    "x = torch.rand((10000, 10000), device=device)\n",
    "y = torch.rand((10000, 10000), device=device)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    with autocast(dtype=torch.bfloat16):\n",
    "        z = torch.matmul(x, y)\n",
    "torch.cuda.synchronize()\n",
    "print(f\"Finished in {time.time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Finished in 2.77 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = \"cuda\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 大きなテンソルをGPUに載せて計算\n",
    "x = torch.rand((10000, 10000), device=device)\n",
    "y = torch.rand((10000, 10000), device=device)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    z = torch.matmul(x, y)\n",
    "torch.cuda.synchronize()\n",
    "print(f\"Finished in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "# cpu 4sec\n",
    "# cuda 2sec\n",
    "\n",
    "# 100\n",
    "# cuda  26sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 7, val_auc: 0.979, train_auc: 0.986\n",
      "Missing log for fold 1: ../models/fold0_NoSecLabel/log_fold1.csv\n",
      "Missing log for fold 2: ../models/fold0_NoSecLabel/log_fold2.csv\n",
      "Missing log for fold 3: ../models/fold0_NoSecLabel/log_fold3.csv\n",
      "Missing log for fold 4: ../models/fold0_NoSecLabel/log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.979 | 0.986 | 0.632 | 0.661 | 0.009 | 0.010 | 7.00 | efficientnet_b0 | 32 | 7 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.033349</td>\n",
       "      <td>0.624897</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.020636</td>\n",
       "      <td>0.871664</td>\n",
       "      <td>0.141454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>0.877786</td>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.942469</td>\n",
       "      <td>0.347776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.938558</td>\n",
       "      <td>0.283766</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>0.966379</td>\n",
       "      <td>0.472249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.960299</td>\n",
       "      <td>0.410690</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.972420</td>\n",
       "      <td>0.548459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.524180</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.976347</td>\n",
       "      <td>0.611012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.982372</td>\n",
       "      <td>0.609740</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.978113</td>\n",
       "      <td>0.622884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.986350</td>\n",
       "      <td>0.661198</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.979262</td>\n",
       "      <td>0.631614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000475            2.87    0.033349   0.624897   0.012976   \n",
       "1      2  0.000406            2.68    0.019327   0.877786   0.145989   \n",
       "2      3  0.000306            3.03    0.015461   0.938558   0.283766   \n",
       "3      4  0.000195            2.86    0.013323   0.960299   0.410690   \n",
       "4      5  0.000095            2.70    0.011484   0.978069   0.524180   \n",
       "5      6  0.000026            2.71    0.010293   0.982372   0.609740   \n",
       "6      7  0.000001            3.02    0.009515   0.986350   0.661198   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.020636  0.871664  0.141454  \n",
       "1  0.014699  0.942469  0.347776  \n",
       "2  0.011580  0.966379  0.472249  \n",
       "3  0.010393  0.972420  0.548459  \n",
       "4  0.009234  0.976347  0.611012  \n",
       "5  0.008748  0.978113  0.622884  \n",
       "6  0.008576  0.979262  0.631614  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir_name = \"fold0_NoSecLabel\"\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "\n",
    "# スコア格納辞書（foldごとの記録）\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# 各foldのベストスコア収集\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# 平均スコアを整形（.3fで表示、epochだけ.2f）\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv 読み込み\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# config情報の統合\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# Markdown出力\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_dir_name = \"fold0_NoSecLabel\"\n",
    "i = 0\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# lossをプロット\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 PyTorch モデル出力比較:\n",
      "最大誤差: 5.95980167388916\n",
      "平均誤差: 1.857330560684204\n",
      "標準偏差: 1.2556836605072021\n"
     ]
    }
   ],
   "source": [
    "# モデル出力チェック\n",
    "\n",
    "# モデルパス\n",
    "# 比較元\n",
    "model_1_path = \"../models/fold0_RemVoice0426_epch6//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_RemVoiceMan0426_epch6//model_fold0.pth\"\n",
    "\n",
    "# 共通設定（このcfg_infは必須）\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# モデル読み込み関数\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# モデル読み込み\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# 同じダミー入力\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# 推論（出力に sigmoid が必要な場合は model に含まれてるか確認して適宜追加）\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# 差分計算\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"🔍 PyTorch モデル出力比較:\")\n",
    "print(f\"最大誤差: {np.max(abs_diff)}\")\n",
    "print(f\"平均誤差: {np.mean(abs_diff)}\")\n",
    "print(f\"標準偏差: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポック1でデバッグできる.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
