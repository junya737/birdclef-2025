{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0c80c0",
   "metadata": {
    "papermill": {
     "duration": 0.004337,
     "end_time": "2025-05-20T09:22:44.781903",
     "exception": false,
     "start_time": "2025-05-20T09:22:44.777566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Some useful references:\n",
    "1. **[Training]**: https://github.com/LIHANG-HONG/birdclef2023-2nd-place-solution\n",
    "2. **[Inference]**: https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25\n",
    "\n",
    "This model backbone is seresnext26t_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a4afbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:22:44.790653Z",
     "iopub.status.busy": "2025-05-20T09:22:44.790232Z",
     "iopub.status.idle": "2025-05-20T09:23:07.830054Z",
     "shell.execute_reply": "2025-05-20T09:23:07.829008Z"
    },
    "papermill": {
     "duration": 23.046365,
     "end_time": "2025-05-20T09:23:07.831968",
     "exception": false,
     "start_time": "2025-05-20T09:22:44.785603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import torchaudio\n",
    "import random\n",
    "import itertools\n",
    "from typing import Union\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c9526f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.840787Z",
     "iopub.status.busy": "2025-05-20T09:23:07.840278Z",
     "iopub.status.idle": "2025-05-20T09:23:07.846257Z",
     "shell.execute_reply": "2025-05-20T09:23:07.845295Z"
    },
    "papermill": {
     "duration": 0.012329,
     "end_time": "2025-05-20T09:23:07.848146",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.835817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    seed = 42\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "\n",
    "    stage = 'train_bce'\n",
    "\n",
    "    train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "    train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "    model_files = ['/kaggle/input/bird2025-sed-ckpt/sedmodel.pth'\n",
    "                  ]\n",
    " \n",
    "    model_name = 'seresnext26t_32x4d'  \n",
    "    pretrained = False\n",
    "    in_channels = 1\n",
    "\n",
    "    \n",
    "    SR = 32000\n",
    "    target_duration = 5\n",
    "    train_duration = 10\n",
    "    \n",
    "    \n",
    "    device = 'cpu'\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00ddcf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.856015Z",
     "iopub.status.busy": "2025-05-20T09:23:07.855714Z",
     "iopub.status.idle": "2025-05-20T09:23:07.884060Z",
     "shell.execute_reply": "2025-05-20T09:23:07.882969Z"
    },
    "papermill": {
     "duration": 0.034235,
     "end_time": "2025-05-20T09:23:07.885805",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.851570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")\n",
    "print(f\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760ede7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.894442Z",
     "iopub.status.busy": "2025-05-20T09:23:07.894078Z",
     "iopub.status.idle": "2025-05-20T09:23:07.908823Z",
     "shell.execute_reply": "2025-05-20T09:23:07.907782Z"
    },
    "papermill": {
     "duration": 0.021291,
     "end_time": "2025-05-20T09:23:07.910633",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.889342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d418cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.919175Z",
     "iopub.status.busy": "2025-05-20T09:23:07.918849Z",
     "iopub.status.idle": "2025-05-20T09:23:07.928299Z",
     "shell.execute_reply": "2025-05-20T09:23:07.927410Z"
    },
    "papermill": {
     "duration": 0.015713,
     "end_time": "2025-05-20T09:23:07.929967",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.914254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == \"linear\":\n",
    "            return x\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.0)\n",
    "    bn.weight.data.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef99c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.938815Z",
     "iopub.status.busy": "2025-05-20T09:23:07.938451Z",
     "iopub.status.idle": "2025-05-20T09:23:07.960446Z",
     "shell.execute_reply": "2025-05-20T09:23:07.959563Z"
    },
    "papermill": {
     "duration": 0.028016,
     "end_time": "2025-05-20T09:23:07.962043",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.934027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        taxonomy_df = pd.read_csv('/kaggle/input/birdclef-2025/taxonomy.csv')\n",
    "        self.num_classes = len(taxonomy_df)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(cfg['n_mels'])\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg['model_name'],\n",
    "            pretrained=False,\n",
    "            in_chans=cfg['in_channels'],\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "        layers = list(self.backbone.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        if \"efficientnet\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "        elif \"eca\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.head.fc.in_features\n",
    "        elif \"res\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "        else:\n",
    "            backbone_out = self.backbone.num_features\n",
    "            \n",
    "        \n",
    "        self.fc1 = nn.Linear(backbone_out, backbone_out, bias=True)\n",
    "        self.att_block = AttBlockV2(backbone_out, self.num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.melspec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.cfg['SR'],\n",
    "            hop_length=self.cfg['hop_length'],\n",
    "            n_mels=self.cfg['n_mels'],\n",
    "            f_min=self.cfg['f_min'],\n",
    "            f_max=self.cfg['f_max'],\n",
    "            n_fft=self.cfg['n_fft'],\n",
    "            pad_mode=\"constant\",\n",
    "            norm=\"slaney\",\n",
    "            onesided=True,\n",
    "            mel_scale=\"htk\",\n",
    "        )\n",
    "        if self.cfg['device'] == \"cuda\":\n",
    "            self.melspec_transform = self.melspec_transform.cuda()\n",
    "        else:\n",
    "            self.melspec_transform = self.melspec_transform.cpu()\n",
    "\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "            stype=\"power\", top_db=80\n",
    "        )\n",
    "\n",
    "\n",
    "    def extract_feature(self,x):\n",
    "        x = x.permute((0, 1, 3, 2))\n",
    "        frames_num = x.shape[2]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        # if self.training:\n",
    "        #    x = self.spec_augmenter(x)\n",
    "        \n",
    "        x = x.transpose(2, 3)\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x, frames_num\n",
    "        \n",
    "    @torch.cuda.amp.autocast(enabled=False)\n",
    "    def transform_to_spec(self, audio):\n",
    "\n",
    "        audio = audio.float()\n",
    "        \n",
    "        spec = self.melspec_transform(audio)\n",
    "        spec = self.db_transform(spec)\n",
    "\n",
    "        if self.cfg['normal'] == 80:\n",
    "            spec = (spec + 80) / 80\n",
    "        elif self.cfg['normal'] == 255:\n",
    "            spec = spec / 255\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "        if self.cfg['in_channels'] == 3:\n",
    "            spec = image_delta(spec)\n",
    "        \n",
    "        return spec\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "\n",
    "        x, frames_num = self.extract_feature(x)\n",
    "        \n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        return torch.logit(clipwise_output)\n",
    "\n",
    "    def infer(self, x, tta_delta=2):\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "        x,_ = self.extract_feature(x)\n",
    "        time_att = torch.tanh(self.att_block.att(x))\n",
    "        feat_time = x.size(-1)\n",
    "        start = (\n",
    "            feat_time / 2 - feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train']) / 2\n",
    "        )\n",
    "        end = start + feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train'])\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        pred = self.attention_infer(start,end,x,time_att)\n",
    "\n",
    "        start_minus = max(0, start-tta_delta)\n",
    "        end_minus=end-tta_delta\n",
    "        pred_minus = self.attention_infer(start_minus,end_minus,x,time_att)\n",
    "\n",
    "        start_plus = start+tta_delta\n",
    "        end_plus=min(feat_time, end+tta_delta)\n",
    "        pred_plus = self.attention_infer(start_plus,end_plus,x,time_att)\n",
    "\n",
    "        pred = 0.5*pred + 0.25*pred_minus + 0.25*pred_plus\n",
    "        return pred\n",
    "        \n",
    "    def attention_infer(self,start,end,x,time_att):\n",
    "        feat = x[:, :, start:end]\n",
    "        # att = torch.softmax(time_att[:, :, start:end], dim=-1)\n",
    "        #             print(feat_time, start, end)\n",
    "        #             print(att_a.sum(), att.sum(), time_att.shape)\n",
    "        framewise_pred = torch.sigmoid(self.att_block.cla(feat))\n",
    "        framewise_pred_max = framewise_pred.max(dim=2)[0]\n",
    "        # clipwise_output = torch.sum(framewise_pred * att, dim=-1)\n",
    "        #logits = torch.sum(\n",
    "        #    self.att_block.cla(feat) * att,\n",
    "        #    dim=-1,\n",
    "        #)\n",
    "\n",
    "        # return clipwise_output\n",
    "        return framewise_pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08af6ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.970489Z",
     "iopub.status.busy": "2025-05-20T09:23:07.970172Z",
     "iopub.status.idle": "2025-05-20T09:23:07.981960Z",
     "shell.execute_reply": "2025-05-20T09:23:07.980629Z"
    },
    "papermill": {
     "duration": 0.018091,
     "end_time": "2025-05-20T09:23:07.983822",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.965731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_sample(path, cfg):\n",
    "    audio, orig_sr = sf.read(path, dtype=\"float32\")\n",
    "    seconds = []\n",
    "    audio_length = cfg.SR * cfg.target_duration\n",
    "    step = audio_length\n",
    "    for i in range(audio_length, len(audio) + step, step):\n",
    "        start = max(0, i - audio_length)\n",
    "        end = start + audio_length\n",
    "        if end > len(audio):\n",
    "            pass\n",
    "        else:\n",
    "            seconds.append(int(end/cfg.SR))\n",
    "\n",
    "    audio = np.concatenate([audio,audio,audio])\n",
    "    audios = []\n",
    "    for i,second in enumerate(seconds):\n",
    "        end_seconds = int(second)\n",
    "        start_seconds = int(end_seconds - cfg.target_duration)\n",
    "    \n",
    "        end_index = int(cfg.SR * (end_seconds + (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        start_index = int(cfg.SR * (start_seconds - (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        end_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        start_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        y = audio[start_index:end_index].astype(np.float32)\n",
    "        if i==0:\n",
    "            y[:start_pad] = 0\n",
    "        elif i==(len(seconds)-1):\n",
    "            y[-end_pad:] = 0\n",
    "        audios.append(y)\n",
    "\n",
    "    return audios\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032dd269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:07.991979Z",
     "iopub.status.busy": "2025-05-20T09:23:07.991626Z",
     "iopub.status.idle": "2025-05-20T09:23:08.004389Z",
     "shell.execute_reply": "2025-05-20T09:23:08.003153Z"
    },
    "papermill": {
     "duration": 0.018983,
     "end_time": "2025-05-20T09:23:08.006266",
     "exception": false,
     "start_time": "2025-05-20T09:23:07.987283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_model_files(cfg):\n",
    "    \"\"\"\n",
    "    Find all .pth model files in the specified model directory\n",
    "    \"\"\"\n",
    "    model_files = []\n",
    "    \n",
    "    model_dir = Path(cfg.model_path)\n",
    "    \n",
    "    for path in model_dir.glob('**/*.pth'):\n",
    "        model_files.append(str(path))\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "def load_models(cfg, num_classes):\n",
    "    \"\"\"\n",
    "    Load all found model files and prepare them for ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # model_files = find_model_files(cfg)\n",
    "    model_files = cfg.model_files\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
    "        return models\n",
    "    \n",
    "    print(f\"Found a total of {len(model_files)} model files.\")\n",
    "    \n",
    "    for i, model_path in enumerate(model_files):\n",
    "        try:\n",
    "            print(f\"Loading model: {model_path}\")\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device), weights_only=False)\n",
    "            cfg_temp = checkpoint['cfg']\n",
    "            cfg_temp['device'] = cfg.device\n",
    "            \n",
    "            model = BirdCLEFModel(cfg_temp)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(cfg.device)\n",
    "            model.eval()\n",
    "            model.zero_grad()\n",
    "            model.half().float()\n",
    "            \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_path}: {e}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_on_spectrogram(audio_path, models, cfg, species_ids):\n",
    "    \"\"\"Process a single audio file and predict species presence for each 5-second segment\"\"\"\n",
    "    audio_path = str(audio_path)\n",
    "    predictions = []\n",
    "    row_ids = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "\n",
    "    print(f\"Processing {soundscape_id}\")\n",
    "    audio_data = load_sample(audio_path, cfg)\n",
    "    for segment_idx, audio_input in enumerate(audio_data):\n",
    "        \n",
    "        end_time_sec = (segment_idx + 1) * cfg.target_duration\n",
    "        row_id = f\"{soundscape_id}_{end_time_sec}\"\n",
    "        row_ids.append(row_id)\n",
    "        \n",
    "        mel_spec = torch.tensor(audio_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        mel_spec = mel_spec.to(cfg.device)\n",
    "        \n",
    "        if len(models) == 1:\n",
    "            with torch.no_grad():\n",
    "                outputs = models[0].infer(mel_spec)\n",
    "                final_preds = outputs.squeeze()\n",
    "                # final_preds = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "\n",
    "        else:\n",
    "            segment_preds = []\n",
    "            for model in models:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.infer(mel_spec)\n",
    "                    probs = outputs.squeeze()\n",
    "                    # probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "                    segment_preds.append(probs)\n",
    "\n",
    "            \n",
    "            final_preds = np.mean(segment_preds, axis=0)\n",
    "                \n",
    "        predictions.append(final_preds)\n",
    "\n",
    "    predictions = np.stack(predictions,axis=0)\n",
    "    \n",
    "    return row_ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71bc210f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:08.014759Z",
     "iopub.status.busy": "2025-05-20T09:23:08.014388Z",
     "iopub.status.idle": "2025-05-20T09:23:08.027069Z",
     "shell.execute_reply": "2025-05-20T09:23:08.025973Z"
    },
    "papermill": {
     "duration": 0.019239,
     "end_time": "2025-05-20T09:23:08.028968",
     "exception": false,
     "start_time": "2025-05-20T09:23:08.009729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(cfg, models, species_ids):\n",
    "    \"\"\"Run inference on all test soundscapes\"\"\"\n",
    "    test_files = list(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        test_files = sorted(glob(str(Path('/kaggle/input/birdclef-2025/train_soundscapes') / '*.ogg')))[:10]\n",
    "    \n",
    "    print(f\"Found {len(test_files)} test soundscapes\")\n",
    "\n",
    "    all_row_ids = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(\n",
    "        executor.map(\n",
    "            predict_on_spectrogram,\n",
    "            test_files,\n",
    "            itertools.repeat(models),\n",
    "            itertools.repeat(cfg),\n",
    "            itertools.repeat(species_ids)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for rids, preds in results:\n",
    "        all_row_ids.extend(rids)\n",
    "        all_predictions.extend(preds)\n",
    "    \n",
    "    return all_row_ids, all_predictions\n",
    "\n",
    "def create_submission(row_ids, predictions, species_ids, cfg):\n",
    "    \"\"\"Create submission dataframe\"\"\"\n",
    "    print(\"Creating submission dataframe...\")\n",
    "\n",
    "    submission_dict = {'row_id': row_ids}\n",
    "    \n",
    "    for i, species in enumerate(species_ids):\n",
    "        submission_dict[species] = [pred[i] for pred in predictions]\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_dict)\n",
    "\n",
    "    submission_df.set_index('row_id', inplace=True)\n",
    "\n",
    "    sample_sub = pd.read_csv(cfg.submission_csv, index_col='row_id')\n",
    "\n",
    "    missing_cols = set(sample_sub.columns) - set(submission_df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing {len(missing_cols)} species columns in submission\")\n",
    "        for col in missing_cols:\n",
    "            submission_df[col] = 0.0\n",
    "\n",
    "    submission_df = submission_df[sample_sub.columns]\n",
    "\n",
    "    submission_df = submission_df.reset_index()\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "\n",
    "def smooth_submission(submission_path):\n",
    "        \"\"\"\n",
    "        Post-process the submission CSV by smoothing predictions to enforce temporal consistency.\n",
    "        \n",
    "        For each soundscape (grouped by the file name part of 'row_id'), each row's predictions\n",
    "        are averaged with those of its neighbors using defined weights.\n",
    "        \n",
    "        :param submission_path: Path to the submission CSV file.\n",
    "        \"\"\"\n",
    "        print(\"Smoothing submission predictions...\")\n",
    "        sub = pd.read_csv(submission_path)\n",
    "        cols = sub.columns[1:]\n",
    "        # Extract group names by splitting row_id on the last underscore\n",
    "        groups = sub['row_id'].str.rsplit('_', n=1).str[0].values\n",
    "        unique_groups = np.unique(groups)\n",
    "        \n",
    "        for group in unique_groups:\n",
    "            # Get indices for the current group\n",
    "            idx = np.where(groups == group)[0]\n",
    "            sub_group = sub.iloc[idx].copy()\n",
    "            predictions = sub_group[cols].values\n",
    "            new_predictions = predictions.copy()\n",
    "            \n",
    "            if predictions.shape[0] > 1:\n",
    "                # Smooth the predictions using neighboring segments\n",
    "                new_predictions[0] = (predictions[0] * 0.8) + (predictions[1] * 0.2)\n",
    "                new_predictions[-1] = (predictions[-1] * 0.8) + (predictions[-2] * 0.2)\n",
    "                for i in range(1, predictions.shape[0]-1):\n",
    "                    new_predictions[i] = (predictions[i-1] * 0.2) + (predictions[i] * 0.6) + (predictions[i+1] * 0.2)\n",
    "            # Replace the smoothed values in the submission dataframe\n",
    "            sub.iloc[idx, 1:] = new_predictions\n",
    "        \n",
    "        sub.to_csv(submission_path, index=False)\n",
    "        print(f\"Smoothed submission saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2008f010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:08.037101Z",
     "iopub.status.busy": "2025-05-20T09:23:08.036785Z",
     "iopub.status.idle": "2025-05-20T09:23:08.043050Z",
     "shell.execute_reply": "2025-05-20T09:23:08.042035Z"
    },
    "papermill": {
     "duration": 0.01205,
     "end_time": "2025-05-20T09:23:08.044640",
     "exception": false,
     "start_time": "2025-05-20T09:23:08.032590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    print(\"Starting BirdCLEF-2025 inference...\")\n",
    "\n",
    "    models = load_models(cfg, num_classes)\n",
    "    \n",
    "    if not models:\n",
    "        print(\"No models found! Please check model paths.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Model usage: {'Single model' if len(models) == 1 else f'Ensemble of {len(models)} models'}\")\n",
    "\n",
    "    row_ids, predictions = run_inference(cfg, models, species_ids)\n",
    "\n",
    "    submission_df = create_submission(row_ids, predictions, species_ids, cfg)\n",
    "\n",
    "    submission_path = 'submission.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission saved to {submission_path}\")\n",
    "\n",
    "    smooth_submission(submission_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Inference completed in {(end_time - start_time)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f0d9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:08.052701Z",
     "iopub.status.busy": "2025-05-20T09:23:08.052360Z",
     "iopub.status.idle": "2025-05-20T09:23:42.769225Z",
     "shell.execute_reply": "2025-05-20T09:23:42.768185Z"
    },
    "papermill": {
     "duration": 34.722514,
     "end_time": "2025-05-20T09:23:42.770712",
     "exception": false,
     "start_time": "2025-05-20T09:23:08.048198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BirdCLEF-2025 inference...\n",
      "Found a total of 1 model files.\n",
      "Loading model: /kaggle/input/bird2025-sed-ckpt/sedmodel.pth\n",
      "Model usage: Single model\n",
      "Found 10 test soundscapes\n",
      "Processing H02_20230420_074000\n",
      "Processing H02_20230420_112000\n",
      "Processing H02_20230420_154500\n",
      "Processing H02_20230420_164000\n",
      "Processing H02_20230420_223500\n",
      "Processing H02_20230421_093000\n",
      "Processing H02_20230421_113500\n",
      "Processing H02_20230421_170000\n",
      "Processing H02_20230421_190500\n",
      "Processing H02_20230421_233500\n",
      "Creating submission dataframe...\n",
      "Submission saved to submission.csv\n",
      "Smoothing submission predictions...\n",
      "Smoothed submission saved to submission.csv\n",
      "Inference completed in 0.58 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f191c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:23:42.780074Z",
     "iopub.status.busy": "2025-05-20T09:23:42.779370Z",
     "iopub.status.idle": "2025-05-20T09:23:42.826134Z",
     "shell.execute_reply": "2025-05-20T09:23:42.825209Z"
    },
    "papermill": {
     "duration": 0.053199,
     "end_time": "2025-05-20T09:23:42.827767",
     "exception": false,
     "start_time": "2025-05-20T09:23:42.774568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H02_20230420_074000_5</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.015284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.013137</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H02_20230420_074000_10</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>0.008562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H02_20230420_074000_15</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.010935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H02_20230420_074000_20</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.011082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H02_20230420_074000_25</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.011930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>H02_20230421_233500_40</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>H02_20230421_233500_45</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>H02_20230421_233500_50</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.001361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>H02_20230421_233500_55</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>H02_20230421_233500_60</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     row_id   1139490   1192948   1194042    126247   1346504  \\\n",
       "0     H02_20230420_074000_5  0.016332  0.012527  0.007971  0.004778  0.009133   \n",
       "1    H02_20230420_074000_10  0.008986  0.009379  0.005560  0.008420  0.007382   \n",
       "2    H02_20230420_074000_15  0.008765  0.013967  0.006337  0.010346  0.009861   \n",
       "3    H02_20230420_074000_20  0.009230  0.013817  0.005187  0.010118  0.011212   \n",
       "4    H02_20230420_074000_25  0.006668  0.008136  0.004723  0.014316  0.008138   \n",
       "..                      ...       ...       ...       ...       ...       ...   \n",
       "115  H02_20230421_233500_40  0.000622  0.000268  0.001013  0.002451  0.001090   \n",
       "116  H02_20230421_233500_45  0.000763  0.000345  0.001095  0.002011  0.001469   \n",
       "117  H02_20230421_233500_50  0.000901  0.000422  0.001033  0.001648  0.001985   \n",
       "118  H02_20230421_233500_55  0.000946  0.000494  0.000867  0.001378  0.001661   \n",
       "119  H02_20230421_233500_60  0.001163  0.000640  0.000780  0.001774  0.001125   \n",
       "\n",
       "       134933    135045   1462711   1462737  ...   yebfly1   yebsee1  \\\n",
       "0    0.009840  0.008630  0.012590  0.015284  ...  0.007486  0.007325   \n",
       "1    0.010534  0.009063  0.009051  0.012479  ...  0.007712  0.006622   \n",
       "2    0.009556  0.008770  0.009856  0.013425  ...  0.008984  0.007204   \n",
       "3    0.010011  0.008615  0.010036  0.013364  ...  0.009529  0.007226   \n",
       "4    0.011394  0.009380  0.007223  0.010487  ...  0.009090  0.007163   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "115  0.002296  0.003640  0.000454  0.001321  ...  0.002527  0.001519   \n",
       "116  0.002735  0.004295  0.000625  0.001896  ...  0.002756  0.001784   \n",
       "117  0.002978  0.004607  0.000755  0.002246  ...  0.002979  0.001832   \n",
       "118  0.003114  0.005149  0.000810  0.002382  ...  0.003257  0.002210   \n",
       "119  0.003272  0.005577  0.000939  0.002943  ...  0.002893  0.002126   \n",
       "\n",
       "      yecspi2   yectyr1   yehbla2   yehcar1   yelori1   yeofly1   yercac1  \\\n",
       "0    0.009524  0.015557  0.006878  0.010789  0.009351  0.013137  0.017736   \n",
       "1    0.007708  0.012560  0.005736  0.012938  0.008207  0.013437  0.011326   \n",
       "2    0.008389  0.014169  0.006305  0.015094  0.009840  0.014444  0.011852   \n",
       "3    0.007192  0.016507  0.007442  0.015733  0.011343  0.014424  0.012735   \n",
       "4    0.006370  0.017960  0.007912  0.015926  0.012076  0.013338  0.012307   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.000969  0.004996  0.000884  0.002199  0.000885  0.004323  0.002254   \n",
       "116  0.000969  0.004868  0.000828  0.002383  0.000867  0.005341  0.002152   \n",
       "117  0.000860  0.005548  0.000813  0.002539  0.000884  0.005650  0.002346   \n",
       "118  0.000919  0.006803  0.000824  0.002699  0.001130  0.005487  0.002700   \n",
       "119  0.000988  0.005950  0.001107  0.002506  0.001624  0.004384  0.002872   \n",
       "\n",
       "       ywcpar  \n",
       "0    0.005246  \n",
       "1    0.008562  \n",
       "2    0.010935  \n",
       "3    0.011082  \n",
       "4    0.011930  \n",
       "..        ...  \n",
       "115  0.001449  \n",
       "116  0.001477  \n",
       "117  0.001361  \n",
       "118  0.001394  \n",
       "119  0.001935  \n",
       "\n",
       "[120 rows x 207 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7130272,
     "sourceId": 11719803,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459867,
     "sourceId": 11870659,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.275304,
   "end_time": "2025-05-20T09:23:45.886660",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T09:22:39.611356",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
