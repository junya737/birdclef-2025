{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n",
      "Tensor device: cuda:0\n",
      "['sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        \n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n",
    "\n",
    "\n",
    "\n",
    "class BirdCLEFDatasetWithPseudoMixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, pseudo_df=None, pseudo_melspecs=None,\n",
    "                 mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.pseudo_df = pseudo_df.reset_index(drop=True) if pseudo_df is not None else None\n",
    "        self.pseudo_melspecs = pseudo_melspecs\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx2label = idx2label\n",
    "        self.species_ids = list(label2idx.keys()) if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df['filename'].map(\n",
    "                lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        rand_val = random.random()\n",
    "\n",
    "        # === real √ó real mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and rand_val < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === real √ó pseudo mixup ===\n",
    "        if (self.mode == \"train\" and self.cfg.use_pseudo_mixup and\n",
    "            self.pseudo_df is not None and\n",
    "            rand_val < (self.cfg.mixup_prob + self.cfg.pseudo_mixup_prob)):\n",
    "            \n",
    "            idx2 = random.randint(0, len(self.pseudo_df) - 1)\n",
    "            row2 = self.pseudo_df.iloc[idx2]\n",
    "            spec2 = self._get_spec_pseudo(row2['samplename'])\n",
    "            label2 = self._get_label_pseudo(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === no mixup ===\n",
    "        return {\n",
    "            'melspec': spec1,\n",
    "            'target': torch.tensor(label1, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_spec_pseudo(self, samplename):\n",
    "        if self.pseudo_melspecs and samplename in self.pseudo_melspecs:\n",
    "            spec = self.pseudo_melspecs[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Pseudo spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        return spec  # No augmentation\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def _get_label_pseudo(self, row):\n",
    "        values = row[self.species_ids].values.astype(np.float32)\n",
    "        values = np.nan_to_num(values, nan=0.0)\n",
    "        return values\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFModelForTrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        # Ê¥ªÊÄßÂåñÈñ¢Êï∞‰∏çÂú®Ôºé\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "class BirdCLEFModelForTrain_Coat(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # CoaTÂ∞ÇÁî®: drop_path_rate„Çí0„Å´„Åô„Çã\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.0  # <= „Åì„Åì„Çí0.0„Å´ÔºÅ\n",
    "        )\n",
    "        \n",
    "        # CoaT„ÅØ reset_classifier „ÅåÂøÖË¶Å\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')  # <= global_pool='avg'\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BirdCLEFModelForTrain_Swin(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        backbone_out = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)  # 2D„Éó„Éº„É™„É≥„Ç∞„Å´Â§âÊõ¥ÔºÅÔºÅ\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if features.ndim == 4:\n",
    "            # CNNÁ≥ª (B, C, H, W)\n",
    "            features = self.pooling(features)\n",
    "            features = features.flatten(1)\n",
    "        elif features.ndim == 3:\n",
    "            # TransformerÁ≥ª (B, N, C)\n",
    "            features = features.mean(dim=1)\n",
    "        elif features.ndim == 2:\n",
    "            # „ÇÇ„ÅÜ (B, C) „Å´„Å™„Å£„Å¶„ÇãÔºà‰æã„Åà„Å∞ SwinTinyÔºâ\n",
    "            pass  # ‰Ωï„ÇÇÂä†Â∑•„Åó„Å™„ÅÑ\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n",
    "\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = None\n",
    "            self.spectrogram_npy = None\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = None\n",
    "            self.pseudo_melspec_npy = None\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # ÂÖ®model„ÅÆ‰øùÂ≠òÂÖà\n",
    "            self.model_path = self.models_dir # ÂêÑ„É¢„Éá„É´„ÅÆ‰øùÂ≠òÂÖàÔºéÂ≠¶ÁøíÊôÇ„Å´ÂãïÁöÑ„Å´Â§âÊõ¥Ôºé\n",
    "            \n",
    "            \n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„Çã\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = '../data/processed/pretrain_0529/train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/pretrain_0529//birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensmbl_0850//pseudo_labels.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/mel_prtl_trn_sndscps_hl512_0850//mel_train_soundscapes.npy\"\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = \"efficientnet_b0\" # tf_efficientnetv2_b3   efficientnet_b0\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainerÂÜÖÈÉ®„ÅßÊ±∫„Åæ„Çã„ÅÆ„Åß„Åì„Åì„Åß„ÅØÊåáÂÆö„Åó„Å™„ÅÑÔºé\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0] # fold„ÅÆÈÅ∏Êäû\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # „É¨„Ç¢Á®Æ„ÅØÂÖ®ÈÉ®train fold„Å´„Åô„Çã\n",
    "            self.aug_prob = 0.5 # spec augment„ÅÆÁ¢∫Áéá\n",
    "            \n",
    "            # real √ó real„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha =  0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labels„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            \n",
    "            \n",
    "            \n",
    "            # real √ó pseudo„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_pseudo_mixup = False # Pseudo mixup„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            self.pseudo_no_call_threshold = 0.06  # no call„ÅÆÈñæÂÄ§Ôºé‰Ωé„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.08„Åå‰∏äÈôê\n",
    "            self.pseudo_high_conf_threshold = 0.9 # Pseudo Label„ÅÆÈ´ò‰ø°È†ºÂ∫¶„ÅÆÈñæÂÄ§ÔºéÈ´ò„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.7„Åå‰∏ãÈôêÔºé\n",
    "            self.pseudo_mixup_prob = 0.1 # Pseudo mixup „Çí‰Ωø„ÅÜÁ¢∫ÁéáÔºéreal √ó real mixup„Å®ÂêåÊôÇ„Å´‰Ωø„Çè„Çå„Çã„Åì„Å®„ÅØ„Å™„ÅÑÔºé\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=False)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train„ÅÆÂá¶ÁêÜ„Çí„ÇØ„É©„Çπ„ÅßÂÆüË°åÔºé\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # label„Å®index„ÅÆÂØæÂøú\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"üì• Loading pseudo label CSV and melspecs from: \", self.cfg.pseudo_label_csv)\n",
    "\n",
    "        # 1. „É©„Éô„É´CSVË™≠„ÅøËæº„Åø\n",
    "        df = pd.read_csv(self.cfg.pseudo_label_csv)\n",
    "        species_cols = df.columns.drop(\"row_id\")\n",
    "        \n",
    "        # 2. soft label ÂâçÂá¶ÁêÜ: „Åó„Åç„ÅÑÂÄ§‰ª•‰∏ã„Çí„Çº„É≠„Å´\n",
    "        df[species_cols] = df[species_cols].where(df[species_cols] >= self.cfg.pseudo_no_call_threshold, 0.0)\n",
    "\n",
    "        # 3. no_call „Å® high_conf „Å´ÂàÜÈ°û\n",
    "        no_call_df = df[df[species_cols].max(axis=1) == 0.0].copy()\n",
    "        no_call_df[\"primary_label\"] = \"no_call\"\n",
    "        no_call_df[\"pseudo_source\"] = \"no_call\"\n",
    "        no_call_df[\"samplename\"] = no_call_df[\"row_id\"]\n",
    "\n",
    "        high_conf_df = df[df[species_cols].max(axis=1) >= self.cfg.pseudo_high_conf_threshold].copy()\n",
    "        high_conf_df[\"primary_label\"] = high_conf_df[species_cols].idxmax(axis=1)\n",
    "        high_conf_df[\"pseudo_source\"] = \"high_conf\"\n",
    "        high_conf_df[\"samplename\"] = high_conf_df[\"row_id\"]\n",
    "\n",
    "        # 4. Áµ±Âêà\n",
    "        self.pseudo_df = pd.concat([no_call_df, high_conf_df], axis=0).reset_index(drop=True)\n",
    "        print(f\"‚úÖ no_call: {len(no_call_df)}, high_conf: {len(high_conf_df)}, total: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # 5. ÂøÖË¶Å„Å™ row_id „Å†„ÅëÊäΩÂá∫\n",
    "        used_ids = set(self.pseudo_df[\"row_id\"])\n",
    "\n",
    "        # 6. ËæûÊõ∏ÂΩ¢Âºè„ÅÆ .npy „ÇíË™≠„ÅøËæº„ÇÄ\n",
    "        print(\"üì¶ Loading full pseudo mel spectrograms from:\", self.cfg.pseudo_melspec_npy)\n",
    "        full_mels = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"üì¶ All pseudo mel specs loaded: {len(full_mels)}\")\n",
    "\n",
    "        # 7. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        self.pseudo_melspecs = {\n",
    "            row_id: full_mels[row_id]\n",
    "            for row_id in used_ids\n",
    "            if row_id in full_mels\n",
    "        }\n",
    "        \n",
    "        del full_mels  # „É°„É¢„É™ÁØÄÁ¥Ñ„ÅÆ„Åü„ÇÅ„Å´ÂâäÈô§\n",
    "        gc.collect()  # „Ç¨„Éº„Éô„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„ÇíÂÆüË°å\n",
    "\n",
    "        print(f\"‚úÖ Filtered mel specs loaded: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            \n",
    "            print(\"Using BirdCLEFDatasetWithPseudoMixup for training...\")\n",
    "            return BirdCLEFDatasetWithPseudoMixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                pseudo_df=self.pseudo_df,\n",
    "                pseudo_melspecs=self.pseudo_melspecs,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "        else:\n",
    "            print(\"Using BirdCLEFDatasetFromNPY_Mixup for training...\")\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # üëá ROC AUC „ÅØ„Éê„Ç§„Éä„É™„É©„Éô„É´„ÇíÂøÖË¶Å„Å®„Åô„Çã„ÅÆ„Åß„ÄÅsoft label„Çí2ÂÄ§Âåñ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „Éê„Ç§„Éä„É™ÂåñÔºàÈÄ£Á∂öÂÄ§„Åß„ÇÇint„Åß„ÇÇÂÆâÂÖ®Ôºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # „Ç®„É©„ÉºÂá∫„Åü„Å®„Åç„ÇÇÂÆâÂøÉ\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „É©„Éô„É´„Çí„Éê„Ç§„Éä„É™ÂåñÔºàsoft labelÂØæÂøúÔºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csv„ÅÆfold„Çí‰Ωø„ÅÜÔºé\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "            # coat„ÅåÊñáÂ≠óÂàó„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞\n",
    "            if 'coat' in self.cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Coat(self.cfg).to(self.cfg.device)\n",
    "            \n",
    "            elif 'swin' in self.cfg.model_name:\n",
    "                print(\"Using Swin model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Swin(self.cfg).to(self.cfg.device)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "                \n",
    "                \n",
    "                \n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # „Çπ„Ç≥„Ç¢ÂèñÂæó\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwise„Çπ„Ç≥„Ç¢„ÇíÈô§Â§ñ„Åó„Åü val_metrics „ÅÆ„É≠„Ç∞\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # „É≠„Ç∞Áî®„Çπ„Ç≥„Ç¢„ÅÆÊõ¥Êñ∞Ôºàclasswise„ÅØÈô§Â§ñÔºâ\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É¨„Ç¢Á®Æ„ÅØfold=-1„Å´„Åô„ÇãÔºé\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # ÂêÑ„É©„Éô„É´„ÅÆÂá∫ÁèæÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„ÅÆ„Éá„Éº„Çø„Å†„Åë fold = -1 „Å´‰∏äÊõ∏„Åç\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3559805/1250311324.py:5: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(cfg.train_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_20250529_2117\n",
      "{0: 'comgre', 1: 'goflea1', 2: 'orihob2', 3: 'nilfly2', 4: 'comkin1', 5: 'houspa', 6: 'kenplo1', 7: 'brnhao1', 8: 'ingori1', 9: 'rossta2', 10: 'insbab1', 11: 'grefla1', 12: 'emedov2', 13: 'blakit1', 14: 'rocpig', 15: 'purher1', 16: 'sohmyn1', 17: 'chbeat1', 18: 'gargan', 19: 'bwfshr1', 20: 'comfla1', 21: 'barfly1', 22: 'asiope1', 23: 'moipig1', 24: 'grnwar1', 25: 'indrol2', 26: 'placuc3', 27: 'bkrfla1', 28: 'insowl1', 29: 'vehpar1', 30: 'eaywag1', 31: 'nutman', 32: 'graher1', 33: 'ashpri1', 34: 'yebbab1', 35: 'grehor1', 36: 'spodov', 37: 'rufwoo2', 38: 'hoopoe', 39: 'niwpig1', 40: 'comtai1', 41: 'brodro1', 42: 'whcbar1', 43: 'grejun2', 44: 'integr', 45: 'whbtre1', 46: 'pomgrp2', 47: 'grewar3', 48: 'junmyn1', 49: 'copbar1', 50: 'grecou1', 51: 'comros', 52: 'whrmun', 53: 'yebbul3', 54: 'isbduc1', 55: 'crfbar1', 56: 'indrob1', 57: 'smamin1', 58: 'maltro1', 59: 'grtdro1', 60: 'inpher1', 61: 'dafbab1', 62: 'grnsan', 63: 'whbsho3', 64: 'whbwag1', 65: 'comior1', 66: 'categr', 67: 'inbrob1', 68: 'whbbul2', 69: 'tilwar1', 70: 'bkwsti', 71: 'spepic1', 72: 'barswa', 73: 'litgre1', 74: 'rorpar', 75: 'bkskit1', 76: 'malwoo1', 77: 'blhori1', 78: 'cohcuc1', 79: 'wbbfly1', 80: 'blnmon1', 81: 'whbwoo2', 82: 'putbab1', 83: 'indpit1', 84: 'compea', 85: 'rewlap1', 86: 'whiter2', 87: 'brwjac1', 88: 'ruftre2', 89: 'scamin3', 90: 'bladro1', 91: 'blrwar1', 92: 'pursun4', 93: 'brwowl1', 94: 'forwag1', 95: 'wynlau1', 96: 'crseag1', 97: 'spoowl1', 98: 'paisto1', 99: 'litspi1', 100: 'pursun3', 101: 'litegr', 102: 'comsan', 103: 'commyn', 104: 'ashwoo2', 105: 'eurbla2', 106: 'gyhcaf1', 107: 'kerlau2', 108: 'grbeat1', 109: 'vefnut1', 110: 'btbeat1', 111: 'lblwar1', 112: 'whtkin2', 113: 'brasta1', 114: 'rerswa1', 115: 'piekin1', 116: 'bncwoo3', 117: 'maghor2', 118: 'wemhar1', 119: 'sttwoo1', 120: 'rewbul', 121: 'junbab2', 122: 'houcro1', 123: 'labcro1', 124: 'indtit1', 125: 'brfowl1', 126: 'aspfly1', 127: 'darter2', 128: 'zitcis1', 129: 'heswoo1', 130: 'rufbab3', 131: 'gybpri1', 132: 'malpar1', 133: 'gloibi', 134: 'sbeowl1', 135: 'lirplo', 136: 'shikra1', 137: 'revbul', 138: 'jerbus2', 139: 'redspu1', 140: 'asbfly', 141: 'brcful1', 142: 'purswa3', 143: 'lewduc1', 144: 'eucdov', 145: 'gryfra', 146: 'brnshr', 147: 'blaeag1', 148: 'aspswi1', 149: 'grenig1', 150: 'cregos1', 151: 'woosan', 152: 'mawthr1', 153: 'brakit1', 154: 'crbsun2', 155: 'lesyel1', 156: 'eurcoo', 157: 'piebus1', 158: 'tibfly3', 159: 'ashdro1', 160: 'lobsun2', 161: 'plhpar1', 162: 'oripip1', 163: 'grywag', 164: 'pabflo1', 165: 'grynig2', 166: 'stbkin1', 167: 'litswi1', 168: 'asikoe2', 169: 'marsan', 170: 'plapri1', 171: 'thbwar1', 172: 'whbwat1', 173: 'laudov1', 174: 'commoo3', 175: 'plaflo1', 176: 'bcnher', 177: 'sqtbul1', 178: 'junowl1', 179: 'bkcbul1', 180: 'rutfly6', 181: 'yewgre1', 182: 'abhori1', 183: 'abethr1', 184: 'abythr1', 185: 'afbfly1', 186: 'afdfly1', 187: 'afecuc1', 188: 'affeag1', 189: 'afghor1', 190: 'afgfly1', 191: 'afmdov1', 192: 'afpfly1', 193: 'afpwag1', 194: 'afpkin1', 195: 'afrgos1', 196: 'afrgrp1', 197: 'afrjac1', 198: 'afrthr1', 199: 'amesun2', 200: 'augbuz1', 201: 'bagwea1', 202: 'bawhor2', 203: 'bcbeat1', 204: 'bawman1', 205: 'beasun2', 206: 'bkctch1', 207: 'bkfruw1', 208: 'blacra1', 209: 'blacuc1', 210: 'blaplo1', 211: 'blbpuf2', 212: 'blcapa2', 213: 'blfbus1', 214: 'blhgon1', 215: 'blksaw1', 216: 'blhher1', 217: 'blnmou1', 218: 'blnwea1', 219: 'bltbar1', 220: 'bltori1', 221: 'bltapa1', 222: 'blwlap1', 223: 'brctch1', 224: 'brcale1', 225: 'brcsta1', 226: 'brican1', 227: 'brcwea1', 228: 'brobab1', 229: 'broman1', 230: 'brosun1', 231: 'brubru1', 232: 'brrwhe3', 233: 'brtcha1', 234: 'brwwar1', 235: 'bswdov1', 236: 'btweye2', 237: 'butapa1', 238: 'bubwar2', 239: 'cabgre1', 240: 'carcha1', 241: 'carwoo1', 242: 'ccbeat1', 243: 'chibat1', 244: 'chewea1', 245: 'chespa1', 246: 'chtapa3', 247: 'chucis1', 248: 'cibwar1', 249: 'cohmar1', 250: 'colsun2', 251: 'combul2', 252: 'combuz1', 253: 'crheag1', 254: 'crefra2', 255: 'crohor1', 256: 'darbar1', 257: 'darter3', 258: 'didcuc1', 259: 'easmog1', 260: 'dutdov1', 261: 'dotbar1', 262: 'edcsun3', 263: 'egygoo', 264: 'eswdov1', 265: 'equaka1', 266: 'eubeat1', 267: 'fatrav1', 268: 'fatwid1', 269: 'fotdro5', 270: 'fislov1', 271: 'gabgos2', 272: 'gbesta1', 273: 'gnbcam2', 274: 'gnhsun1', 275: 'gobbun1', 276: 'grbcam1', 277: 'gobwea1', 278: 'golher1', 279: 'gobsta5', 280: 'grccra1', 281: 'grecor', 282: 'grewoo2', 283: 'grwpyt1', 284: 'gryapa1', 285: 'grywrw1', 286: 'gybfis1', 287: 'gycwar3', 288: 'gyhbus1', 289: 'gyhkin1', 290: 'gyhneg1', 291: 'gyhspa1', 292: 'gytbar1', 293: 'hadibi1', 294: 'hamerk1', 295: 'helgui', 296: 'hartur1', 297: 'hipbab1', 298: 'hunsun2', 299: 'joygre1', 300: 'huncis1', 301: 'kerspa2', 302: 'klacuc1', 303: 'kvbsun1', 304: 'lawgol', 305: 'lessts1', 306: 'lesmaw1', 307: 'libeat1', 308: 'litwea1', 309: 'loceag1', 310: 'lotcor1', 311: 'lotlap1', 312: 'luebus1', 313: 'mabeat1', 314: 'marsto1', 315: 'marsun2', 316: 'malkin1', 317: 'macshr1', 318: 'meypar1', 319: 'mcptit1', 320: 'moccha1', 321: 'mouwag1', 322: 'ndcsun2', 323: 'norbro1', 324: 'nobfly1', 325: 'norcro1', 326: 'norfis1', 327: 'norpuf1', 328: 'nubwoo1', 329: 'pabspa1', 330: 'piecro1', 331: 'palfly2', 332: 'palpri1', 333: 'pitwhy', 334: 'purgre2', 335: 'quailf1', 336: 'pygbat1', 337: 'ratcis1', 338: 'rbsrob1', 339: 'raybar1', 340: 'rebfir2', 341: 'rebhor1', 342: 'reboxp1', 343: 'reccor', 344: 'reccuc1', 345: 'reedov1', 346: 'refcro1', 347: 'refbar2', 348: 'reftin1', 349: 'refwar2', 350: 'reisee2', 351: 'rehwea1', 352: 'rehblu1', 353: 'rewsta1', 354: 'rindov', 355: 'rocmar2', 356: 'rostur1', 357: 'ruegls1', 358: 'sccsun2', 359: 'sacibi2', 360: 'rufcha2', 361: 'scrcha1', 362: 'scthon1', 363: 'sichor1', 364: 'shesta1', 365: 'sincis1', 366: 'slbgre1', 367: 'slcbou1', 368: 'sltnig1', 369: 'sobfly1', 370: 'somgre1', 371: 'somtit4', 372: 'soufis1', 373: 'soucit1', 374: 'spemou2', 375: 'spepig1', 376: 'spewea1', 377: 'spfbar1', 378: 'spfwea1', 379: 'spmthr1', 380: 'spwlap1', 381: 'squher1', 382: 'strsee1', 383: 'subbus1', 384: 'stusta1', 385: 'supsta1', 386: 'tacsun1', 387: 'tafpri1', 388: 'tamdov1', 389: 'thrnig1', 390: 'trobou1', 391: 'varsun2', 392: 'vibsta2', 393: 'vilwea1', 394: 'vimwea1', 395: 'walsta1', 396: 'wbgbir1', 397: 'wbrcha2', 398: 'wbswea1', 399: 'wfbeat1', 400: 'whbcan1', 401: 'whbcou1', 402: 'whbtit5', 403: 'whbcro2', 404: 'whbwea1', 405: 'whbwhe3', 406: 'whcpri2', 407: 'wheslf1', 408: 'whhsaw1', 409: 'whihel1', 410: 'whctur2', 411: 'wlwwar', 412: 'witswa1', 413: 'whrshr1', 414: 'wookin1', 415: 'wtbeat1', 416: 'yebapa1', 417: 'yebbar1', 418: 'yebduc1', 419: 'yebere1', 420: 'yebgre1', 421: 'yeccan1', 422: 'yebsto1', 423: 'yefcan', 424: 'yelbis1', 425: 'yertin1', 426: 'yenspu1', 427: 'yesbar1', 428: 'yespet1', 429: 'yetgre1', 430: 'zebdov', 431: 'afrsil1', 432: 'akepa1', 433: 'akiapo', 434: 'akekee', 435: 'amewig', 436: 'akikik', 437: 'apapan', 438: 'aniani', 439: 'arcter', 440: 'barpet', 441: 'belkin1', 442: 'bkbplo', 443: 'bknsti', 444: 'blkfra', 445: 'bkwpet', 446: 'blknod', 447: 'bongul', 448: 'brant', 449: 'brnboo', 450: 'brnnod', 451: 'brnowl', 452: 'brtcur', 453: 'buffle', 454: 'bulpet', 455: 'bubsan', 456: 'buwtea', 457: 'burpar', 458: 'cacgoo1', 459: 'calqua', 460: 'cangoo', 461: 'canvas', 462: 'caster1', 463: 'chbsan', 464: 'chukar', 465: 'chemun', 466: 'cintea', 467: 'comgal1', 468: 'comwax', 469: 'dunlin', 470: 'coopet', 471: 'crehon', 472: 'eurwig', 473: 'ercfra', 474: 'elepai', 475: 'fragul', 476: 'gadwal', 477: 'gamqua', 478: 'glwgul', 479: 'gnwtea', 480: 'golphe', 481: 'grbher3', 482: 'gresca', 483: 'grefri', 484: 'gwfgoo', 485: 'hawama', 486: 'hawcoo', 487: 'hawcre', 488: 'hawhaw', 489: 'hawpet1', 490: 'hoomer', 491: 'hawgoo', 492: 'houfin', 493: 'iiwi', 494: 'hudgod', 495: 'incter1', 496: 'jabwar', 497: 'japqua', 498: 'kalphe', 499: 'laugul', 500: 'kauama', 501: 'layalb', 502: 'leasan', 503: 'lcspet', 504: 'leater1', 505: 'lesyel', 506: 'lessca', 507: 'lobdow', 508: 'lotjae', 509: 'magpet1', 510: 'madpet', 511: 'mallar3', 512: 'masboo', 513: 'merlin', 514: 'mauala', 515: 'maupar', 516: 'mitpar', 517: 'moudov', 518: 'norcar', 519: 'norhar2', 520: 'normoc', 521: 'norpin', 522: 'norsho', 523: 'oahama', 524: 'omao', 525: 'osprey', 526: 'pagplo', 527: 'palila', 528: 'parjae', 529: 'pecsan', 530: 'peflov', 531: 'perfal', 532: 'pibgre', 533: 'reccar', 534: 'pomjae', 535: 'puaioh', 536: 'redava', 537: 'redjun', 538: 'redpha1', 539: 'refboo', 540: 'rempar', 541: 'rettro', 542: 'ribgul', 543: 'rinduc', 544: 'rinphe', 545: 'rudtur', 546: 'ruff', 547: 'sander', 548: 'semplo', 549: 'sheowl', 550: 'skylar', 551: 'shtsan', 552: 'snogoo', 553: 'sooter1', 554: 'sooshe', 555: 'sora', 556: 'sopsku1', 557: 'sposan', 558: 'towsol', 559: 'wantat1', 560: 'warwhe1', 561: 'wesmea', 562: 'wessan', 563: 'wetshe', 564: 'whfibi', 565: 'whiter', 566: 'whttro', 567: 'wiltur', 568: 'yebcar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/pretrain_0529//birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 73277 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 58621 samples\n",
      "Validation set: 14656 samples\n",
      "Using BirdCLEFDatasetFromNPY_Mixup for training...\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee1b4aca9c4415a4c6f1d8cf458a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4baa4b98a434d9488a9ac4a9163e03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0140, Train AUC: 0.6841, Train MAP: 0.0079\n",
      "Val Loss: 0.0086, Val AUC: 0.8859, Val MAP: 0.0803\n",
      "New best AUC: 0.8859 at epoch 1\n",
      "\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c345a16a7add4dbb81890740d4d8f8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797169a5ef0b4492b14d3a30c1d948fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0082, Train AUC: 0.8937, Train MAP: 0.0846\n",
      "Val Loss: 0.0063, Val AUC: 0.9508, Val MAP: 0.2281\n",
      "New best AUC: 0.9508 at epoch 2\n",
      "\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b073d37b8742228b56af7437e84ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ff7997493045c48197fd9138f948cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0069, Train AUC: 0.9436, Train MAP: 0.1805\n",
      "Val Loss: 0.0054, Val AUC: 0.9646, Val MAP: 0.3267\n",
      "New best AUC: 0.9646 at epoch 3\n",
      "\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0fe820e35645898ad83f881beb19f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4919795a96479ab347d22a8b59b261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0060, Train AUC: 0.9680, Train MAP: 0.2863\n",
      "Val Loss: 0.0049, Val AUC: 0.9710, Val MAP: 0.3804\n",
      "New best AUC: 0.9710 at epoch 4\n",
      "\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beff287691f74f67b957230806277a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8743ef0bca04820b6a3c2b7abe4cbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0053, Train AUC: 0.9805, Train MAP: 0.3894\n",
      "Val Loss: 0.0045, Val AUC: 0.9746, Val MAP: 0.4238\n",
      "New best AUC: 0.9746 at epoch 5\n",
      "\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6f5b00160d431b950cff3934b2433c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729a8de3a2ce419494c7975caf7f69fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0048, Train AUC: 0.9870, Train MAP: 0.4861\n",
      "Val Loss: 0.0043, Val AUC: 0.9766, Val MAP: 0.4517\n",
      "New best AUC: 0.9766 at epoch 6\n",
      "\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9748087175814679a8472bc72321eaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cc6ae212404805be40ea92871a5dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0045, Train AUC: 0.9900, Train MAP: 0.5523\n",
      "Val Loss: 0.0042, Val AUC: 0.9769, Val MAP: 0.4621\n",
      "New best AUC: 0.9769 at epoch 7\n",
      "\n",
      "Best AUC for fold 0: 0.9769\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.9769\n",
      "Mean AUC: 0.9769\n",
      "============================================================\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´„ÅØmodels_{current_time}„Å´‰øùÂ≠ò„Åï„Çå„ÇãÔºé\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    # taxonomy„ÅØ„É©„Éô„É´„Å®index„ÅÆÂØæÂøú„ÇíÂèñ„Çã„Åü„ÇÅ„Å´ÂøÖË¶ÅÔºé\n",
    "    taxonomy_df = train_df.drop_duplicates(subset=['primary_label']).reset_index(drop=True)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 10, val_auc: 0.961, train_auc: 0.984\n",
      "Missing log for fold 1: ../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/log_fold1.csv\n",
      "Missing log for fold 2: ../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/log_fold2.csv\n",
      "Missing log for fold 3: ../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/log_fold3.csv\n",
      "Missing log for fold 4: ../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.961 | 0.984 | 0.621 | 0.683 | 0.012 | 0.013 | 10.00 | efficientnet_b0 | 32 | 10 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.035727</td>\n",
       "      <td>0.602388</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.113608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.836596</td>\n",
       "      <td>0.128934</td>\n",
       "      <td>0.018696</td>\n",
       "      <td>0.903830</td>\n",
       "      <td>0.316452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.896024</td>\n",
       "      <td>0.241452</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.423576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.018021</td>\n",
       "      <td>0.928283</td>\n",
       "      <td>0.330715</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>0.948337</td>\n",
       "      <td>0.489140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.429676</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.954104</td>\n",
       "      <td>0.544437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>0.963718</td>\n",
       "      <td>0.493201</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.956263</td>\n",
       "      <td>0.577265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.973891</td>\n",
       "      <td>0.572610</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>0.958297</td>\n",
       "      <td>0.611675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>0.645768</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.959457</td>\n",
       "      <td>0.616605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.982736</td>\n",
       "      <td>0.671416</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.961081</td>\n",
       "      <td>0.621392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.983939</td>\n",
       "      <td>0.682903</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.961203</td>\n",
       "      <td>0.621468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000488            1.73    0.035727   0.602388   0.014649   \n",
       "1      2  0.000452            1.72    0.022987   0.836596   0.128934   \n",
       "2      3  0.000397            1.56    0.019714   0.896024   0.241452   \n",
       "3      4  0.000328            1.56    0.018021   0.928283   0.330715   \n",
       "4      5  0.000251            1.90    0.016548   0.953497   0.429676   \n",
       "5      6  0.000173            1.73    0.015348   0.963718   0.493201   \n",
       "6      7  0.000104            1.55    0.014131   0.973891   0.572610   \n",
       "7      8  0.000049            1.56    0.013354   0.979656   0.645768   \n",
       "8      9  0.000013            1.90    0.012991   0.982736   0.671416   \n",
       "9     10  0.000001            1.73    0.012554   0.983939   0.682903   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.024587  0.815242  0.113608  \n",
       "1  0.018696  0.903830  0.316452  \n",
       "2  0.016113  0.936770  0.423576  \n",
       "3  0.014686  0.948337  0.489140  \n",
       "4  0.013883  0.954104  0.544437  \n",
       "5  0.013157  0.956263  0.577265  \n",
       "6  0.012699  0.958297  0.611675  \n",
       "7  0.012397  0.959457  0.616605  \n",
       "8  0.012152  0.961081  0.621392  \n",
       "9  0.012103  0.961203  0.621468  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir = \"../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/\"\n",
    "\n",
    "# „Çπ„Ç≥„Ç¢Ê†ºÁ¥çËæûÊõ∏Ôºàfold„Åî„Å®„ÅÆË®òÈå≤Ôºâ\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# ÂêÑfold„ÅÆ„Éô„Çπ„Éà„Çπ„Ç≥„Ç¢ÂèéÈõÜ\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# Âπ≥Âùá„Çπ„Ç≥„Ç¢„ÇíÊï¥ÂΩ¢Ôºà.3f„ÅßË°®Á§∫„ÄÅepoch„Å†„Åë.2fÔºâ\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv Ë™≠„ÅøËæº„Åø\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# configÊÉÖÂ†±„ÅÆÁµ±Âêà\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# MarkdownÂá∫Âäõ\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAHWCAYAAACIZjNQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9sklEQVR4nO3deZyN5f/H8dc5s+8ztpmRfd/3nUTWFJEiSUiUqKT6lr4RqbTxaxGipIWUQn0lGUv2fRfGkhDGzmCY9fz+uJrhmMEYM+ee5f18PK7HnLnPfe7zOTN3Ne+u+/5cNofD4UBERERERESylN3qAkRERERERPIChS8REREREREXUPgSERERERFxAYUvERERERERF1D4EhERERERcQGFLxERERERERdQ+BIREREREXEBhS8REREREREXUPgSERERERFxAYUvERGRPK5Xr174+/tbXYaISK6n8CUiIllmypQp2Gw21q9fb3UplurVqxc2my3N4e3tbXV5IiLiIu5WFyAiIpIXeHl58fnnn6fa7ubmZkE1IiJiBYUvERERF3B3d+fRRx+1ugwREbGQLjsUERHLbdq0iXvuuYfAwED8/f1p0aIFq1evdtonPj6eESNGULZsWby9vcmfPz9NmjQhIiIiZZ+oqCh69+5NkSJF8PLyIjw8nPvvv5+///77uu/9wQcfYLPZOHDgQKrnhgwZgqenJ2fOnAFgz549dO7cmbCwMLy9vSlSpAgPP/ww586dy5SfQ/JlmkuXLuXJJ58kf/78BAYG8thjj6XUcLVx48ZRuXJlvLy8KFy4MAMGDODs2bOp9luzZg3t2rUjJCQEPz8/qlWrxkcffZRqv8OHD9OxY0f8/f0pWLAgL774IomJiZny2URERDNfIiJisT///JM777yTwMBA/vOf/+Dh4cFnn31Gs2bNWLJkCfXr1wdg+PDhjBo1iieeeIJ69eoRHR3N+vXr2bhxI61atQKgc+fO/PnnnzzzzDOUKFGC48ePExERwcGDBylRokSa79+lSxf+85//8MMPP/DSSy85PffDDz/QunVrQkJCiIuLo02bNsTGxvLMM88QFhbG4cOHmTNnDmfPniUoKOimn/XkyZOptnl6ehIYGOi0beDAgQQHBzN8+HAiIyMZP348Bw4c4I8//sBms6X8PEaMGEHLli3p379/yn7r1q1jxYoVeHh4ABAREcF9991HeHg4zz33HGFhYezcuZM5c+bw3HPPpbxnYmIibdq0oX79+nzwwQcsWLCA0aNHU7p0afr373/TzyYiIungEBERySJffvmlA3CsW7fuuvt07NjR4enp6di3b1/KtiNHjjgCAgIcTZs2TdlWvXp1x7333nvd45w5c8YBON5///1brrNhw4aO2rVrO21bu3atA3B8/fXXDofD4di0aZMDcMyYMeOWj9+zZ08HkOZo06ZNyn7JP6/atWs74uLiUra/9957DsDx888/OxwOh+P48eMOT09PR+vWrR2JiYkp+40dO9YBOCZPnuxwOByOhIQER8mSJR3Fixd3nDlzxqmmpKSkVPW98cYbTvvUrFkz1c9FREQyTpcdioiIZRITE5k/fz4dO3akVKlSKdvDw8N55JFHWL58OdHR0QAEBwfz559/smfPnjSP5ePjg6enJ3/88Ueal+jdSNeuXdmwYQP79u1L2fb999/j5eXF/fffD5Ays/X7778TExNzS8cH8Pb2JiIiItV45513Uu3br1+/lJkrgP79++Pu7s7cuXMBWLBgAXFxcQwaNAi7/cp/yvv27UtgYCC//vorYC7n3L9/P4MGDSI4ONjpPZJn0K721FNPOX1/55138tdff93yZxURkbQpfImIiGVOnDhBTEwM5cuXT/VcxYoVSUpK4tChQwC88cYbnD17lnLlylG1alVeeukltm7dmrK/l5cX7777Lr/99huhoaE0bdqU9957j6ioqJvW8dBDD2G32/n+++8BcDgczJgxI+U+NICSJUsyePBgPv/8cwoUKECbNm349NNP032/l5ubGy1btkw1atSokWrfsmXLOn3v7+9PeHh4yr1ryfenXftz8/T0pFSpUinPJ4fJKlWq3LQ+b29vChYs6LQtJCTkloOsiIhcn8KXiIjkCE2bNmXfvn1MnjyZKlWq8Pnnn1OrVi2n9u2DBg1i9+7djBo1Cm9vb4YOHUrFihXZtGnTDY9duHBh7rzzTn744QcAVq9ezcGDB+natavTfqNHj2br1q28+uqrXLp0iWeffZbKlSvzzz//ZP4HdjG1vBcRyXoKXyIiYpmCBQvi6+tLZGRkqud27dqF3W6naNGiKdvy5ctH7969+e677zh06BDVqlVj+PDhTq8rXbo0L7zwAvPnz2f79u3ExcUxevTom9bStWtXtmzZQmRkJN9//z2+vr60b98+1X5Vq1bltddeY+nSpSxbtozDhw8zYcKEW//wN3DtpZUXLlzg6NGjKU1DihcvDpDq5xYXF8f+/ftTni9dujQA27dvz9T6REQkYxS+RETEMm5ubrRu3Zqff/7ZqR38sWPHmDZtGk2aNEm57O/UqVNOr/X396dMmTLExsYCEBMTw+XLl532KV26NAEBASn73Ejnzp1xc3Pju+++Y8aMGdx33334+fmlPB8dHU1CQoLTa6pWrYrdbk/X8W/FxIkTiY+PT/l+/PjxJCQkcM899wDQsmVLPD09+fjjj3E4HCn7ffHFF5w7d457770XgFq1alGyZEk+/PDDVC3or36diIi4hlrNi4hIlps8eTLz5s1Ltf25557jzTffJCIigiZNmvD000/j7u7OZ599RmxsLO+9917KvpUqVaJZs2bUrl2bfPnysX79en788UcGDhwIwO7du2nRogVdunShUqVKuLu7M2vWLI4dO8bDDz980xoLFSpE8+bNGTNmDOfPn091yeGiRYsYOHAgDz30EOXKlSMhIYFvvvkGNzc3OnfufNPjJyQk8O2336b5XKdOnZyCXlxcXMpniYyMZNy4cTRp0oQOHToAZsZwyJAhjBgxgrZt29KhQ4eU/erWrZuymLPdbmf8+PG0b9+eGjVq0Lt3b8LDw9m1axd//vknv//++03rFhGRTGRxt0UREcnFklunX28cOnTI4XA4HBs3bnS0adPG4e/v7/D19XU0b97csXLlSqdjvfnmm4569eo5goODHT4+Po4KFSo43nrrrZSW7CdPnnQMGDDAUaFCBYefn58jKCjIUb9+fccPP/yQ7nonTZrkABwBAQGOS5cuOT33119/OR5//HFH6dKlHd7e3o58+fI5mjdv7liwYMFNj3ujVvOAY//+/U4/ryVLljj69evnCAkJcfj7+zu6d+/uOHXqVKrjjh071lGhQgWHh4eHIzQ01NG/f/9ULeUdDodj+fLljlatWjkCAgIcfn5+jmrVqjk++eQTp/r8/PxSve7111936E8FEZHMY3M4dN2BiIhIdjBlyhR69+7NunXrqFOnjtXliIhIJtM9XyIiIiIiIi6g8CUiIiIiIuICCl8iIiIiIiIuoHu+REREREREXEAzXyIiIiIiIi6g8CUiIiIiIuICWmQ5g5KSkjhy5AgBAQHYbDaryxEREREREYs4HA7Onz9P4cKFsduvP7+l8JVBR44coWjRolaXISIiIiIi2cShQ4coUqTIdZ9X+MqggIAAwPyAAwMDLa5GMiI+Pp758+fTunVrPDw8rC5H8gCdc+JKOt/E1XTOiatlp3MuOjqaokWLpmSE61H4yqDkSw0DAwMVvnKo+Ph4fH19CQwMtPwfWMkbdM6JK+l8E1fTOSeulh3PuZvdjqSGGyIiIiIiIi6g8CUiIiIiIuICCl8iIiIiIiIuoHu+RERERCRXcDgcJCQkkJiYaHUp4gLx8fG4u7tz+fLlLP+du7m54e7ufttLTCl8iYiIiEiOFxcXx9GjR4mJibG6FHERh8NBWFgYhw4dcsm6u76+voSHh+Pp6ZnhYyh8iYiIiEiOlpSUxP79+3Fzc6Nw4cJ4enq65I9xsVZSUhIXLlzA39//hgsb3y6Hw0FcXBwnTpxg//79lC1bNsPvp/AlIiIiIjlaXFwcSUlJFC1aFF9fX6vLERdJSkoiLi4Ob2/vLA1fAD4+Pnh4eHDgwIGU98wINdwQERERkVwhq/8Al7wtM84vnaEiIiIiIiIuoPAlIiIiIiLiAgpfIiIiIiK5SIkSJfjwww+tLkPSoPAlIiIiImIBm812wzF8+PAMHXfdunX069fvtmpr1qwZgwYNuq1jSGrqdphLXL4MGWy6IiIiIiIWOHr0aMrj77//nmHDhhEZGZmyzd/fP+Wxw+EgMTERd/eb//lesGDBzC1UMo1mvnK4v/+G9u2hXj1wOKyuRkRERCR7cDjg4kVrRnr/JgsLC0sZQUFB2Gy2lO937dpFQEAAv/32G7Vr18bLy4vly5ezb98+7r//fkJDQ/H396du3bosWLDA6bjXXnZos9n4/PPP6dSpE76+vpQtW5Zffvnltn6+P/30E5UrV8bLy4sSJUowevRop+fHjRtH2bJl8fb2JjQ0lAcffDDluR9//JGqVavi4+ND/vz5admyJRcvXrytenIKzXzlcCEhsHix+Qd96VK46y6rKxIRERGxXkwMXDVx5FIXLoCfX+Yc65VXXuGDDz6gVKlShISEcOjQIdq1a8dbb72Fl5cXX3/9Ne3btycyMpJixYpd9zgjRozgvffe4/333+eTTz6he/fuHDhwgHz58t1yTRs2bKBLly4MHz6crl27snLlSp5++mny589Pr169WL9+Pc8++yzffPMNjRo14vTp0yxbtgwws33dunXjvffeo1OnTpw/f55ly5bhyCOzCApfOVxQEDz6KHz2GYwbp/AlIiIikpu88cYbtGrVKuX7fPnyUb169ZTvR44cyaxZs/jll18YOHDgdY/Tq1cvunXrBsDbb7/Nxx9/zNq1a2nbtu0t1zRmzBhatGjB0KFDAShXrhw7duzg/fffp1evXhw8eBA/Pz/uu+8+AgICKF68ODVr1gRM+EpISOCBBx6gePHiAFStWvWWa8ipdNlhLtC/v/k6cyZcdemwiIiISJ7l62tmoKwYvr6Z9znq1Knj9P2FCxd48cUXqVixIsHBwfj7+7Nz504OHjx4w+NUq1Yt5bGfnx+BgYEcP348QzXt3LmTxo0bO21r3Lgxe/bsITExkVatWlG8eHFKlSpFjx49mDp1KjExMQBUr16dFi1aULVqVR566CEmTZrEmTNnMlRHTqTwlQtUrw6NG0NCAnz+udXViIiIiFjPZjOX/lkxbLbM+xx+11y/+OKLLzJr1izefvttli1bxubNm6latSpxcXE3PI6Hh8c1Px8bSUlJmVfoVQICAti4cSPfffcd4eHhDBs2jOrVq3P27Fnc3NyIiIjgt99+o1KlSnzyySeUL1+e/fv3Z0kt2Y3CVy7x9NPm62efmRAmIiIiIrnPihUr6NWrF506daJq1aqEhYXx999/u7SGihUrsmLFilR1lStXDjc3NwDc3d1p2bIl7733Hlu3buXvv/9m0aJFgAl+jRs3ZsSIEWzatAlPT09mzZrl0s9gFd3zlUt07gyDBsHhw/DLL/DAA1ZXJCIiIiKZrWzZssycOZP27dtjs9kYOnRols1gnThxgs2bNzttCw8P54UXXqBu3bqMHDmSrl27smrVKsaOHcu4ceMAmDNnDn/99RdNmzYlJCSEuXPnkpSURPny5VmzZg0LFy6kdevWFCpUiDVr1nDixAkqVqyYJZ8hu9HMVy7h5QV9+5rH/573IiIiIpLLjBkzhpCQEBo1akT79u1p06YNtWrVypL3mjZtGjVr1nQakyZNolatWvzwww9Mnz6dKlWqMGzYMN544w169eoFQHBwMDNnzuTuu++mYsWKTJgwge+++47KlSsTGBjI0qVLadeuHeXKleO1115j9OjR3HPPPVnyGbIdRzYwduxYR/HixR1eXl6OevXqOdasWXPD/X/44QdH+fLlHV5eXo4qVao4fv31V6fnX3/9dUf58uUdvr6+juDgYEeLFi0cq1evdtqnePHiDsBpjBo1Kt01nzt3zgE4zp07l/4PmsX+/tvhsNsdDnA4du60uprsLy4uzjF79mxHXFyc1aVIHqFzTlxJ55u4mpXn3KVLlxw7duxwXLp0yeXvLdZJTEx0nDlzxpGYmOiS97vReZbebGD5zNf333/P4MGDef3119m4cSPVq1enTZs21+2+snLlSrp160afPn3YtGkTHTt2pGPHjmzfvj1ln3LlyjF27Fi2bdvG8uXLKVGiBK1bt+bEiRNOx3rjjTc4evRoynjmmWey9LNmteLF4b77zOMJE6ytRUREREREnFkevsaMGUPfvn3p3bs3lSpVYsKECfj6+jJ58uQ09//oo49o27YtL730EhUrVmTkyJHUqlWLsWPHpuzzyCOP0LJlS0qVKkXlypUZM2YM0dHRbN261elYAQEBTiuLX9tNJidKbrwxZYpZeFlERERERLIHSxtuxMXFsWHDBoYMGZKyzW6307JlS1atWpXma1atWsXgwYOdtrVp04bZs2df9z0mTpxIUFCQ04J0AO+88w4jR46kWLFiPPLIIzz//PO4u6f9I4mNjSU2Njbl++joaADi4+OJj4+/6Wd1lWbNoHRpd/bts/Httwk8/njeWC08I5J/b9np9ye5m845cSWdb+JqVp5z8fHxOBwOkpKSsqz5hGQ/Docj5asrfu9JSUk4HA7i4+NTujomS+95b2n4OnnyJImJiYSGhjptDw0NZdeuXWm+JioqKs39o6KinLbNmTOHhx9+mJiYGMLDw4mIiKBAgQIpzz/77LPUqlWLfPnysXLlSoYMGcLRo0cZM2ZMmu87atQoRowYkWr7/Pnz8c3MlfQywZ13lmbfviq8++4FQkOXZOpaE7lRRESE1SVIHqNzTlxJ55u4mhXnnLu7O2FhYVy4cOGm611J7nP+/HmXvE9cXByXLl1i6dKlJFyztlPyItI3k2tbzTdv3pzNmzdz8uRJJk2aRJcuXVizZg2FChUCcJo9q1atGp6enjz55JOMGjUKLy+vVMcbMmSI02uio6MpWrQorVu3JjAwMOs/0C1o0ACmT3ewf38w+fPfS4MGmv1KS3x8PBEREbRq1SrVwoMiWUHnnLiSzjdxNSvPucuXL3Po0CH8/f3x9vZ26XuLdRwOB+fPnycgIACbC2YbLl++jI+PD02bNk11niVfFXczloavAgUK4ObmxrFjx5y2Hzt2jLCwsDRfExYWlq79/fz8KFOmDGXKlKFBgwaULVuWL774wukSx6vVr1+fhIQE/v77b8qXL5/qeS8vrzRDmYeHR7b7j1poKHTrBl9+CRMnunPnnVZXlL1lx9+h5G4658SVdL6Jq1lxziUmJmKz2bDb7djtlrc0EBdJvtQw+Xef1ex2OzabLc1zPL3nvKVnp6enJ7Vr12bhwoUp25KSkli4cCENGzZM8zUNGzZ02h/M9Pb19r/6uFffs3WtzZs3Y7fbU2bGcrrkxhs//ADXNHkUERERERELWH7Z4eDBg+nZsyd16tShXr16fPjhh1y8eJHevXsD8Nhjj3HHHXcwatQoAJ577jnuuusuRo8ezb333sv06dNZv349EydOBODixYu89dZbdOjQgfDwcE6ePMmnn37K4cOHeeihhwDTtGPNmjU0b96cgIAAVq1axfPPP8+jjz5KSEiINT+ITFanDtStC+vWweTJ8PLLVlckIiIiIpK3WR6+unbtyokTJxg2bBhRUVHUqFGDefPmpTTVOHjwoNM0YqNGjZg2bRqvvfYar776KmXLlmX27NlUqVIFADc3N3bt2sVXX33FyZMnyZ8/P3Xr1mXZsmVUrlwZMJcQTp8+neHDhxMbG0vJkiV5/vnnU3VRzOmefhp694bx4+HFF+GapiwiIiIiIuJClocvgIEDBzJw4MA0n/vjjz9SbXvooYdSZrGu5e3tzcyZM2/4frVq1WL16tW3XGdO07UrvPACHDgAv/12ZQFmEREREck9mjVrRo0aNfjwww8BKFGiBIMGDWLQoEHXfY3NZmPWrFl07Njxtt47s46TV+iOxFzMxwcef9w8HjfO2lpERERExFn79u1p27Ztms8tW7YMm83G1q1bb/m469ato1+/frdbnpPhw4dTo0aNVNuPHj3KPffck6nvda0pU6YQHBycpe/hKgpfudxTT5mv8+bBvn3W1iIiIiIiV/Tp04eIiAj++eefVM99+eWX1KlTh2rVqt3ycQsWLOiydWjDwsLS7AguaVP4yuVKl4a2bcHhgM8+s7oaERERERdxOCDhojXDkb41Vu+77z4KFizIlClTnLZfuHCBGTNm0KdPH06dOkW3bt2444478PX1pWrVqnz33Xc3PG6JEiVSLkEE2LNnT8raVJUqVUpzIeyXX36ZcuXK4evrS6lSpRg6dCjx8fGAmXkaMWIEW7ZswWazYbPZUmq22WzMnj075Tjbtm3j7rvvxsfHh/z589OvXz8uXLiQ8nyvXr3o2LEjH3zwAeHh4eTPn58BAwakvFdGHDx4kPvvvx9/f38CAwPp0qWL09JUW7ZsSWm0FxgYSO3atVm/fj0ABw4coH379oSEhODn50flypWZO3duhmu5mWxxz5dkraefNjNfX3wBI0aYyxFFREREcrXEGPjB35r37nIB3P1uupu7uzuPPfYYU6ZM4b///W/KQsEzZswgMTGRbt26ceHCBWrXrs3LL79MYGAgv/76Kz169KB06dLUq1fvpu+RlJTEAw88QGhoKGvWrOHcuXNp3gsWEBDAlClTKFy4MNu2baNv374EBATwn//8h65du7J9+3bmzZvHggULAAgKCkp1jIsXL9KmTRsaNmzIunXrOH78OE888QQDBw50CpiLFy8mPDycxYsXs3fvXrp27UqNGjXo27fvTT9PWp+vU6dO+Pv7s2TJEhISEhgwYABdu3ZN6R3RvXt3atasyfjx43Fzc2Pz5s0p63INGDCAuLg4li5dip+fHzt27MDfP+vOG4WvPKBdOyhWDA4eNOt+9expdUUiIiIiAvD444/z/vvvs2TJEpo1awaYSw47d+5MUFAQQUFBvPjiiyn7P/PMM/z+++/88MMP6QpfCxYsYNeuXfz+++8ULlwYgLfffjvVfVqvvfZayuMSJUrw4osvMn36dP7zn//g4+ODv78/7u7uhIWFXfe9pk2bxuXLl/n666/x8zPhc+zYsbRv35533303pZt5SEgIY8eOxc3NjQoVKnDvvfeycOHCDIWvJUuWsG3bNvbv30/RokUB+Prrr6lcuTLr1q2jbt26HDx4kJdeeokKFSoAULZs2ZTXHzx4kM6dO1O1alUASpUqdcs13AqFrzzAzc3c+/Xqq6bxhsKXiIiI5HpuvmYGyqr3TqcKFSrQqFEjJk+eTLNmzdi7dy/Lli3jjTfeACAxMZG3336bH374gcOHDxMXF0dsbGy67+nauXMnRYsWTQleAA0bNky13/fff8/HH3/Mvn37uHDhAgkJCQQGBqb7cyS/V/Xq1VOCF0Djxo1JSkoiMjIyJXxVrlwZt6vWQAoPD2fbtm239F7Jdu/eTdGiRVOCF0ClSpUIDg5m586d1K1bl8GDB/PEE0/wzTff0LJlSx566CFKly4NwLPPPkv//v2ZP38+LVu2pHPnzhm6zy69dM9XHtGnD3h6wtq18O8lriIiIiK5l81mLv2zYvx7+WB69enTh59++onz58/z5ZdfUrp0ae666y4A3n//fT766CNefvllFi9ezObNm2nTpg1xcXGZ9qNatWoV3bt3p127dsyZM4dNmzbx3//+N1Pf42rJl/wls9lsJCUlZcl7genU+Oeff3LvvfeyaNEiKlWqxKxZswB44okn+Ouvv+jRowfbtm2jTp06fPLJJ1lWi8JXHlGoECQvjTZ+vLW1iIiIiMgVXbp0wW63M23aNL7++msef/zxlPu/VqxYwf3338+jjz5K9erVKVWqFLt37073sStWrMihQ4c4evRoyrZr17tduXIlxYsX57///S916tShbNmyHDhwwGkfT09PEhMTb/peW7Zs4eLFiynbVqxYgd1up3z58umu+VaUK1eOQ4cOcejQoZRtO3bs4OzZs1SqVMlpv+eff5758+fzwAMP8OWXX6Y8V7RoUZ566ilmzpzJCy+8wKRJk7KkVlD4ylOeftp8nTYNzpyxthYRERERMfz9/enatStDhgzh6NGj9OrVK+W5smXLEhERwcqVK9m5cydPPvmkUye/m2nZsiXlypWjZ8+ebNmyhWXLlvHf//7XaZ+yZcty8OBBpk+fzr59+/j4449TZoaSlShRgv3797N582ZOnjxJbGxsqvfq3r073t7e9OzZk+3bt7N48WKeeeYZevTokXLJYUYlJiayefNmp7Fz506aNWtG1apV6d69Oxs3bmTt2rU89thj3HXXXdSpU4dLly4xcOBA/vjjDw4cOMCKFStYt24dFStWBGDQoEH8/vvv7N+/n40bN7J48eKU57KCwlce0rAhVK8Oly/DNR1NRURERMRCffr04cyZM7Rp08bp/qzXXnuNWrVq0aZNG5o1a0ZYWBgdO3ZM93HtdjuzZs3i0qVL1KtXjyeeeIK33nrLaZ8OHTrw/PPPM3DgQGrUqMHKlSsZOnSo0z6dO3embdu2NG/enIIFC6bZ7t7X15fff/+d06dPU7duXR588EFatGjB2LFjb+2HkYYLFy5Qs2ZNp3H//fdjs9mYNWsWISEhNG3alJYtW1KqVCm+//57ANzc3Dh16hSPPfYY5cqVo0uXLtxzzz2MGDECMKFuwIABVKxYkbZt21KuXDnGjRt32/Vej83hSOdCBOIkOjqaoKAgzp07d8s3I1pp4kR48kkoUwYiI8Geh+N3fHw8c+fOpV27dqmuPRbJCjrnxJV0vomrWXnOXb58mf3791OyZEm8vb1d+t5inaSkJKKjowkMDMTugj9qb3SepTcb5OE/vfOmRx6BwEDYuxf+XaZBRERERERcQOErj/H3h+TLiLNwRlVERERERK6h8JUH9e9vvv7vf2bhZRERERERyXoKX3lQhQpw992QlGTuARMRERERkayn8JVHJbednzQJsmj9PBERERGXUh85yUqZcX4pfOVRHTpA4cJw/Dj89JPV1YiIiIhkXHJ3xZiYGIsrkdws+fy6nW6e7plVjOQsHh7Qrx8MH24ab3TrZnVFIiIiIhnj5uZGcHAwx48fB8x6UzabzeKqJKslJSURFxfH5cuXs7TVvMPhICYmhuPHjxMcHIybm1uGj6XwlYf17QtvvgnLl8PWrVCtmtUViYiIiGRMWFgYQEoAk9zP4XBw6dIlfHx8XBK2g4ODU86zjFL4ysMKF4ZOnWDGDBg/3gwRERGRnMhmsxEeHk6hQoWIj4+3uhxxgfj4eJYuXUrTpk2zfGFvDw+P25rxSqbwlcc9/bQJX998A+++axZgFhEREcmp3NzcMuWPZMn+3NzcSEhIwNvbO8vDV2ZRw4087q67oGJFuHjRBDAREREREckaCl95nM12pe38p5+COrSKiIiIiGQNhS+hRw/w84OdO2HJEqurERERERHJnRS+hKAgE8DAtJ0XEREREZHMp/AlAPTvb77OmgVHjlhbi4iIiIhIbqTwJYBZ46tJE0hIgM8/t7oaEREREZHcR+FLUiQ33vjsM9DyGCIiIiIimUvhS1I88AAUKmQuO/zlF6urERERERHJXRS+JIWXFzzxhHmsxhsiIiIiIplL4UucPPkk2O2waJFpPS8iIiIiIplD4UucFCsG7dubxxMmWFuLiIiIiEhuovAlqSQ33pgyBS5etLQUEREREZFcQ+FLUmnZEsqUgehomDrV6mpERERERHIHhS9JxW6/sujyp5+Cw2FtPSIiIiIiuYHCl6SpVy/w9oatW2HVKqurERERERHJ+RS+JE358sEjj5jHajsvIiIiInL7FL7kupIbb8yYAcePW1uLiIiIiEhOp/Al11W7NtSrB3FxMHmy1dWIiIiIiORsCl9yQ8mzXxMmQGKitbWIiIiIiORkCl9yQ126mPu/DhyAuXOtrkZEREREJOdS+JIb8vGBxx83j9V4Q0REREQk4xS+5KaeegpsNpg3D/bts7oaEREREZGcSeFLbqp0aWjb1jyeMMHaWkREREREciqFL0mX5MYbkyfDpUvW1iIiIiIikhMpfEm63HMPFC8Op0/D999bXY2IiIiISM6j8CXp4uZm7v0CNd4QEREREckIhS9Jtz59wNMT1q0zQ0RERERE0k/hS9KtYEGz7hfA+PHW1iIiIiIiktMofMktSW688d135v4vERERERFJH4UvuSUNGkCNGnD5MkyZYnU1IiIiIiI5h8KX3BKb7crs17hxkJRkbT0iIiIiIjmFwpfcskcegcBA2LcPIiKsrkZEREREJGdQ+JJb5ucHvXqZx2o7LyIiIiKSPgpfkiHJlx7OmQMHDlhbi4iIiIhITqDwJRlSvjy0aGHu+Zo40epqRERERESyP4UvybDk2a/PP4fYWGtrERERERHJ7hS+JMM6dIDCheH4cfjpJ6urERERERHJ3hS+JMPc3eHJJ81jNd4QEREREbkxhS+5LX37mhC2YgVs2WJ1NSIiIiIi2ZfCl9yW8HB44AHzePx4a2sREREREcnOFL7ktiU33vj2Wzh3ztpaRERERESyK4UvuW1Nm0KlSnDxInz9tdXViIiIiIhkT9kifH366aeUKFECb29v6tevz9q1a2+4/4wZM6hQoQLe3t5UrVqVuXPnOj0/fPhwKlSogJ+fHyEhIbRs2ZI1a9Y47XP69Gm6d+9OYGAgwcHB9OnThwsXLmT6Z8sLbLYrs1/jxoHDYW09IiIiIiLZkeXh6/vvv2fw4MG8/vrrbNy4kerVq9OmTRuOHz+e5v4rV66kW7du9OnTh02bNtGxY0c6duzI9u3bU/YpV64cY8eOZdu2bSxfvpwSJUrQunVrTpw4kbJP9+7d+fPPP4mIiGDOnDksXbqUfv36Zfnnza169AA/P9i1C/74w+pqRERERESyH8vD15gxY+jbty+9e/emUqVKTJgwAV9fXyZPnpzm/h999BFt27blpZdeomLFiowcOZJatWoxduzYlH0eeeQRWrZsSalSpahcuTJjxowhOjqarVu3ArBz507mzZvH559/Tv369WnSpAmffPIJ06dP58iRIy753LlNYKAJYKC28yIiIiIiaXG38s3j4uLYsGEDQ4YMSdlmt9tp2bIlq1atSvM1q1atYvDgwU7b2rRpw+zZs6/7HhMnTiQoKIjq1aunHCM4OJg6deqk7NeyZUvsdjtr1qyhU6dOqY4TGxtLbGxsyvfR0dEAxMfHEx8fn74PnMv17QsTJngwa5aDAwcSKFzY6opuLPn3pt+fuIrOOXElnW/iajrnxNWy0zmX3hosDV8nT54kMTGR0NBQp+2hoaHs2rUrzddERUWluX9UVJTTtjlz5vDwww8TExNDeHg4ERERFChQIOUYhQoVctrf3d2dfPnypTpOslGjRjFixIhU2+fPn4+vr++NP2geUqlSY3bsKMArr+zj4YcjrS4nXSIiIqwuQfIYnXPiSjrfxNV0zomrZYdzLiYmJl37WRq+slLz5s3ZvHkzJ0+eZNKkSXTp0oU1a9akCl3pNWTIEKcZt+joaIoWLUrr1q0JDAzMrLJzvPPnbfToAUuWlOeLL0rj4WF1RdcXHx9PREQErVq1wiM7Fyq5hs45cSWdb+JqOufE1bLTOZd8VdzNWBq+ChQogJubG8eOHXPafuzYMcLCwtJ8TVhYWLr29/Pzo0yZMpQpU4YGDRpQtmxZvvjiC4YMGUJYWFiqhh4JCQmcPn36uu/r5eWFl5dXqu0eHh6W/7Kzky5d4IUX4OhRG3PnevDgg1ZXdHP6HYqr6ZwTV9L5Jq6mc05cLTucc+l9f0sbbnh6elK7dm0WLlyYsi0pKYmFCxfSsGHDNF/TsGFDp/3BTDVeb/+rj5t8z1bDhg05e/YsGzZsSHl+0aJFJCUlUb9+/Yx+HAE8Pc29X6DGGyIiIiIiV7O82+HgwYOZNGkSX331FTt37qR///5cvHiR3r17A/DYY485NeR47rnnmDdvHqNHj2bXrl0MHz6c9evXM3DgQAAuXrzIq6++yurVqzlw4AAbNmzg8ccf5/Dhwzz00EMAVKxYkbZt29K3b1/Wrl3LihUrGDhwIA8//DCFs3uXiBzgySfBbofFi2HnTqurERERERHJHiwPX127duWDDz5g2LBh1KhRg82bNzNv3ryUphoHDx7k6NGjKfs3atSIadOmMXHiRKpXr86PP/7I7NmzqVKlCgBubm7s2rWLzp07U65cOdq3b8+pU6dYtmwZlStXTjnO1KlTqVChAi1atKBdu3Y0adKEiRMnuvbD51JFi0KHDubx+PHW1iIiIiIikl1ki4YbAwcOTJm5utYfaazY+9BDD6XMYl3L29ubmTNn3vQ98+XLx7Rp026pTkm/p5+G2bPhq6/g7bfB39/qikRERERErGX5zJfkTi1aQNmyEB0NU6daXY2IiIiIiPUUviRL2O3Qv795PG4cOBzW1iMiIiIiYjWFL8kyvXqBjw9s3QorV1pdjYiIiIiItRS+JMuEhMAjj5jHajsvIiIiInmdwpdkqaefNl9nzIBr1rUWEREREclTFL4kS9WqBfXrQ3w8fPGF1dWIiIiIiFhH4UuyXPLs14QJkJhobS0iIiIiIlZR+JIs16UL5MsHBw/Cr79aXY2IiIiIiDUUviTLeXtDnz7msRpviIiIiEhepfAlLvHUU2Czwe+/w969VlcjIiIiIuJ6Cl/iEqVKwT33mMcTJlhbi4iIiIiIFRS+xGWSG29MngyXLllbi4iIiIiIqyl8icu0bQslSsCZMzB9utXViIiIiIi4lsKXuIybm7n3C9R4Q0RERETyHoUvcanHHwdPT1i/Htats7oaERERERHXUfgSlypYELp2NY81+yUiIiIieYnCl7hccuON6dPh1ClraxERERERcRWFL3G5+vWhZk24fBmmTLG6GhERERER11D4Epez2a7Mfo0fD0lJ1tYjIiIiIuIKCl9iiW7dICgI9u2D+fOtrkZEREREJOspfIkl/PygVy/zWI03RERERCQvUPgSy/Tvb77OmQN//21pKSIiIiIiWU7hSyxTvjy0bAkOB0ycaHU1IiIiIiJZS+FLLJXceOPzzyE21tpaRERERESyksKXWKp9e7jjDjhxAn780epqRERERESyjsKXWMrdHZ580jxW4w0RERERyc0UvsRyTzxhQtjKlbB5s9XViIiIiIhkDYUvsVx4OHTubB6PH29tLSIiIiIiWUXhS7KF5MYb334L585ZW4uIiIiISFZQ+JJs4c47oXJliImBr76yuhoRERERkcyn8CXZgs12ZfZr3Diz9peIiIiISG6i8CXZxqOPgr8/REbC4sVWVyMiIiIikrkUviTbCAyEHj3MY7WdFxEREZHcRuFLspXkSw9nz4bDhy0tRUREREQkUyl8SbZSpQo0bQqJiTBpktXViIiIiIhkHoUvyXaSZ78mToT4eGtrERERERHJLApfku106gShoXD0qLn8UEREREQkN1D4kmzH0xP69jWP1XhDRERERHILhS/Jlvr1A7sd/vgDduywuhoRERERkdun8CXZUtGicP/95vH48dbWIiIiIiKSGRS+JNtKbrzx1Vdw4YK1tYiIiIiI3C6FL8m27r4bypWD8+fh22+trkZERERE5PYofEm2ZbdD//7m8bhx4HBYW4+IiIiIyO1Q+JJsrWdP8PGBbdtgxQqrqxERERERyTiFL8nWQkLgkUfMY7WdFxEREZGcTOFLsr3kxhs//gjHjllbi4iIiIhIRil8SbZXqxY0aADx8fDFF1ZXIyIiIiKSMQpfkiMkz35NmAAJCdbWIiIiIiKSEQpfkiM89BDkzw+HDsGvv1pdjYiIiIjIrVP4khzB2xv69DGP1XhDRERERHIihS/JMZ56Cmw2mD8f9uyxuhoRERERkVuj8CU5RsmS0K6deTxhgrW1iIiIiIjcKoUvyVGSG298+SXExFhbi4iIiIjIrVD4khylTRszA3bmDEyfbnU1IiIiIiLpp/AlOYqbm7n3C+DTT8HhsLYeEREREZH0UviSHOfxx8HLCzZuhHXrrK5GRERERCR9FL4kxylQALp0MY/Vdl5EREREcgqFL8mRBgwwX6dPh1OnrK1FRERERCQ9FL4kR6pXD2rVgthYmDzZ6mpERERERG5O4UtyJJvtStv58eMhKcnaekREREREbkbhS3Ksbt0gKAj274fff7e6GhERERGRG1P4khzL1xd69zaP1XhDRERERLI7hS/J0fr3N19//RX+/tvSUkREREREbihbhK9PP/2UEiVK4O3tTf369Vm7du0N958xYwYVKlTA29ubqlWrMnfu3JTn4uPjefnll6latSp+fn4ULlyYxx57jCNHjjgdo0SJEthsNqfxzjvvZMnnk6xTrhy0amUWW/7sM6urERERERG5PsvD1/fff8/gwYN5/fXX2bhxI9WrV6dNmzYcP348zf1XrlxJt27d6NOnD5s2baJjx4507NiR7du3AxATE8PGjRsZOnQoGzduZObMmURGRtKhQ4dUx3rjjTc4evRoynjmmWey9LNK1khuvPH553D5srW1iIiIiIhcj+Xha8yYMfTt25fevXtTqVIlJkyYgK+vL5Ov0z/8o48+om3btrz00ktUrFiRkSNHUqtWLcaOHQtAUFAQERERdOnShfLly9OgQQPGjh3Lhg0bOHjwoNOxAgICCAsLSxl+fn5Z/nkl8913HxQpAidPwo8/Wl2NiIiIiEja3K1887i4ODZs2MCQIUNSttntdlq2bMmqVavSfM2qVasYPHiw07Y2bdowe/bs677PuXPnsNlsBAcHO21/5513GDlyJMWKFeORRx7h+eefx9097R9JbGwssbGxKd9HR0cD5jLH+Pj4G31McYEnnrAzfLgbn36aRNeuiel6TfLvTb8/cRWdc+JKOt/E1XTOiatlp3MuvTVYGr5OnjxJYmIioaGhTttDQ0PZtWtXmq+JiopKc/+oqKg09798+TIvv/wy3bp1IzAwMGX7s88+S61atciXLx8rV65kyJAhHD16lDFjxqR5nFGjRjFixIhU2+fPn4+vr+8NP6dkveLFvXBza83q1XbGjl1KqVLn0v3aiIiILKxMJDWdc+JKOt/E1XTOiatlh3MuJiYmXftZGr6yWnx8PF26dMHhcDB+/Hin566ePatWrRqenp48+eSTjBo1Ci8vr1THGjJkiNNroqOjKVq0KK1bt3YKdWKduXNhxgz488+mDBx489mv+Ph4IiIiaNWqFR4eHi6oUPI6nXPiSjrfxNV0zomrZadzLvmquJuxNHwVKFAANzc3jh075rT92LFjhIWFpfmasLCwdO2fHLwOHDjAokWLbhqQ6tevT0JCAn///Tfly5dP9byXl1eaoczDw8PyX7YYzzxjwtd339n54AM711xlel36HYqr6ZwTV9L5Jq6mc05cLTucc+l9f0sbbnh6elK7dm0WLlyYsi0pKYmFCxfSsGHDNF/TsGFDp/3BTDVevX9y8NqzZw8LFiwgf/78N61l8+bN2O12ChUqlMFPI1Zr0gSqVIGYGPjqK6urERERERFxZnm3w8GDBzNp0iS++uordu7cSf/+/bl48SK9e/cG4LHHHnNqyPHcc88xb948Ro8eza5duxg+fDjr169n4MCBgAleDz74IOvXr2fq1KkkJiYSFRVFVFQUcXFxgGna8eGHH7Jlyxb++usvpk6dyvPPP8+jjz5KSEiI638ItyspERIuWV2F5Wy2K23nx40za3+JiIiIiGQXGbrs8NChQ9hsNooUKQLA2rVrmTZtGpUqVaJfv363dKyuXbty4sQJhg0bRlRUFDVq1GDevHkpTTUOHjyI3X4lIzZq1Ihp06bx2muv8eqrr1K2bFlmz55NlSpVADh8+DC//PILADVq1HB6r8WLF9OsWTO8vLyYPn06w4cPJzY2lpIlS/L888+n6qKYIyRehpWPmq9NZ4M9V9/Gd1OPPgr/+Q/s3g2LFkGLFlZXJCIiIiJiZOgv9UceeYR+/frRo0cPoqKiaNWqFZUrV2bq1KlERUUxbNiwWzrewIEDU2aurvXHH3+k2vbQQw/x0EMPpbl/iRIlcNxkyqNWrVqsXr36lmrMts7thCO/mvC19kmo/7mZAsqjAgLgscfMzNe4cQpfIiIiIpJ9ZOiyw+3bt1OvXj0AfvjhB6pUqcLKlSuZOnUqU6ZMycz65Gby1YTG34PNDn9Nhm2vW12R5ZIvPfz5Z/jnH2trERERERFJlqHwFR8fn9L5b8GCBXTo0AGAChUqcPTo0cyrTtKnSAeoO8E83j4S9oy/8f65XOXKcNddkJgIkyZZXY2IiIiIiJGh8FW5cmUmTJjAsmXLiIiIoG3btgAcOXIkXZ0FJQuU6QtVh5vH6wbAoVmWlmO15NmviRPh3z4rIiIiIiKWylD4evfdd/nss89o1qwZ3bp1o3r16gD88ssvKZcjigWqDIPSfQEHrOgGx5dbXZFlOnaEsDCIioLZs62uRkREREQkg+GrWbNmnDx5kpMnTzJ58uSU7f369WPChAmZVpzcIpsN6o6DOzpAUiwsaQ9n/7S6Kkt4ekLfvubxuHHW1iIiIiIiAhkMX5cuXSI2NjZlTawDBw7w4YcfEhkZqUWKrWZ3h8bfQYFGEH8W/mgLMXmz60S/fuDmBkuWwJ95M4OKiIiISDaSofB1//338/XXXwNw9uxZ6tevz+jRo+nYsSPjx+ftZg/Zgrsv3PU/CKxggtfithB3xuqqXK5IEfi3Fww6LUVERETEahkKXxs3buTOO+8E4McffyQ0NJQDBw7w9ddf8/HHH2dqgZJBXvmg+TzwKQzn/oQl95u1wPKYAQPM16+/hvPnra1FRERERPK2DIWvmJgYAgICAJg/fz4PPPAAdrudBg0acODAgUwtUG6DX3ETwDyC4MQyWNkdkhKtrsql7r4bypc3wevbb62uRkRERETysgyFrzJlyjB79mwOHTrE77//TuvWrQE4fvw4gYGBmVqg3KbgqtB0Ntg94dBM2PAsOBxWV+UyNhv0728ejxuXpz66iIiIiGQzGQpfw4YN48UXX6REiRLUq1ePhg0bAmYWrGbNmplaoGSC0GbQ6FvABnvGwY5RVlfkUj17go8PbN8Oy/Nu930RERERsViGwteDDz7IwYMHWb9+Pb///nvK9hYtWvB///d/mVacZKJiD0Htj8zjLf+FfV9aW48LBQdD9+7msdrOi4iIiIhVMhS+AMLCwqhZsyZHjhzhn39MK/N69epRoUKFTCtOMln5Z6DSK+bx2r5w+Fdr63Ghp582X3/6ySy8LCIiIiLiahkKX0lJSbzxxhsEBQVRvHhxihcvTnBwMCNHjiQpKSmza5TMVP1tKPkYOBJheRc4ucbqilyiZk1o2BDi4+Hzz62uRkRERETyogyFr//+97+MHTuWd955h02bNrFp0ybefvttPvnkE4YOHZrZNUpmstmg/ucQ3hYSY2DJvRC92+qqXCJ59uuzzyAhwdpaRERERCTvyVD4+uqrr/j888/p378/1apVo1q1ajz99NNMmjSJKVOmZHKJkunsHtBkBuSrA7GnYHEbuJT7r8V78EEoUAD++QfmzLG6GhERERHJazIUvk6fPp3mvV0VKlTg9OnTt12UuICHPzT7FfzLwMW/4Y97ID7a6qqylLc39OljHqvxhoiIiIi4WobCV/Xq1Rk7dmyq7WPHjqVatWq3XZS4iHchswizdyE4sxmWPgCJcVZXlaWefNJceRkRAbvzxtWWIiIiIpJNuGfkRe+99x733nsvCxYsSFnja9WqVRw6dIi5c+dmaoGSxQJKQ7O5sKAZHFsIq3uZNcFsGW6Ema2VLAnt2sGvv8KkSXaaN7e6IhERERHJKzL0F/Zdd93F7t276dSpE2fPnuXs2bM88MAD/Pnnn3zzzTeZXaNktXy14c6ZYHOHA9/BppesrihLDRhgvn71lZ3YWDdrixERERGRPCNDM18AhQsX5q233nLatmXLFr744gsmTpx424WJi4W3ggZfwqoesGsM+BSGii9YXVWWaNPGzIDt329j6dI76NTJ6opEREREJC/IndeWScaUfBRqvGceb3oR/p5mbT1ZxG6H/v3N499+K4nDYW09IiIiIpI3KHyJs4ovQvlB5vHqXhC1wMpqskzv3uDl5eCvv4IZPtzO5ctWVyQiIiIiuZ3Clziz2aDWaCjWFZLiYWknOL3J6qoyXYECMGBAEgCjRrlRvTosXGhxUSIiIiKSq93SPV8PPPDADZ8/e/bs7dQi2YXNDg2/gtjjcGyxWQOs9UrwL2V1ZZlq1Kgk7PaNfPttHXbvttGyJXTvDqNHQ2io1dWJiIiISG5zSzNfQUFBNxzFixfnsccey6paxZXcvODOWRBcHS4fg0Vt4PIJq6vKVDYbNGlyhG3bEhgwwHw/dSpUqACffQZJSVZXKCIiIiK5yS3NfH355ZdZVYdkR55B0Pw3mN8QLuyFP+6FFovAw9/qyjJVUBCMHQs9e5pFmDdtgqeegilTTAjTuuEiIiIikhl0z5fcmE84NP8dvPLD6XWwvIu5FywXqlsX1q6FDz8Ef39YvRpq1YKXXoKLF62uTkRERERyOoUvubnA8nDXHHDzgaO/wdp+5Nb+7O7u8NxzsHMnPPAAJCbCBx9ApUrwyy9WVyciIiIiOZnCl6RPgQbQ5AewucFfU2Dra1ZXlKWKFIGffoL//Q+KF4eDB+H++6FjRzh0yOrqRERERCQnUviS9LvjPqj3mXn859sQOdbaelzgvvvgzz/h5ZfNrNjPP0PFijBmDCQkWF2diIiIiOQkCl9ya0r3gapvmMcbnoWDP1pbjwv4+cE778DGjdC4sbn/64UXoE4dc1+YiIiIiEh6KHzJravyGpR5CnDAykfh+FKrK3KJqlVh6VKYNAlCQmDLFmjUCPr3By1xJyIiIiI3o/Alt85mgzpjoUhHSIqFJR3g7Darq3IJux2eeAIiI01reocDJkwwa4NNm5Zr+5CIiIiISCZQ+JKMsbtBo2lQsDHEn4PF98DFg1ZX5TIFC5p1wBYvhvLl4dgx6N4dWreGPXusrk5EREREsiOFL8k4dx9o+gsEVYJLh2FxW4g9bXVVLtWsmbn8cORI8PKCBQvM5YlvvAGxsVZXJyIiIiLZicKX3B6vfNBsHvjcAdE7YWkHSLhkdVUu5eUFr70G27dDq1YmdL3+OlSrBosWWV2diIiIiGQXCl9y+/yKQvN54BEMJ1bAykcgKdHqqlyuTBn4/Xf47jsIDYXdu6FFC+jRA44ft7o6EREREbGawpdkjuAqcNfPYPeCf2bD+gF5svuEzQYPPwy7dsHTT5vvv/3WNOSYNAmSkqyuUERERESsovAlmadQU2g8DbDB3s9g+5tWV2SZ4GD49FOzDliNGnDmDPTrB02awLa80RhSRERERK6h8CWZq+gDpg09wLZhsPdza+uxWL16sG4djBljFmtetQpq1oT//Mcs1iwiIiIieYfCl2S+ck9D5f+ax+uehH/+Z209FnN3h+efh5074YEHIDER3n8fKlWC/+XtH42IiIhInqLwJVmj2kgo1RscSbCiK5xYZXVFlitaFH76yQSuYsXg4EHo0MEEskOHrK5ORERERLKawpdkDZsN6n0GhdtB4iVYch+c22V1VdnCfffBjh3m0kN3d5g1y8yC/d//QUKC1dWJiIiISFZR+JKsY/eAJj9A/noQdxr+aAsxR6yuKlvw84N334WNG6FRI7hwAQYPhrp1Ye1aq6sTERERkayg8CVZy90P7poDAWXh4gH44x6IO2d1VdlG1aqwbJlpQx8SAps3Q4MGpk392bNWVyciIiIimUnhS7Ked0Fo/jt4h8HZrbCsEyTGWl1VtmG3wxNPmLXBevQwy6ONH2/WBvvuuzy5XJqIiIhIrqTwJa7hXxKazQX3ADi2GFY9ZppxSIpCheDrr2HRIihXDo4dg0cegTZtYO9eq6sTERERkdul8CWuk68mNJ1p7gU7+ANsHKxpnTQ0bw5bt8Ibb4CXF0REQJUqMHIkxGrCUERERCTHUvgS1wprCQ2+Mo8jP4KdH1hbTzbl5QVDh8K2bdCypQldw4ZB9eqweLHV1YmIiIhIRih8ieuV6AY1R5vHm/8D+7+xtp5srGxZmD8fpk2D0FCIjIS774aePeH4caurExEREZFbofAl1qg4GCq8YB6vfhyOzre2nmzMZoNu3UxDjv79zfdff20ackyaBEm6dU5EREQkR1D4EuvUfA+KPwKOBFj2AJxab3VF2VpwMIwbB6tWmcsPz5yBfv2gaVPYvt3q6kRERETkZhS+xDo2OzT40twHlnARltwL5/dZXVW2V78+rF8PY8aYxZpXrICaNeHll+HiRaurExEREZHrUfgSa7l5wp0/QUgNuHwcFrcxX+WG3N3h+edh507o2BESEuC996ByZZgzx+rqRERERCQtCl9iPY9AaPYb+JWEC/vgj3sh/oLVVeUIRYvCrFnw889QrBgcOADt20PnzvDPP1ZXJyIiIiJXU/iS7MEnDJrPA68CcHo9LH8QkuKtrirH6NABduyAl14CNzeYORMqVoQPPzSzYiIiIiJiPYUvyT4Cy8Fdv4KbLxz9HVb30SLMt8DPz1x6uHEjNGwIFy6YSxPr1YO1a62uTkREREQUviR7KVAPmswAmxv8/Q1sGWJ1RTlOtWqwfDlMnGg6JG7aBA0awMCBcO6c1dWJiIiI5F0KX5L93NEO6n9uHu94FyI/traeHMhuh759zaLMjz5qJhA//dSsDTZ9uiYURURERKyg8CXZU6leUP0t83jDIDjwg5XV5FiFCsE338DChVCuHERFmQWb27aFvXutrk5EREQkb1H4kuyr0hAoOwBwwKoecOwPqyvKse6+G7ZuhREjwMsL5s+HKlXgzTchNtbq6kRERETyBoUvyb5sNqj9ERTtDElxsPR+OLPV6qpyLC8vGDYMtm2Dli1N6Bo6FGrUgD/+sLo6ERERkdwvW4SvTz/9lBIlSuDt7U39+vVZe5PWbDNmzKBChQp4e3tTtWpV5s6dm/JcfHw8L7/8MlWrVsXPz4/ChQvz2GOPceTIEadjnD59mu7duxMYGEhwcDB9+vThwgWtLZXt2N2g0bdQqCnER8MfbeHiAaurytHKljUzX1OnmssSd+2C5s2hVy84ccLq6kRERERyL8vD1/fff8/gwYN5/fXX2bhxI9WrV6dNmzYcP348zf1XrlxJt27d6NOnD5s2baJjx4507NiR7du3AxATE8PGjRsZOnQoGzduZObMmURGRtKhQwen43Tv3p0///yTiIgI5syZw9KlS+nXr1+Wf17JADdvaPozBFWBS0dhcVuIPWV1VTmazQaPPGKC11NPme+/+so05PjiC0hKsrpCERERkdzH8vA1ZswY+vbtS+/evalUqRITJkzA19eXyZMnp7n/Rx99RNu2bXnppZeoWLEiI0eOpFatWowdOxaAoKAgIiIi6NKlC+XLl6dBgwaMHTuWDRs2cPDgQQB27tzJvHnz+Pzzz6lfvz5NmjThk08+Yfr06almyCSb8AyG5r+BbxGI3gVL2kNCjNVV5XghITB+PKxcCdWrw+nT8MQTcNdd8O//zxARERGRTOJu5ZvHxcWxYcMGhgy5spaT3W6nZcuWrFq1Ks3XrFq1isGDBztta9OmDbNnz77u+5w7dw6bzUZwcHDKMYKDg6lTp07KPi1btsRut7NmzRo6deqU6hixsbHEXtWZIDo6GjCXOcbHx9/0s0om8AiFO+fgvqg5tpOrSFrWhcRGM8CesdM4+fem3x/Urg2rVsEnn9h54w07y5fbqFnTwaBBSbz2WhK+vlZXmDvonBNX0vkmrqZzTlwtO51z6a3B0vB18uRJEhMTCQ0NddoeGhrKrl270nxNVFRUmvtHRUWluf/ly5d5+eWX6datG4GBgSnHKFSokNN+7u7u5MuX77rHGTVqFCNGjEi1ff78+fjqL1OXyuf2Eo3ih+N29FcO/nw/WzyfNtfNZVBEREQmVpezlS8PH37ow+efV2XNmnA++MCNr7++TL9+26hT55jV5eUaOufElXS+iavpnBNXyw7nXExM+q7IsjR8ZbX4+Hi6dOmCw+Fg/Pjxt3WsIUOGOM24RUdHU7RoUVq3bp0S6sRV2uE4XBbHyq6USIigaLn6JFUedstHiY+PJyIiglatWuHh4ZEFdeZcPXvC//6XwKBBbhw65MebbzagU6ckRo9OpEgRq6vLuXTOiSvpfBNX0zknrpadzrnkq+JuxtLwVaBAAdzc3Dh2zPn/qB87doywsLA0XxMWFpau/ZOD14EDB1i0aJFTQAoLC0vV0CMhIYHTp09f9329vLzw8vJKtd3Dw8PyX3aeVOJBiP8U1vXHbcebuPkXhTIZa5ii32HaHngAWrc2a4P93//BrFl2IiLsvPkmDBgA7rn6f91kLZ1z4ko638TVdM6Jq2WHcy69729pww1PT09q167NwoULU7YlJSWxcOFCGjZsmOZrGjZs6LQ/mKnGq/dPDl579uxhwYIF5M+fP9Uxzp49y4YNG1K2LVq0iKSkJOrXr58ZH01coexTUGWoebyuP/zzs7X15EL+/vD++7BxIzRoABcuwKBBUL8+fP89nD9vdYUiIiIiOYfl3Q4HDx7MpEmT+Oqrr9i5cyf9+/fn4sWL9O7dG4DHHnvMqSHHc889x7x58xg9ejS7du1i+PDhrF+/noEDBwImeD344IOsX7+eqVOnkpiYSFRUFFFRUcTFxQFQsWJF2rZtS9++fVm7di0rVqxg4MCBPPzwwxQuXNj1PwTJuKojoHQfcCTBiofhxAqrK8qVqlWDFStgwgQIDjZh7OGHoUABaN8evvwSTp60ukoRERGR7M3y8NW1a1c++OADhg0bRo0aNdi8eTPz5s1Laapx8OBBjh49mrJ/o0aNmDZtGhMnTqR69er8+OOPzJ49mypVqgBw+PBhfvnlF/755x9q1KhBeHh4yli5cmXKcaZOnUqFChVo0aIF7dq1o0mTJkycONG1H15un80GdSdA4fsg8bJpQX9up9VV5Up2Ozz5pFkbbMgQs1hzXBzMmQOPPw5hYdCiBXz6KRw+bHW1IiIiItmPzeFwOKwuIieKjo4mKCiIc+fOqeFGdpAQAwtbwKnV4FsUWq8C3ztu+JL4+Hjmzp1Lu3btLL9OOCdyOGDHDpg504zNm52fb9DA3DfWqROUKWNJidmOzjlxJZ1v4mo658TVstM5l95sYPnMl0imcPeFu/4HgeUh5hD8cQ/EnbW6qlzNZoPKlWHoUNi0Cfbtgw8+gEaNzPOrV8N//mNmyKpXN407tm0zoU1EREQkL1L4ktzDuwA0mwfeYXB2GyztaC5FFJcoVQpeeMHcG3b4MIwbBy1bgpsbbN0Kw4ebe8fKlYOXX4Y1ayApyeqqRURERFxH4UtyF/8S0HweeATC8SWwsgckJVpdVZ5TuDD07w8REXDsGEyZAh06gJcX7N0L771nLkssVgyeeQYWL4aEBKurFhEREclaCl+S+4RUhztngd0DDv0IGwfpWjcL5c9vFm3++Wc4cQJ++MF0SvT3NzNkY8fC3Xebhh19+sCvv0JsrNVVi4iIiGQ+hS/JncLuhobfmMe7x8KOd62tRwAICICHHoLvvjNBLLlTYv78cOoUTJ4M990HBQvCI4/Ajz+atcVEREREcgOFL8m9ineFWh+ax1uGwF9fWVqOOPP2hnvvhS++gKgoWLgQBgwwlyyeP28C2kMPmSDWsSN8/TWcPm111SIiIiIZp/AluVuF56DiS+bxmj5w5Ddr65E0ububSw/HjoVDh2DVKnjpJShdGi5fNpcs9uwJoaHQurVZ7Pmq5f9EREREcgSFL8n9arwDJR4FRyIsexBOrbO6IrkBu90043jvPdizB7Zsgddfh6pVTVOOiAjTzOOOO6BJExgzBvbvt7pqERERkZtT+JLcz2aH+l9AWGtIjIE/7oXoPVZXJelgs5n29MOHm3b1u3fDu+9C/fqmh8qKFaa9falSUKsWvPmmWfhZ/VVEREQkO1L4krzBzRPu/BFCakHsCVjcBi4fs7oquUVly5qFm1evNpcnfvIJNG9uZss2bTILPleuDBUrwquvwvr1CmIiIiKSfSh8Sd7hEQDN5oJ/Kbi4H/dlHXB3XLK6KsmgIkVg4EBYtMisJfbFF6aBh6cnREbCqFFQty4ULw6DBsHSpZCoJd9ERETEQgpfkrf4hELz38GrILazm6h7+R2IPWV1VXKbChQwLevnzDEt7JM7Jfr5mRmyjz6Cu+6C8HDo1w/mzYO4OKurFhERkbxG4UvynoAy0OxXHG5+FEragvvcsrD5Fbh83OrKJBMEBppFnH/4wQSx5E6JISHm+0mT4J57oFAhePRRmDkTLl60umoRERHJCxS+JG/KX5fEpnM4ay+JLeGCWYT55xKwYTBcUg/z3MLHBzp0gClTzKWJyZ0Sw8Lg3DmYOhU6dzZriT3wAHz7LZw9a3XVIiIiklspfEme5SjQmCXeY0hoPBPy1YXESxD5f/BzSVg3EC4esrpEyUQeHtCyJYwbB4cPX+mUWKIEXLoEs2ZBjx5mRuyee8wM2XFNhoqIiEgmUviSvM1mw1H4PmizBprNg4KNISkW9nwK/ysNa5+EC1pEKrex26FRI/jgA/jrL9i4EV57DSpVgvh4c09Yv35mhuyuu8w9YwcPWl21iIiI5HQKXyJgFpQq3AZaLoMWi6BQM0iKh70T4X9lYXVvrQ2WS9lsULMmjBwJf/4JO3fC229DnTqmTf3SpaZbYvHipnviqFGmm6KIiIjIrVL4ErmazQahzaHlYhPEwlqDIxH+mgK/VoAV3eHcDqurlCxUoQIMGQLr1sGBA/Dhh9C0qTk11q8364dVqGDWExs61KwvprXEREREJD0UvkSup1ATuPt3aL0aCt8HjiQ4MA1+rQLLu8CZrVZXKFmsWDF47jlYsgSOHoWJE6FtW3P/2I4d8OabUKsWlCpl7h9bsQKSkqyuWkRERLIrhS+RmylQH5r9D9pugCKdAAccnAG/VYelHeH0BqsrFBcIDYW+feG330wjjm+/NR0SfXzg779hzBho0gTuuMN0VIyIMPePiYiIiCRT+BJJr3y1oOlMaLcVinUFbPDPzzCvDixuBydWWV2huEhwMHTvDj/9BCdPmrXCHn0UgoIgKgomTIDWrU3nxJ49zVpjly5ZXbWIiIhYTeFL5FYFV4Um0+HeHVCiB9jc4OhvENEIFrWC40utrlBcyNcXOnWCb74xM2LJnRILFTJrhn39NXTsCAUKwMMPu7F4cRGOHbO6ahEREbGCwpdIRgVVgEZfw32RULoP2NwhagEsuMuMqAXqxJDHeHpCmzbw2Wdw5MiVTonFikFMDMycaeejj2pTtKgHtWqZxh5LlkBcnNWVi4iIiCsofIncroDSUP9zaL8HyjwFdk8z+7WoFcxvBIfnKoTlQW5ucOed8H//Z+4JW78eXn45kVKlzgKmS+I770CzZpA/P9x/P4wfb9YdExERkdxJ4Usks/iXgHrjocM+KPcsuHnDqdWw5F74va65P0whLE+y2aB2bRg5MokxY5Zw6FA833xj7hsrWBAuXIBffoGnn4bSpaFsWXjmGZgzxzwnIiIiuYPCl0hm8y0CdT6CDvuh4ovg5ms6Ii7tCL/VMJ0SHepHnpeFhpoGHd9+axp0bNgAb71l1hNzd4e9e2HsWGjf3syKtWgB770HW7cqv4uIiORkCl8iWcUnDGq+D/f/DZWGgHsAnN1q1gj7tQrsnwpJCVZXKRaz281aYa++au7/OnUKZs2Cp56CEiXM/WCLFsHLL0P16qaVfe/eMH262VdERERyDoUvkazmXRBqvG1CWJXXwSMYonfCqkdhTkX4awokaUEoMQIDTXfE5Pu/IiPh44+hXTvTWfHoUZgyBbp1M5cs1q8Pw4aZBZ4TlOVFRESyNYUvEVfxygfVhpsQVv0t8MoPF/bC6t7wv3KwdyIkxlpdpWQjNhuUK2fu//r1Vzh9GhYsgBdfhKpVzSWIa9fCyJFmgecCBeDBB2HSJDh40OrqRURE5FoKXyKu5hkElV+FDn9DjffAuxBc/BvWPgn/KwORYyHxstVVSjbk5WXu/3r/fXP/1z//wOTJ0LUr5MsH586ZhZ/79YPixaFSJRg8GH7/XYs8i4iIZAcKXyJW8fCHSi+Zxhy1PgSfwhDzD2x4Bn4uCbv+DxJirK5SsrGr7/86fhxWr4YRI6BhQ3Mv2c6dptV927YmnLVta77fsUONO0RERKyg8CViNXdfqPCcaVFfdxz4FoPLUbBxMPxcAna8C/Hnra5Ssjk3tyv3f61cCSdPwowZ0KcPFCkCly+bGbDBg6FyZTMz1rcv/PgjnD1rdfUiIiJ5g8KXSHbh5g1l+5vFmutNAv9SEHsCNr9iQti2kRB31uoqJYcICTH3f33+ubn/688/YfRoaN3aXL546JB57qGHzL1ijRube8fWroXERKurFxERyZ0UvkSyGzdPKPME3BcJDb6CgHIQdxq2DTMhbOswiD1tdZWSg9hszvd/nT4Nv/0GgwZBhQombK1caWbN6teHQoVMN8UpU0x3RREREckcCl8i2ZXdHUo9BvfugEbfQVBliD8H20fCz8XNjNjl41ZXKTmQr++V+7927oQDB2DiRHjgAdPq/vRpcx9Z795QuLBZX+w//zHrjcWqIaeIiEiGKXyJZHd2NyjxMLTbCk1+hJAakHDB3Av2cwnYMBguaXpCMq5YMXP/108/mYWbly+H116DunXNrNnWrabDYosWpnHHfffB2LGwZ48ad4iIiNwKhS+RnMJmh2Kdoe1GaPoL5KsLiZcg8v9Md8R1A+HiIaurlBzO3d35/q/jx2HaNOjZE8LCICbGrDn2zDNmDbIyZeDpp+Hnn+G8+sKIiIjckMKXSE5js0GR9tBmDTSbBwUbQ1Is7PkU/lfarBd2Yb/VVUouUaDAlfu/jhyBzZvh3XeheXPw8IC//oLx46FjRzMr1qwZjBoFmzZBUpK1tYuIiGQ3Cl8iOZXNBoXbQMtl0GIRFGoGSfGwdyL8ryys7g3Re6yuUnIRm835/q/Tp+F//4MBA8wMWEICLFkCr74KtWpBeDj06AFTp5oZNBERkbxO4Uskp7PZILQ5tFxsglhYa3Akwl9T4NcKsKI7nNthdZWSC/n7O9//tXcvfPopdOgAfn4mcH37LTz6KISGQp068N//wtKlEB9vdfUiIiKup/AlkpsUagJ3/w6t10Dh+8CRBAemwa9VYHkXOLPV6golFytd+sr9X6dPw+LF8MorUKOGeX7DBnj7bbjrLsifHzp1ggkTYL+ukhURkTxC4UskNypQD5r9zzTnKPoA4ICDM+C36rC0I5zeYHWFkst5ejrf/3X0KHz1FTzyiLmP7Px5mD0b+veHUqWgfHl49lmYOxcuXrS6ehERkayh8CWSm+WrCXf+ZNrUF+sK2OCfn2FeHVjcDk6ssrpCySPCwuCxx8z9X8eOwbp18OabcOed4OYGu3fDJ5/Avfeaxh2tWsEHH8C2bWpnLyIiuYfCl0heEFwVmkw3CzaX6AE2Nzj6G0Q0goUt4dgSqyuUPMRud77/69QpmDkTnnwSiheHuDhYsABeegmqVYMiRaBXL5g0Cf78U10URUQk51L4EslLgipAo6/hvkgo3Qds7nBsISxsBgvugqgFmmYQlwsKcr7/a9cu+PBDuOce8PExLe6/+gr69YMqVcz9YvfcY2bOFi2CCxes/gQiIiLp4251ASJigYDSUP9zqDIU/nwH/poMx5fColaQv4HZXvge00lRxIVsNnP/V/ny8NxzcPkyLFtmWtivXAlr1sDZszBvnhlgZtKqV4dGjcxo3BiKFdPpKyIi2Y/Cl0he5lcc6o2HKv+FHe/DvolwajUsuRfy1TYh7I4O+itWLOPtbe7/atXKfJ+QAFu3miCWPA4cME09Nm0yre4BChe+EsYaNYKaNU0TEBERESspfIkI+BaBOh9B5SGwazTsHmc6Ii7tCMHVoMprULQz2HSlsljL3d0s4FyrFgwcaLb98w+sWnUljG3caC5V/PFHM8CEuDp1zKxYo0bQsCEULGjd5xARkbxJ4UtErvAJg5rvQ8WXIfL/IPITOLvVrBEWWBEq/xeKdwW7/tUh2UeRIvDQQ2YAXLoE69fDihVXAtmpU7B8uRnJypZ1nh2rVMlcwigiIpJV9BeUiKTmXQCqvwUVXoDIjyHyI4jeCasehW3DofKrJoS5+1pdqUgqPj6mhf2dd5rvHQ7Ys+dKEFuxAnbsMNv27DHNPMA0/mjY8EoYq1cPAgKs+xwiIpL7KHyJyPV55YNqw6HC87DnU9g1Bi7shTWPw7qnoGBjCGtlRr5auixRsiWbDcqVM6NXL7PtzBlYvfpKIFuzBs6dS93Io1q1K5cqNmpkWuHrFkgREckohS8RuTnPIDPbVe5Z2DsBdo+Fiwfg2GIztrwKnvkgrKUJYuGtTDMPkWwqJMS0q7/nHvP99Rp5bN5sRnIjj/Bw50sVa9VSIw8REUk/hS8RST8Pf6j4orkc8fweiIow49hiiDsNB38wAyCg7JVZsdDmJsCJZFNpNfI4fPhKI48VK0wjj6NH4aefzADw8oK6da+EsYYNoVAh6z6HiIhkbwpfInLrbDYILGdGuQGQFA+n1sLRf8PYqTUmnJ3fA3vGgc0N8teDsNZmVix/PbB7WP0pRG7ojjvgwQfNgCuNPK6eHTt5MnUjjzJlnC9VVCMPERFJpvAlIrfP7mHu/yrY2NwjFncOjv9xJYyd3w0nV5mxfQS4B5jZsORLFAPK6UYayfZu1shj5Ur480/Yu9eMqxt5NGhwJYzVr69GHiIieZXCl4hkPs8gKHK/GQAXD5oQdjQCji2A2FNw+BczAHyLXrlEMayl6bYoks1dr5HHmjVXLlVMbuTx++9mwJVGHlffO1aihP7/g4hIXqDwJSJZz68YlO5jhiMJzmy6Mit2YjnEHIK/JpuBDUJqmhmxsFZmNs3N2+pPIJIuISHQtq0ZYBp5bNvm3Ob+6kYe48aZ/cLCTAhLvlyxZk1zP5mIiOQuCl8i4lo2O+SrbUblVyAhBo4vu9K84+xWOLPRjB3vgpsPFLzzShgLrqYpAskx3N1NkKpZEwYMMNuubuSxcqVp5BEVBTNnmgEmeNWp4zw7pkYeIiI5n8KXiFjL3RcKtzED4FIURC2EqPkmjF06+u/j+eZ579ArLe3DWoFvYetqF8mAtBp5bNhgZsWubuSxYoUZycqUcQ5jlSqBm5s1n0FERDJG4UtEshefMCjZ3QyHA87tuKql/R9w+Rj8PdUMgKBKV4JYobtMO3yRHMTHB5o0MQPMab93r/Olilc38vj6a7NfYKBp5JF8qaIaeYiIZH8KXyKSfdlsEFzZjAqDIDHOdExMDmOn1plwdm4HRH5kui4WaHQljOWrDXZNDUjOYrNB2bJm9Oxptp09C6tXXwlkq1dDdDTMn28GmEYeVatemRmrW9cEORERyT4UvkQk53DzhNC7zKj+JsSehmOLrnRSvLgfji8xY+tr4BkCoXdfaWnvX8rqTyCSIcHBqRt5bN/ufKni33/Dli1mjB8P4EFISBvuusuNO+80M2Q1a4Knp3WfQ0Qkr1P4EpGcyysfFHvQDIDz+67MikUtgrgzcOgnM8CEr7BWEN7ahDLPYMtKF7kd7u5Qo4YZyY08jhxxbuSxYYODM2e8mT0bZs82+3h7Q716Jog1bgwNG0K+fNZ8BhGRvMhudQGffvopJUqUwNvbm/r167N27dob7j9jxgwqVKiAt7c3VatWZe7cuU7Pz5w5k9atW5M/f35sNhubN29OdYxmzZphs9mcxlNPPZWZH0tErBBQGso+BXf+BJ1PQOtVUPUN0y3R5g4X/oK9n8GyzvBTfvi9AWwZCseXmksaRXKwwoWhc2cYPdqEsJMnE3jrrWW89VYi7dtD/vxw+TIsXQqjRsF995ltlStDv35mUei9e3WpoohIVrJ05uv7779n8ODBTJgwgfr16/Phhx/Spk0bIiMjKZRGT92VK1fSrVs3Ro0axX333ce0adPo2LEjGzdupEqVKgBcvHiRJk2a0KVLF/r27Xvd9+7bty9vvPFGyve+vr6Z/wFFxDp2dyjQwIyqQyH+vLkcMXl9seidcGqNGX++Ce5+UKjZlZmxwApqaS85mo8PVK58mnbtkvDwcMPhgMjIK10UV6yA3bthxw4zJk0yrytU6MqaY40bQ61aWnNMRCSzWBq+xowZQ9++fenduzcAEyZM4Ndff2Xy5Mm88sorqfb/6KOPaNu2LS+99BIAI0eOJCIigrFjxzJhwgQAevToAcDff/99w/f29fUlLCwsEz+NiGRrHgFwx31mAMT8A1ELroSx2BNw5FczAHzuuLK2WFhL8NYiS5Kz2WxQoYIZffqYbSdOXOmouGIFrF8Px4/jdKmil5dp3pEcxho1MjNmIiJy6ywLX3FxcWzYsIEhQ4akbLPb7bRs2ZJVq1al+ZpVq1YxePBgp21t2rRhdvJ/IW7B1KlT+fbbbwkLC6N9+/YMHTr0hrNfsbGxxMbGpnwfHR0NQHx8PPHx8bf8/mK95N+bfn95lEcoFO1uhiMJzm3FfmwhtmMLsZ1Yju3SYfhrihmAI6gaSaEtcYS2wFGwiVn8+RbpnBNXSs/5FhwM7dqZAeayxI0bbaxcacbq1TZOnrSxfDksX37ldeXLO2jUyEGjRkk0bOigbFlNFIv+HSeul53OufTWYFn4OnnyJImJiYSGhjptDw0NZdeuXWm+JioqKs39o6Kibum9H3nkEYoXL07hwoXZunUrL7/8MpGRkcycOfO6rxk1ahQjRoxItX3+/Pm6ZDGHi4iIsLoEyTYqAhWxe/cjf9JOCiZupmDiFoKT/sJ2bitu57bC7jEk4sFpe0WOu9XghFsNztlLgC39t9DqnBNXysj5VqmSGX36wJEj/uzcmY+dO/MRGZmPf/4JIDLSRmSkjS+/NOd9UFAs5cufpmLF01SocJoyZc7i4ZGU2R9Fcgj9O05cLTucczExMenaL092O+zXr1/K46pVqxIeHk6LFi3Yt28fpUuXTvM1Q4YMcZp1i46OpmjRorRu3ZrAwMAsr1kyX3x8PBEREbRq1QoPDw+ry5Fsp2PKo/jLx7EdX5QyM+Z26R8KJm2lYNJWiP8ah1dBHIWap8yM4Vs0zSPqnBNXyqrz7eTJeFavNjNjq1bZWL/exrlzXqxdG87ateEAeHo6qF3bQcOGZoasYUMHBQtmWgmSTenfceJq2emcS74q7mYsC18FChTAzc2NY8eOOW0/duzYde/FCgsLu6X906t+/foA7N2797rhy8vLC6807jj28PCw/Jctt0e/Q7kpjzsgoAeU7mFawUVHXmlpf2wxttgT2A79gP3QD2b/wPIQ1trcLxbazNxvdvXhdM6JC2X2+RYeDp06mQEQGwsbNzo38jhxwgSzVatgzBizX7lyV+4ba9wYypfXpYq5lf4dJ66WHc659L6/ZeHL09OT2rVrs3DhQjp27AhAUlISCxcuZODAgWm+pmHDhixcuJBBgwalbIuIiKBhw4a3VUtyO/rw8PDbOo6I5AE2GwRVMKP8M5AUDyfX/LvQ83w4vdaEs+hI2P2JaXFfoAGEtcJWsDk2R4LVn0AkU3l5mfXCGjaEF180/39i717nMLZzp+msuHs3fPmleV3+/M5dFevUMeuQiYjkZpZedjh48GB69uxJnTp1qFevHh9++CEXL15M6X742GOPcccddzBq1CgAnnvuOe666y5Gjx7Nvffey/Tp01m/fj0TJ05MOebp06c5ePAgR44cASAyMhIws2ZhYWHs27ePadOm0a5dO/Lnz8/WrVt5/vnnadq0KdWqVXPxT0BEcjy7BxRqYka1ERB3Fo4t/jeMRcCFvXBiOZxYjjuvcx92bL+VMq3sA8tfGQHlTUdFTQVIDmezQdmyZvTqZbadOmXWHksOY+vWmW3/+58ZAJ6eULu2c1fFNFadERHJ0SwNX127duXEiRMMGzaMqKgoatSowbx581Kaahw8eBC7/cpN7I0aNWLatGm89tprvPrqq5QtW5bZs2enrPEF8Msvv6SEN4CHH34YgNdff53hw4fj6enJggULUoJe0aJF6dy5M6+99pqLPrWI5GqewVC0kxkAF/5OuUTREbUQe9xpE8gu7IUjc5xf6xH0bxAr5xzKAsqC+613VxTJLvLnN4s63/fvSg9xcakvVTx+3AS0Vavggw/MfmXKOF+qWKEC2NPf20ZEJNuxORxayz4joqOjCQoK4ty5c2q4kUPFx8czd+5c2rVrZ/l1wpI3xMfFsejXb2lRrwjuMfuuXJ4YHQkX/wau969jG/gVM0Hs2tky3ztuqdOi5B056d9xDgf89ZdzGPvzz9T75ctnLm9MDmN165rFpCV7yEnnnOQO2emcS282yJPdDkVELGGzcdmeH0eh5uDR2vm5xMtwfq8JYucjnYNZ/Fm4eMCMqPnOr3PzhcByaQSzcqkafYhkVzYblC5txmOPmW1nzjhfqrh2LZw+Db/+agaAhwfUquU8O3bNijQiItmKwpeISHbg5g3BVcy4msMBsSeuBLHzkRC923w9vw8SY+DMZjOu5RPuHMqSH/uVALubCz6USMaFhDgvAB0fD5s2Oc+ORUXBmjVmJHdVLF3aOYxVrKhLFUUk+1D4EhHJzmw204jDuxAUutP5uaR4uLA/9WzZ+Ui4fBwuHTXj+B/Or7N7QkCZtIOZVz6XfTSRW+HhAfXqmfH88+b/S+zfn/pSxX37zPj6a/O64GDTvCO5s2K9euDra+lHEZE8TOFLRCSnsnuYSw4DywHtnZ+LO3vNbFny4z2QFAvndphxLa8CV4Wxqy5n9C8Nbp6u+FQi6WKzQalSZvToYbadPQurV18JY2vWmG1z55oB4O4ONWs6z45ppRkRcRWFLxGR3MgzGArUN+NqSYkQc/DKpYtXB7SYfyD2JJw4CSdWOL/O5gZ+JVM3/AgsD96hapEv2UJwMLRtawaYSxW3bHGeHTtyxLS6X7cOPvzQ7FeypHMYq1xZlyqKSNZQ+BIRyUvsbuBf0gzaOD8Xf8HMjKWaLdsNCReuapH/q/PrPALT7sSoFvliMQ8Ps3hznTrw3HPmUsUDB5zD2LZt5vLF/fvh22/N64KCoEoVKFfOjLJlzdcyZdRdUURuj8KXiIgYHv6Qr6YZV3M44NKRtEPZxb8hPhpOrzPDydUt8q/pyOhbRC3yxeVsNihRwozu3c22c+dSX6p47tyV769VtOiVUHZ1MCtRwoQ9EZEbUfgSEZEbs9nMemK+d0DY3c7PJV42XRevbY9/PhLizty4RX5A2dSXMAaWV4t8camgIGjTxgyAhATYvh127YLdu2HPHvN1925z/9ihQ2YsXOh8HHd3c/nitaGsXDm44w5dxigihsKXiIhknJs3BFc242oOh7l/LK1OjMkt8s9uMeNaqVrkl/u3RX5x02REJAu5u0ONGmZczeGAkyedw1jy4z174NIl83XPnivrkCXz8TGXLKYVzAoU0C2TInmJwpeIiGQ+mw28C5pRqInzc2m1yD+/23y9fOz6LfJtbuBbDAJKm+6L/qVNy3z/0uBfylw2KZJFbDYoWNCMRo2cn0tKMo08rg1lu3fDX3+ZYLZtmxnXCgpKO5SVLQuBga75bCLiOgpfIiLiWjdtkZ9GJ8bzeyHxElzcbwYLUh/XOzR1KEsOal6aXpCsY7dDkSJm3H3NlbkJCfD336lD2Z49cPCgub8sufvitUJD0w5mpUuDt7dLPpqIZDKFLxERyT48g6FAPTOu5nCY2bAL+8w4v/ffr/9+H3fazJpdPgYnV6Y+rnvAv0GszDUzZ6XBp4jpAimSBdzdzSWHZcqkfu7SJbMgdFrB7NixK2PZMufX2WxQrFjawax4cfOeIpI96R9PERHJ/mw28C1sRqE7Uz8fdzbtUHZhn1m/LOE8nNlsxrXsnuBX4qpLGK+aMfMvae5rE8kCPj6mpX2VKqmfO3fuyj1kV4eyyEiIjjYt8w8cgIgI59d5eJiFp9O6jPGOOzQBLGI1hS8REcn5PIMhX20zrpV42dxjlhzMrg5nF/dDUpy55+z87jQObDNt8Z0C2VWPPYOz+INJXhUUdGWNsqs5HHDixPUbf1y+bAJaZGTqY/r6Xglk1waz/PkVzERcQeFLRERyNzdvCKpoxrWSEiHmUOpQlvw44bx5PuZQ6gYgAF75rwSyq0NZQBnwDtNfs5LpbDYoVMiMxo2dn0tKgn/+STuY/fUXxMTAli1mXCskJO1QVrYsBGj1B5FMo/AlIiJ5l90N/EuYQQvn55Lb5ac1Y3Zhn7m/LPaUGafWpj62m6/pwphWd0a/YmqbL5nObjf3ghUrBi2uOZ3j4680/rj2HrNDh+DMGbPA9Jo1qY8bHp52MCtdGry8XPLRRHINhS8REZG0XN0uv2DD1M/Hn4cLf6UxY7YXYg6atczObTcj1bHdzLplTjNmyc1ASoG7X9Z/PslTPDyuzGTde6/zczEx12/8cfw4HD1qxpIlzq+z202Dj+RQVrq0nWPHwggIsFGwIOTLZ4aPj+s+p0h2p/AlIiKSER4BEFLdjGslxsHFA2nMmO01gS3x8r/B7S8gIvXrvcOumjG7pkOjl27Okczl6wtVq5pxrbNnUzf+SA5m0dGwf78Z8+cDuAH1eecd52N4eZkQFhLi/DWtbVd/DQ5W50bJfXRKi4iIZDY3Twgsa8a1HElX2uZfO2N2YR/EnYHLUWacWJH69R6B11/PzLcI2OxZ//kkzwgOhrp1zbiaw2Fmxa6eLdu1K4ldu87icIRw5oyNM2fMOmexsVdmz25VUNCNA9r1Qpyfn/4fhWRPCl8iIiKuZLOD7x1mFGqa+vm4M2mHsvP74NJhiI+GM5vMuJbd07TH9y+D3bckpeIvYTt0AfwKg1ch8C7078yZAprcHpvNLAIdGgp3/rv6Q3x8InPnLqNdu3Z4eHjgcMCFC3D6tLmn7EZfr90WHW2Oee6cGX//fWv1ubunb3YtrX08dDumZCGFLxERkezEMwTy1zHjWgmXTHv889cEswv74OLfpm1+dCRER+IGVAVY/YXzMWx28Cr4bxD7N5B5FwLv0DS2FdL9Z5JhNpvplBgQYO4NuxUJCeaSxxsFtOuFuLg48/rjx824Vf7+t36JZL58EBio2Ta5OYUvERGRnMLdB4IqmXGta9rmJ56LJGrvasLzuWOPPWG6M8adNpc9Xj5mRrre0y91IPMOTb3NqxB4FTAdJEVuk7s7FChgxq1wOODSpVubZUv+evYsKbN1Fy6YLpC3ws3NXKZ5q5dIhoSAt9ZyzzMUvkRERHKDa9rmJ8XHs/6fubRr1g578nVUSfGmff7l41eNYxB73Hlb7L/bEy9DwkVI2G9m3G7KZgLY1YHs6lm1a2fW3P01VSCZymYzDUR8faFIkVt7bWKiudzxZrNsaW27dMm8/tQpM26Vry8ULJj2KFQo9TZ//aOTYyl8iYiI5BV2D/AJN+NmHA5IuHBNIPs3lKW1LfYU4IDYE2ac+/Pm7+Hmk/7LH70Kgl1/tkjWcXMzs1AhIWYNs1tx+bIJYrd6ieSZM2Zx7JgYOHDAjPTw9k5fSEveFhCgsJZd6N9iIiIikprNZtrpewSYboo3k5Tw76LT18yqOYW0q7YnxkDiJdOS/2I6/+L0yu8cyryumVW7OrR56AYccR1vb7MYdXg6/r/G1ZKS4Px5M1t24oTzOH487W2XLpmwd+hQ+i+N9PS8cUi7dntQkP7xySoKXyIiInL77O7gE2pGeiRcTP/lj7Enzb1qsafMiN6Zjnq80n/5o1dBszyAiIvZ7SboBAVBqVLpe83FizcOadd+f/GiaUJy+LAZ6eHhYe63u9Fs2tUjONh8Frk5hS8RERFxPXe/f9vil7z5vkmJpllIciC7dE1Qu/aSyIQLkBRrGpDEpHdqIMQ5lHmGmNkzj6B/RyB4XvX46q9u3pomEJfx8zOjRIn07R8Tk3oG7UYzaxcuQHz8ra3N5uaW/vvVChUyl3bm1bCm8CUiIiLZm90NvAuaQeWb758QY+47u/byx7SCWuwJcCSa9dXizgCRGajPI3VQu/qrZ1Daz1+93T1AnSIlS/j6mlb/6W33f/ly+kJa8uPoaNNsJCrKjPRwc4P8+dN3v1rBgqYrpFsu+cdD4UtERERyF3dfcC8Ofun4a9ORZELXtUEt/qxZ0Dr+nPkad+7K4/jkx+cBx79dJP+9JPK26va/QWi72Szcv481Cye3ydsbihY1Iz1iY+HkyZuHtOTvz50zYe1W1mGz200ASx3K7NjthWjXLuOf19UUvkRERCTvstn/beSRH4Iq3tprHUnmEse4c85BLf7cTULbv9sT/v2aFGuOl3DBjEvpvDEnLdedhbs6tGkWTjKPlxfccYcZ6REXZ8JaemfWkjtCnjxpxk6nWz7daNXqFrucWEzhS0RERCQjbPZ/A0vg7R0nMTYdoe3fr3FpBDmXz8JdMyP37yyczeaLf9JhEx4dIea+Pi0PINfw9ITChc1Ij/h40w0yrZAWFZWIv/9JIJ3JLxvQPxEiIiIiVnLzArfke9oyKM1ZuPSEtmuC3m3MwrkDLQDmXP3ZvE0Ic/d3Hh7+qbe5+6W93eOafdx8dGllHuLhAWFhZlwrPj6JuXMPA9VdXldGKXyJiIiI5HSZOgt3vdB249k5R9w54i+dwcN2GZsj8d/jXTbjdmfinNiuH+A8rgppNwp7ae2nWTpxAZ1lIiIiImK4eYHbv+32b1FCfDy/zZ1Lu3vuwcPNcWX2LP7ClccJF6+z/ervLzpvT34uMebfd3JAwnkzMpPd6/ozcjcMcDfYT7N0cg2FLxERERHJPDabWbTazcs0MsksSYkmgF0d0K4b4G4S9K7e5kj49/ixpnVfls7SXWdGzs0HbG5mBtPmBtiv+v6qx7eynWv2ue72DBz7tt4zb4dRhS8RERERyf7sbmAPAI+AzD1uYtwNAtwNgt4NZ+su/nvwLJqly+kyKdi5Y6dcXFUg5/SaV/gSERERkbzLzRPc8oFXvsw7piPJLPZ9bSC7XoBLjDGvcSQBSWbh7+TvHYn/brvV7ddsu91jk2RmH9PanvI4vT+fxH/f4/bYAG/3Ird9HFdS+BIRERERyUw2u7mk0MPf6kpcKyW8ZUGwS2N7Qnwcf63bQ06KXwpfIiIiIiJy+5IvE3QRR3w8F+yXXfZ+mcF1Px0REREREZE8TOFLRERERETEBRS+REREREREXEDhS0RERERExAUUvkRERERERFxA4UtERERERMQFFL5ERERERERcQOFLRERERETEBRS+REREREREXEDhS0RERERExAUUvkRERERERFxA4UtERERERMQFFL5ERERERERcQOFLRERERETEBdytLiCncjgcAERHR1tciWRUfHw8MTExREdH4+HhYXU5kgfonBNX0vkmrqZzTlwtO51zyZkgOSNcj8JXBp0/fx6AokWLWlyJiIiIiIhkB+fPnycoKOi6z9scN4tnkqakpCSOHDlCQEAANpvN6nIkA6KjoylatCiHDh0iMDDQ6nIkD9A5J66k801cTeecuFp2OuccDgfnz5+ncOHC2O3Xv7NLM18ZZLfbKVKkiNVlSCYIDAy0/B9YyVt0zokr6XwTV9M5J66WXc65G814JVPDDRERERERERdQ+BIREREREXEBhS/Js7y8vHj99dfx8vKyuhTJI3TOiSvpfBNX0zknrpYTzzk13BAREREREXEBzXyJiIiIiIi4gMKXiIiIiIiICyh8iYiIiIiIuIDCl4iIiIiIiAsofEmeM2rUKOrWrUtAQACFChWiY8eOREZGWl2W5BHvvPMONpuNQYMGWV2K5GKHDx/m0UcfJX/+/Pj4+FC1alXWr19vdVmSSyUmJjJ06FBKliyJj48PpUuXZuTIkainm2SGpUuX0r59ewoXLozNZmP27NlOzzscDoYNG0Z4eDg+Pj60bNmSPXv2WFNsOih8SZ6zZMkSBgwYwOrVq4mIiCA+Pp7WrVtz8eJFq0uTXG7dunV89tlnVKtWzepSJBc7c+YMjRs3xsPDg99++40dO3YwevRoQkJCrC5Ncql3332X8ePHM3bsWHbu3Mm7777Le++9xyeffGJ1aZILXLx4kerVq/Ppp5+m+fx7773Hxx9/zIQJE1izZg1+fn60adOGy5cvu7jS9FGrecnzTpw4QaFChViyZAlNmza1uhzJpS5cuECtWrUYN24cb775JjVq1ODDDz+0uizJhV555RVWrFjBsmXLrC5F8oj77ruP0NBQvvjii5RtnTt3xsfHh2+//dbCyiS3sdlszJo1i44dOwJm1qtw4cK88MILvPjiiwCcO3eO0NBQpkyZwsMPP2xhtWnTzJfkeefOnQMgX758FlciudmAAQO49957admypdWlSC73yy+/UKdOHR566CEKFSpEzZo1mTRpktVlSS7WqFEjFi5cyO7duwHYsmULy5cv55577rG4Msnt9u/fT1RUlNN/W4OCgqhfvz6rVq2ysLLrc7e6ABErJSUlMWjQIBo3bkyVKlWsLkdyqenTp7Nx40bWrVtndSmSB/z111+MHz+ewYMH8+qrr7Ju3TqeffZZPD096dmzp9XlSS70yiuvEB0dTYUKFXBzcyMxMZG33nqL7t27W12a5HJRUVEAhIaGOm0PDQ1NeS67UfiSPG3AgAFs376d5cuXW12K5FKHDh3iueeeIyIiAm9vb6vLkTwgKSmJOnXq8PbbbwNQs2ZNtm/fzoQJExS+JEv88MMPTJ06lWnTplG5cmU2b97MoEGDKFy4sM45kWvoskPJswYOHMicOXNYvHgxRYoUsbocyaU2bNjA8ePHqVWrFu7u7ri7u7NkyRI+/vhj3N3dSUxMtLpEyWXCw8OpVKmS07aKFSty8OBBiyqS3O6ll17ilVde4eGHH6Zq1ar06NGD559/nlGjRlldmuRyYWFhABw7dsxp+7Fjx1Key24UviTPcTgcDBw4kFmzZrFo0SJKlixpdUmSi7Vo0YJt27axefPmlFGnTh26d+/O5s2bcXNzs7pEyWUaN26cavmM3bt3U7x4cYsqktwuJiYGu935T0o3NzeSkpIsqkjyipIlSxIWFsbChQtTtkVHR7NmzRoaNmxoYWXXp8sOJc8ZMGAA06ZN4+effyYgICDlmuCgoCB8fHwsrk5ym4CAgFT3E/r5+ZE/f37dZyhZ4vnnn6dRo0a8/fbbdOnShbVr1zJx4kQmTpxodWmSS7Vv35633nqLYsWKUblyZTZt2sSYMWN4/PHHrS5NcoELFy6wd+/elO/379/P5s2byZcvH8WKFWPQoEG8+eablC1blpIlSzJ06FAKFy6c0hExu1GreclzbDZbmtu//PJLevXq5dpiJE9q1qyZWs1LlpozZw5Dhgxhz549lCxZksGDB9O3b1+ry5Jc6vz58wwdOpRZs2Zx/PhxChcuTLdu3Rg2bBienp5Wlyc53B9//EHz5s1Tbe/ZsydTpkzB4XDw+uuvM3HiRM6ePUuTJk0YN24c5cqVs6Dam1P4EhERERERcQHd8yUiIiIiIuICCl8iIiIiIiIuoPAlIiIiIiLiAgpfIiIiIiIiLqDwJSIiIiIi4gIKXyIiIiIiIi6g8CUiIiIiIuICCl8iIiIiIiIuoPAlIiLiYjabjdmzZ1tdhoiIuJjCl4iI5Cm9evXCZrOlGm3btrW6NBERyeXcrS5ARETE1dq2bcuXX37ptM3Ly8uiakREJK/QzJeIiOQ5Xl5ehIWFOY2QkBDAXBI4fvx47rnnHnx8fChVqhQ//vij0+u3bdvG3XffjY+PD/nz56dfv35cuHDBaZ/JkydTuXJlvLy8CA8PZ+DAgU7Pnzx5kk6dOuHr60vZsmX55ZdfsvZDi4iI5RS+RERErjF06FA6d+7Mli1b6N69Ow8//DA7d+4E4OLFi7Rp04aQkBDWrVvHjBkzWLBggVO4Gj9+PAMGDKBfv35s27aNX375hTJlyji9x4gRI+jSpQtbt26lXbt2dO/endOnT7v0c4qIiGvZHA6Hw+oiREREXKVXr158++23eHt7O21/9dVXefXVV7HZbDz11FOMHz8+5bkGDRpQq1Ytxo0bx6RJk3j55Zc5dOgQfn5+AMydO5f27dtz5MgRQkNDueOOO+jduzdvvvlmmjXYbDZee+01Ro4cCZhA5+/vz2+//aZ7z0REcjHd8yUiInlO8+bNncIVQL58+VIeN2zY0Om5hg0bsnnzZgB27txJ9erVU4IXQOPGjUlKSiIyMhKbzcaRI0do0aLFDWuoVq1aymM/Pz8CAwM5fvx4Rj+SiIjkAApfIiKS5/j5+aW6DDCz+Pj4pGs/Dw8Pp+9tNhtJSUlZUZKIiGQTuudLRETkGqtXr071fcWKFQGoWLEiW7Zs4eLFiynPr1ixArvdTvny5QkICKBEiRIsXLjQpTWLiEj2p5kvERHJc2JjY4mKinLa5u7uToECBQCYMWMGderUoUmTJkydOpW1a9fyxRdfANC9e3def/11evbsyfDhwzlx4gTPPPMMPXr0IDQ0FIDhw4fz1FNPUahQIe655x7Onz/PihUreOaZZ1z7QUVEJFtR+BIRkTxn3rx5hIeHO20rX748u3btAkwnwunTp/P0008THh7Od999R6VKlQDw9fXl999/57nnnqNu3br4+vrSuXNnxowZk3Ksnj17cvnyZf7v//6PF198kQIFCvDggw+67gOKiEi2pG6HIiIiV7HZbMyaNYuOHTtaXYqIiOQyuudLRERERETEBRS+REREREREXED3fImIiFxFV+OLiEhW0cyXiIiIiIiICyh8iYiIiIiIuIDCl4iIiIiIiAsofImIiIiIiLiAwpeIiIiIiIgLKHyJiIiIiIi4gMKXiIiIiIiICyh8iYiIiIiIuMD/A4RAGw+hZdksAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_dir_name = \"../models/fld0_sfzn1_hd_hl512_psdMxp_mxp08_epch10/\"\n",
    "i = 0\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# loss„Çí„Éó„É≠„ÉÉ„Éà\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BirdCLEFModelForInference:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([206, 1280]) from checkpoint, the shape in current model is torch.Size([569, 1280]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([206]) from checkpoint, the shape in current model is torch.Size([569]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m load_model(model_2_path)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m models_lib\u001b[38;5;241m.\u001b[39mBirdCLEFModelForInference(cfg_inf, num_classes)\n\u001b[1;32m     16\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BirdCLEFModelForInference:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([206, 1280]) from checkpoint, the shape in current model is torch.Size([569, 1280]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([206]) from checkpoint, the shape in current model is torch.Size([569])."
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´Âá∫Âäõ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "\n",
    "# „É¢„Éá„É´„Éë„Çπ\n",
    "# ÊØîËºÉÂÖÉ\n",
    "model_1_path = \"../models/sfzn1_hd_hl512//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_safezone1000_head_hoplength512/model_fold0.pth\"\n",
    "\n",
    "# ÂÖ±ÈÄöË®≠ÂÆöÔºà„Åì„ÅÆcfg_inf„ÅØÂøÖÈ†àÔºâ\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÈñ¢Êï∞\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# Êé®Ë´ñÔºàÂá∫Âäõ„Å´ sigmoid „ÅåÂøÖË¶Å„Å™Â†¥Âêà„ÅØ model „Å´Âê´„Åæ„Çå„Å¶„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶ÈÅ©ÂÆúËøΩÂä†Ôºâ\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# Â∑ÆÂàÜË®àÁÆó\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\")\n",
    "print(f\"ÊúÄÂ§ßË™§Â∑Æ: {np.max(abs_diff)}\")\n",
    "print(f\"Âπ≥ÂùáË™§Â∑Æ: {np.mean(abs_diff)}\")\n",
    "print(f\"Ê®ôÊ∫ñÂÅèÂ∑Æ: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„Éù„ÉÉ„ÇØ1„Åß„Éá„Éê„ÉÉ„Ç∞„Åß„Åç„Çã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
