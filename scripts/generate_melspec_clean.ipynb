{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from module import config_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.PROCESSED_DIR = \"\"\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # å…¨modelã®ä¿å­˜å…ˆ\n",
    "            self.model_path = self.models_dir # å„ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆï¼å­¦ç¿’æ™‚ã«å‹•çš„ã«å¤‰æ›´ï¼\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_DURATION = 5 # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆæ™‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 16\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 16  # ä¸¦åˆ—å‡¦ç†ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•° 16ãã‚‰ã„ã§ã„ã„\n",
    "        self.N_JOBS_DURATION = 47\n",
    "        \n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeã—ãªã„ãªã‚‰True\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "        self.num_rare_samples = 10 # ã“ã‚Œä»¥ä¸‹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã®speciesã¯rare speciesã¨ã—ã¦æ‰±ã†\n",
    "        self.is_crop_aug = False\n",
    "        self.num_prune_samples = 1000 # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ã“ã‚Œä»¥ä¸‹ã«prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = DatasetConfig(kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: OFF\n",
      "Max samples to process: ALL\n",
      "Loading taxonomy data...\n",
      "Loading training metadata...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{config.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{config.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 unique species\n",
      "Total samples to process: 28564 out of 28564 available\n",
      "Samples by class:\n",
      "class\n",
      "Aves        27648\n",
      "Amphibia      583\n",
      "Mammalia      178\n",
      "Insecta       155\n",
      "Name: count, dtype: int64\n",
      "âœ… Added 'duration_sec'. Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "label_list = sorted(train_df['primary_label'].unique())\n",
    "label_id_list = list(range(len(label_list)))\n",
    "label2id = dict(zip(label_list, label_id_list))\n",
    "id2label = dict(zip(label_id_list, label_list))\n",
    "\n",
    "print(f'Found {len(label_list)} unique species')\n",
    "working_df = train_df.copy()\n",
    "working_df['target'] = working_df.primary_label.map(label2id)\n",
    "working_df['filepath'] = config.RAW_DIR + '/train_audio/' + working_df.filename\n",
    "working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "working_df[\"crop_strategy\"] = \"center\"\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')\n",
    "print(f'Samples by class:')\n",
    "print(working_df['class'].value_counts())\n",
    "\n",
    "# éŸ³æºã®é•·ã•ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿½åŠ ï¼\n",
    "duration_df = pd.read_csv(\"../data/processed/train_duration.csv\")\n",
    "working_df = working_df.merge(duration_df, on=\"filename\", how=\"left\")\n",
    "\n",
    "missing = working_df[\"duration_sec\"].isna().sum()\n",
    "print(f\"âœ… Added 'duration_sec'. Missing values: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # å…¨éŸ³æºã®é•·ã•ã‚’è¨ˆç®—\n",
    "# def get_duration(filepath, sr):\n",
    "#     try:\n",
    "#         audio, _ = librosa.load(filepath, sr=sr)\n",
    "#         return len(audio) / sr\n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Could not load {filepath}: {e}\")\n",
    "#         return np.nan\n",
    "\n",
    "# print(\"ğŸ”„ Calculating durations with parallel processing...\")\n",
    "\n",
    "# # tqdm å¯¾å¿œ\n",
    "# filepaths = working_df['filepath'].tolist()\n",
    "# durations = Parallel(n_jobs=config.N_JOBS_DURATION)(\n",
    "#     delayed(get_duration)(fp, config.FS) for fp in tqdm(filepaths)\n",
    "# )\n",
    "\n",
    "# working_df['duration_sec'] = durations\n",
    "# print(\"âœ… Added 'duration_sec' column to working_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usable_ranges_from_duration(duration_sec, silence_segments, min_clip_sec=5.0):\n",
    "    usable_ranges = []\n",
    "    current_start = 0.0\n",
    "\n",
    "    for seg in silence_segments:\n",
    "        s_start, s_end = seg[\"start\"], seg[\"end\"]\n",
    "        if s_end <= current_start:\n",
    "            continue\n",
    "        if s_start > current_start:\n",
    "            usable_end = min(s_start, duration_sec)\n",
    "            if usable_end - current_start >= min_clip_sec:\n",
    "                usable_ranges.append((round(current_start, 2), round(usable_end, 2)))\n",
    "        current_start = max(current_start, s_end)\n",
    "\n",
    "    if duration_sec - current_start >= min_clip_sec:\n",
    "        usable_ranges.append((round(current_start, 2), round(duration_sec, 2)))\n",
    "\n",
    "    return usable_ranges\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm  # âœ… notebookç‰ˆ\n",
    "\n",
    "def build_usable_ranges_df(working_df, silence_df, min_clip_sec=5.0):\n",
    "    records = []\n",
    "\n",
    "    for _, row in tqdm(working_df.iterrows(), total=len(working_df)):\n",
    "        fname = row[\"filename\"]\n",
    "        duration = row[\"duration_sec\"]\n",
    "\n",
    "        silence_segments = silence_df[silence_df[\"filename\"] == fname][[\"start\", \"end\"]].to_dict(\"records\")\n",
    "        usable = get_usable_ranges_from_duration(duration, silence_segments, min_clip_sec)\n",
    "\n",
    "        records.append({\n",
    "            \"filename\": fname,\n",
    "            \"usable_ranges\": usable\n",
    "        })\n",
    "\n",
    "    usable_df = pd.DataFrame(records)\n",
    "    return usable_df\n",
    "# usable_df = build_usable_ranges_df(working_df, humanvoice_df, min_clip_sec=1)\n",
    "# usable_df.to_csv(\"../data/processed/usable_ranges_human_voice_0425.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_df = pd.read_csv(\"../data/processed/usable_ranges_human_voice_0425.csv\")\n",
    "if \"usable_ranges\" not in working_df.columns:\n",
    "    working_df = pd.merge(working_df, usable_df, on=\"filename\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_valid_ranges(df, usable_col=\"usable_ranges\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: 'filename', usable_col (list of (start, end))\n",
    "        Assumes df is already filtered (e.g., by collection).\n",
    "        \n",
    "    usable_col : str\n",
    "        Column name containing list of usable ranges.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: ['filename', 'valid_start_sec', 'valid_end_sec']\n",
    "    \"\"\"\n",
    "    def safe_eval(x):\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except:\n",
    "                return []\n",
    "        return x\n",
    "\n",
    "    start_list = []\n",
    "    end_list = []\n",
    "    filenames = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ranges = safe_eval(row[usable_col])\n",
    "        filenames.append(row[\"filename\"])\n",
    "\n",
    "        if not ranges:\n",
    "            start_list.append(np.nan)\n",
    "            end_list.append(np.nan)\n",
    "        else:\n",
    "            longest = max(ranges, key=lambda x: x[1] - x[0])\n",
    "            start_list.append(longest[0])\n",
    "            end_list.append(longest[1])\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"valid_start_sec\": start_list,\n",
    "        \"valid_end_sec\": end_list\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSAã®éŸ³æºã‹ã‚‰äººé–“ã®å£°ã‚’é™¤å»\n",
    "\n",
    "working_df[\"valid_start_sec\"] = 0\n",
    "working_df[\"valid_end_sec\"] = working_df[\"duration_sec\"]\n",
    "\n",
    "# CSAã®éŸ³æºã‹ã‚‰äººé–“ã®å£°ã‚’é™¤å»\n",
    "csa_df = working_df[working_df[\"collection\"] == \"CSA\"]\n",
    "valid_range_df = extract_valid_ranges(csa_df)\n",
    "\n",
    "working_df = working_df.set_index(\"filename\")\n",
    "valid_range_df = valid_range_df.set_index(\"filename\")\n",
    "\n",
    "working_df.loc[valid_range_df.index, [\"valid_start_sec\", \"valid_end_sec\"]] = \\\n",
    "    valid_range_df[[\"valid_start_sec\", \"valid_end_sec\"]].values\n",
    "\n",
    "working_df = working_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰‹å‹•ã§äººã®å£°é™¤å»\n",
    "\n",
    "# 4. ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã® valid_start_sec ã‚’å¤‰æ›´\n",
    "# ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ€åˆã«ã‚¹ãƒšã‚¤ãƒ³èªãŒå«ã¾ã‚Œã‚‹ï¼‰\n",
    "spanish_intro_filenames = [\n",
    "    '50186/CSA28885.ogg',\n",
    "    '52884/CSA14875.ogg'\n",
    "]\n",
    "# valid_start_sec ã‚’ 4.0 ã«å¤‰æ›´\n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(spanish_intro_filenames),\n",
    "    'valid_start_sec'\n",
    "] = 4.0\n",
    "\n",
    "\n",
    "# é€”ä¸­ã§äººã®å£°ã®ã¿ã«ãªã‚‹ã®ã§é™¤å»\n",
    "voice_only_ranges = {\n",
    "    '476537/CSA35459.ogg': 134,  # 2åˆ†14ç§’ = 134ç§’\n",
    "    '476537/CSA35461.ogg': 259,  # 4åˆ†19ç§’ = 259ç§’\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Eliana Barona- CortÃ©sã€€ã®éŸ³æºï¼è©±ã—ã¦ã„ã‚‹éƒ¨åˆ†ï¼ã„ã‚‰ãªã„éƒ¨åˆ†\n",
    "# 24292/CSA34649.ogg 2min8ä»¥é™\n",
    "# 24292/CSA34651.ogg 1min33ä»¥é™\n",
    "# 50186/CSA34622.ogg 21sä»¥é™\n",
    "# 50186/CSA34678.ogg 43sä»¥é™\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA34649.ogg': 128,   # 2åˆ†8ç§’ = 128ç§’\n",
    "    '24292/CSA34651.ogg': 93,    # 1åˆ†33ç§’ = 93ç§’\n",
    "    '50186/CSA34622.ogg': 21,    # 21ç§’\n",
    "    '50186/CSA34678.ogg': 43,    # 43ç§’\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "# Alexandra Butrago-Cardona ã®éŸ³æºãƒã‚§ãƒƒã‚¯\n",
    "# è©±ã—ã¦ã„ã‚‹éƒ¨åˆ†ï¼ã„ã‚‰ãªã„éƒ¨åˆ†\n",
    "# 24292/CSA35021.ogg 36sä»¥é™\n",
    "# 52884/CSA34947.ogg 13sä»¥é™\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA35021.ogg': 36,    # 36ç§’\n",
    "    '52884/CSA34947.ogg': 13,     # 13ç§’\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Fabio A. Sarria-S ã®éŸ³å£°ã¯ 0ã€œ7ç§’ ã ã‘ä½¿ç”¨å¯èƒ½ã«è¨­å®šï¼å¾ŒåŠã¯ãŸã ã®èª¬æ˜ãªã®ã§\n",
    "fabio_filenames = train_df.loc[\n",
    "    train_df['author'] == \"Fabio A. Sarria-S\", 'filename'\n",
    "].tolist()\n",
    "# \n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(fabio_filenames), 'valid_end_sec'\n",
    "] = 7.0\n",
    "\n",
    "#  Fabioã®è§£èª¬ã§ï¼Œå¿…ãšã—ã‚‚7secã§ã¯ãªã„ã‚‚ã®\n",
    "fabio_override = {\n",
    "    \"48124/CSA36346.ogg\": 24.0,\n",
    "    \"52884/CSA36344.ogg\": 55.0,\n",
    "    \"52884/CSA36342.ogg\": 14.0,  # â† è¿½åŠ åˆ†\n",
    "}\n",
    "\n",
    "for fname, end_sec in fabio_override.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# cropæˆ¦ç•¥ã¯åŸºæœ¬center\n",
    "working_df[\"crop_strategy\"] = \"center\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Marked 0 samples as invalid (over 1000 per label)\n"
     ]
    }
   ],
   "source": [
    "# é™¤å»ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š\n",
    "working_df[\"is_valid_audio\"] = True\n",
    "\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«ã”ã¨ã«å‡¦ç†\n",
    "for label, group in working_df.groupby('primary_label'):\n",
    "    if len(group) > config.num_prune_samples:\n",
    "        # ãƒ©ãƒ³ãƒ€ãƒ ã«500ä»¶ã‚’æ®‹ã™ï¼ˆæ®‹ã‚Šã‚’is_valid_audio=Falseã«ï¼‰\n",
    "        keep_indices = group.sample(n=config.num_prune_samples, random_state=config.seed).index\n",
    "        drop_indices = group.index.difference(keep_indices)\n",
    "        working_df.loc[drop_indices, 'is_valid_audio'] = False\n",
    "        print(label)\n",
    "\n",
    "print(f\"âœ… Marked {(~working_df['is_valid_audio']).sum()} samples as invalid (over {config.num_prune_samples} per label)\")\n",
    "\n",
    "\n",
    "# # # === 2. é™¤å»å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ False ã«ä¸Šæ›¸ã ===\n",
    "# fabio_remove_filenames = [\n",
    "#     '1139490/CSA36385.ogg',\n",
    "#     '1462737/CSA36369.ogg',\n",
    "#     '1462737/CSA36380.ogg',\n",
    "#     '1462737/CSA36381.ogg',\n",
    "#     '1462737/CSA36386.ogg',\n",
    "#     '1462737/CSA36391.ogg',\n",
    "#     '1462737/CSA36395.ogg',\n",
    "#     '963335/CSA36374.ogg',\n",
    "#     '963335/CSA36375.ogg',\n",
    "# ]\n",
    "# working_df.loc[working_df[\"filename\"].isin(fabio_remove_filenames), \"is_valid_audio\"] = False\n",
    "\n",
    "# ãƒã‚¤ã‚ºé™¤å»ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š\n",
    "working_df[\"apply_denoise\"] = False\n",
    "\n",
    "# fabio_denoise_filenames = [\n",
    "#     '1462711/CSA36371.ogg',\n",
    "#     '1462711/CSA36379.ogg',\n",
    "#     '963335/CSA36372.ogg',\n",
    "#     '963335/CSA36377.ogg',\n",
    "# ]\n",
    "\n",
    "# working_df.loc[working_df[\"filename\"].isin(fabio_denoise_filenames), \"apply_denoise\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of augmentations: 0\n"
     ]
    }
   ],
   "source": [
    "# augmentationã®ãŸã‚ã®å‡¦ç†ï¼å„éŸ³æºã§ã©ã‚Œãã‚‰ã„å¢—ã‚„ã™ã®ã‹ã‚’äº‹å‰ã«æ±ºå®š\n",
    "\n",
    "# åˆæœŸåŒ–\n",
    "working_df['n_augment'] = 0\n",
    "working_df['multi_crop'] = False\n",
    "\n",
    "target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "# valid_end_sec ãŒ None ãªã‚‰ duration_sec ã«è£œå®Œ\n",
    "working_df['valid_end_sec'] = working_df.apply(\n",
    "    lambda row: row['duration_sec'] if pd.isna(row['valid_end_sec']) else row['valid_end_sec'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# valid_start_sec ãŒ None ãªã‚‰ 0 ã«è£œå®Œï¼ˆå¿µã®ãŸã‚ï¼‰\n",
    "working_df['valid_start_sec'] = working_df['valid_start_sec'].fillna(0)\n",
    "\n",
    "# rareãªãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "label_counts = working_df['primary_label'].value_counts().rename_axis(\"label\").reset_index(name=\"sample_count\")\n",
    "rare_labels = label_counts[label_counts['sample_count'] < config.num_rare_samples]['label'].tolist()\n",
    "\n",
    "# âœ… rareç¨®ã”ã¨ã« crop æ•°ã‚’å‰²ã‚Šå½“ã¦ã‚‹\n",
    "for rare_label in rare_labels:\n",
    "    base_rows = working_df[working_df['primary_label'] == rare_label]\n",
    "    n_exist = len(base_rows)\n",
    "    n_needed = config.num_rare_samples - n_exist\n",
    "    n_aug_per_sample = math.ceil(n_needed / n_exist)\n",
    "\n",
    "    for idx, row in base_rows.iterrows():\n",
    "        usable_duration_sec = row['valid_end_sec'] - row['valid_start_sec']\n",
    "        usable_samples = int(usable_duration_sec * config.FS)\n",
    "\n",
    "        # å°‘ãªãã¨ã‚‚2å€ã«ã™ã‚‹\n",
    "        max_possible = usable_samples // target_samples\n",
    "        n_actual = min(n_aug_per_sample, max_possible)\n",
    "\n",
    "        if n_actual > 0:\n",
    "            working_df.at[idx, 'multi_crop'] = True\n",
    "            working_df.at[idx, 'n_augment'] = n_actual\n",
    "            \n",
    "            \n",
    "if not config.is_crop_aug:\n",
    "    working_df['n_augment'] = 0\n",
    "    working_df['multi_crop'] = False\n",
    "\n",
    "# num_augmented\n",
    "print(f\"Total number of augmentations: {working_df['n_augment'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_strategyã«åŸºã¥ã„ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šå‡ºã™\n",
    "# ç¾çŠ¶centerã—ã‹ä½¿ã£ã¦ãªã„ã®ã§ã‚ã¾ã‚Šæ„å‘³ãŒãªã„ã‚³ãƒ¼ãƒ‰ï¼\n",
    "def crop_audio(audio_data: np.ndarray, target_samples: int, strategy='center'):\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    if total_samples < target_samples:\n",
    "        n_copy = math.ceil(target_samples / total_samples)\n",
    "        audio_data = np.concatenate([audio_data] * n_copy)\n",
    "        total_samples = len(audio_data)\n",
    "\n",
    "    if strategy == 'head':\n",
    "        # 1ç§’é…ã‚‰ã›ã¦é–‹å§‹ï¼ˆãŸã ã—åã¾ã‚‰ãªã„å ´åˆã¯0ã‹ã‚‰ï¼‰\n",
    "        buffer = int(1.0 * config.FS)\n",
    "        start_idx = min(buffer, total_samples - target_samples)\n",
    "    elif strategy == 'tail':\n",
    "        start_idx = total_samples - target_samples\n",
    "    elif strategy == 'center':\n",
    "        start_idx = total_samples // 2 - target_samples // 2\n",
    "    elif strategy == 'random':\n",
    "        max_start = total_samples - target_samples\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "    elif isinstance(strategy, (float, int)):\n",
    "        start_idx = int(strategy * config.FS)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "    end_idx = start_idx + target_samples\n",
    "    return audio_data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# audioã‚’melã«å¤‰æ›\n",
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éŸ³æºã‚’melã«å¤‰ãˆã‚‹å‡¦ç†ï¼ä¸¦åˆ—åŒ–ã«å¯¾å¿œ\n",
    "def process_row(row):\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        mel_list = []\n",
    "        name_list = []\n",
    "\n",
    "        # === æœ‰åŠ¹ç¯„å›²ã‚’ç§’ â†’ ã‚µãƒ³ãƒ—ãƒ«ã«å¤‰æ› ===\n",
    "        valid_start_sec = row.get(\"valid_start_sec\", 0)\n",
    "        valid_end_sec = row.get(\"valid_end_sec\", None)\n",
    "        duration_sec = len(audio_data) / config.FS\n",
    "\n",
    "        if pd.isna(valid_end_sec) or valid_end_sec is None:\n",
    "            valid_end_sec = duration_sec\n",
    "\n",
    "        valid_start_sample = int(valid_start_sec * config.FS)\n",
    "        valid_end_sample = int(valid_end_sec * config.FS)\n",
    "\n",
    "        usable_audio = audio_data[valid_start_sample:valid_end_sample]\n",
    "        total_usable_samples = len(usable_audio)\n",
    "\n",
    "        # === ã‚ªãƒªã‚¸ãƒŠãƒ« clip ===\n",
    "        strategy = row.crop_strategy\n",
    "        try:\n",
    "            strategy = float(strategy)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        clip = crop_audio(usable_audio, target_samples, strategy=\"center\")  # strategyã¯centerå›ºå®š or ä»»æ„ã§ã‚‚å¯\n",
    "        if len(clip) < target_samples:\n",
    "            clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "        mel = audio2melspec(clip)\n",
    "        if mel.shape != config.TARGET_SHAPE:\n",
    "            mel = cv2.resize(mel, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        mel_list.append(mel.astype(np.float32))\n",
    "        name_list.append(row.samplename)\n",
    "\n",
    "        # === n_augment ã«å¿œã˜ã¦ crop ===\n",
    "        n_aug = int(row.get(\"n_augment\", 0))\n",
    "        if n_aug <= 0:\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "\n",
    "        interval = max((total_usable_samples - target_samples) // (n_aug + 1), 1)\n",
    "\n",
    "        for i in range(n_aug):\n",
    "            start_idx = min(i * interval, total_usable_samples - target_samples)\n",
    "            clip = usable_audio[start_idx: start_idx + target_samples]\n",
    "            if len(clip) < target_samples:\n",
    "                clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "            mel_crop = audio2melspec(clip)\n",
    "            if mel_crop.shape != config.TARGET_SHAPE:\n",
    "                mel_crop = cv2.resize(mel_crop, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "            mel_list.append(mel_crop.astype(np.float32))\n",
    "            name_list.append(f\"{row.samplename}_crop{i}\")\n",
    "\n",
    "        return list(zip(name_list, mel_list)), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melå¤‰æ›ã‚’ä¸¦åˆ—åŒ–\n",
    "results = Parallel(n_jobs=config.N_JOBS)(\n",
    "    delayed(process_row)(row) for _, row in working_df.iloc[:total_samples].iterrows()\n",
    ")\n",
    "\n",
    "# çµæœã®æ•´ç†\n",
    "all_bird_data = {}\n",
    "errors = []\n",
    "\n",
    "for result, err in results:\n",
    "    if result is not None:\n",
    "        for name, mel in result:\n",
    "            all_bird_data[name] = mel\n",
    "    if err is not None:\n",
    "        errors.append(err)\n",
    "        \n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "if errors:\n",
    "    print(\"Errors:\")\n",
    "    for filepath, error in errors:\n",
    "        print(f\"  {filepath}: {error}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… working_df_augmented created with 0 augmented rows.\n"
     ]
    }
   ],
   "source": [
    "# working_dfã«augmentã—ãŸãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¿½åŠ \n",
    "augmented_rows = []\n",
    "\n",
    "for _, row in working_df.iterrows():\n",
    "    n_aug = int(row.get('n_augment', 0))\n",
    "    if n_aug > 0:\n",
    "        for i in range(n_aug):\n",
    "            new_row = row.copy()\n",
    "            new_row['samplename'] = f\"{row.samplename}_crop{i}\"\n",
    "            augmented_rows.append(new_row)\n",
    "\n",
    "# DataFrameã«ã¾ã¨ã‚ã‚‹\n",
    "augmented_rows = pd.DataFrame(augmented_rows)\n",
    "working_df_augmented = pd.concat([working_df, augmented_rows], ignore_index=True)\n",
    "print(f\"âœ… working_df_augmented created with {len(augmented_rows)} augmented rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # äº‹å‰ã«foldã‚’æ±ºã‚ã¦ãŠãï¼5foldï¼\n",
    "\n",
    "\n",
    "# working_df_augmented['group_id'] = working_df_augmented['samplename'].map(lambda x: x.split('_crop')[0])\n",
    "\n",
    "# # fold åˆ—ã‚’åˆæœŸåŒ–\n",
    "# working_df_augmented['fold'] = -1\n",
    "\n",
    "# # âœ… stratify + group ä¸¡ç«‹ï¼\n",
    "# sgkf = StratifiedGroupKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "# groups = working_df_augmented['group_id']\n",
    "# labels = working_df_augmented['primary_label']\n",
    "\n",
    "# for fold_id, (_, val_idx) in enumerate(sgkf.split(working_df_augmented, labels, groups=groups)):\n",
    "#     working_df_augmented.loc[val_idx, 'fold'] = fold_id\n",
    "\n",
    "# fold ã‚’å›ºå®šã™ã‚‹\n",
    "train_0419 = pd.read_csv(\"../data/processed/mel_cleaned_0419/train.csv\")\n",
    "# cropå‰ã® fold æƒ…å ±ã‚’è¾æ›¸åŒ–\n",
    "fold_map = train_0419.set_index(\"samplename\")[\"fold\"].to_dict()\n",
    "\n",
    "# cropå¾Œã® working_df_augmented ã« fold ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "working_df_augmented[\"group_id\"] = working_df_augmented[\"samplename\"].map(lambda x: x.split(\"_crop\")[0])\n",
    "working_df_augmented[\"fold\"] = working_df_augmented[\"group_id\"].map(fold_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Removed 0 rows marked as invalid audio.\n",
      "âœ… Final training set size: 28564\n"
     ]
    }
   ],
   "source": [
    "# === ç„¡åŠ¹ãªéŸ³æºã‚’é™¤å¤–ï¼ˆfoldä»˜ä¸å¾Œï¼‰ ===\n",
    "working_df_filtered = working_df_augmented[working_df_augmented[\"is_valid_audio\"]].reset_index(drop=True)\n",
    "\n",
    "print(f\"ğŸ“‰ Removed {len(working_df_augmented) - len(working_df_filtered)} rows marked as invalid audio.\")\n",
    "print(f\"âœ… Final training set size: {len(working_df_filtered)}\")\n",
    "\n",
    "working_df_augmented = working_df_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Mel-spectrograms saved to: ../data/processed/melspec_20250424_2207/birdclef2025_melspec_5sec_256_256.npy\n",
      "ğŸ“¦ File size: 7143.48 MB\n",
      "ğŸ“ Example shape: (256, 256)\n",
      "ğŸ“ Config saved to: ../data/processed/melspec_20250424_2207/config.csv\n",
      "ğŸ“ Augmented training metadata saved to: ../data/processed/melspec_20250424_2207/train.csv\n",
      "ğŸ“Š Total rows: 28564\n"
     ]
    }
   ],
   "source": [
    "# melã¨working_dfã‚’ä¿å­˜ï¼working_dfã¯train.csvã¨ã—ã¦ä¿å­˜\n",
    "\n",
    "# 4mins\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JSTæ™‚åˆ»ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# âœ… ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ debug ã«å¿œã˜ã¦åˆ†å²\n",
    "if config.debug:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ä¿å­˜ ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\nâœ… Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"ğŸ“¦ File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"ğŸ“ Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configã®ä¿å­˜ ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(config).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"ğŸ“ Config saved to: {config_path}\")\n",
    "\n",
    "\n",
    "# âœ… train.csv ã¨ã—ã¦ä¿å­˜\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df_augmented.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"ğŸ“ Augmented training metadata saved to: {train_csv_path}\")\n",
    "print(f\"ğŸ“Š Total rows: {len(working_df_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Foldä¸€è‡´: 28564 / 28564 (100.00%)\n",
      "ğŸ‰ Fold assignment is consistent across all records.\n"
     ]
    }
   ],
   "source": [
    "# train_0419: samplename â†’ fold ã®ãƒãƒƒãƒ—ã‚’ä½œæˆ\n",
    "fold_map = train_0419.set_index(\"samplename\")[\"fold\"].to_dict()\n",
    "\n",
    "# working_df_augmented å´ã®å…ƒ clip ã«å¯¾ã™ã‚‹fold\n",
    "working_df_augmented[\"group_id\"] = working_df_augmented[\"samplename\"].map(lambda x: x.split(\"_crop\")[0])\n",
    "working_df_augmented[\"fold_from_train0419\"] = working_df_augmented[\"group_id\"].map(fold_map)\n",
    "\n",
    "# æ¯”è¼ƒï¼šfoldåˆ—ã¨fold_from_train0419åˆ—ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹\n",
    "match = (working_df_augmented[\"fold\"] == working_df_augmented[\"fold_from_train0419\"])\n",
    "num_total = len(working_df_augmented)\n",
    "num_match = match.sum()\n",
    "\n",
    "print(f\"âœ… Foldä¸€è‡´: {num_match} / {num_total} ({100*num_match/num_total:.2f}%)\")\n",
    "\n",
    "# 100%ä¸€è‡´ã—ã¦ã„ãªã„ã¨ãã®å·®åˆ†ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰\n",
    "if num_match != num_total:\n",
    "    mismatches = working_df_augmented[~match][[\"samplename\", \"group_id\", \"fold\", \"fold_from_train0419\"]]\n",
    "    print(\"âŒ Fold mismatch detected!\")\n",
    "    display(mismatches.head())\n",
    "else:\n",
    "    print(\"ğŸ‰ Fold assignment is consistent across all records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabioã®è§£èª¬ã€€å¿…ãšã—ã‚‚7secã§ã¯ãªã„\n",
    "# 48124/CSA36346.ogg 24secä»¥é™\n",
    "# 52884/CSA36344.ogg 55secä»¥é™\n",
    "# 52884/CSA36342.ogg 14secä»¥é™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19\n",
    "idx_list = working_df[working_df[\"collection\"] == \"CSA\"][\"primary_label\"].unique()\n",
    "df = working_df[working_df[\"primary_label\"] == f\"{idx_list[i]}\"][[\"primary_label\", \"filename\", \"author\", \"valid_end_sec\", \"duration_sec\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSAãƒã‚§ãƒƒã‚¯\n",
    "# æœ€å¾Œã«ã‚¹ãƒšã‚¤ãƒ³èªãŒå«ã¾ã‚Œã¦ã„ãªã„label\n",
    "# 1564122, 50186/CSA28885.ogg, 523060\n",
    "# 52884/CSA14875.ogg\n",
    "# 548639\n",
    "# 714022\n",
    "# 868458\n",
    "\n",
    "\n",
    "\n",
    "# ã‚¹ãƒšã‚¤ãƒ³èªæœ€åˆã«å«ã¾ã‚Œã‚‹ 4secãã‚‰ã„\n",
    "# 50186/CSA28885.ogg\n",
    "# 52884/CSA14875.ogg\n",
    "\n",
    "\n",
    "\n",
    "# è©±ã—ã¦ã‚‹äºº\n",
    "# Eliana Barona- CortÃ©s\n",
    "# Alexandra Butrago-Cardona\n",
    "# Fabio A. Sarria-S\n",
    "\n",
    "# äººã®å£°ã ã‘ã®ç®‡æ‰€\n",
    "# 24292/CSA34649.ogg 2min48ç§»è¡Œ\n",
    "# 24292/CSA34651.ogg 1min34ç§»è¡Œ\n",
    "# 476537/CSA35459.ogg 2min14ç§»è¡Œ\n",
    "# 476537/CSA35461.ogg 4min19ç§»è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_label\n",
       "grekis     990\n",
       "compau     808\n",
       "trokin     787\n",
       "roahaw     709\n",
       "banana     610\n",
       "          ... \n",
       "1564122      6\n",
       "42087        5\n",
       "528041       4\n",
       "1139490      4\n",
       "21116        3\n",
       "Name: count, Length: 206, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ£’ã‚°ãƒ©ãƒ•\n",
    "\n",
    "working_df_augmented[\"primary_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
