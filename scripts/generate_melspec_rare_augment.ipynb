{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from module import config_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # 全modelの保存先\n",
    "            self.model_path = self.models_dir # 各モデルの保存先．学習時に動的に変更．\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5.0 # 推論時のウィンドウサイズ\n",
    "        self.TARGET_DURATION = 5 # データセット作成時のウィンドウサイズ\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 16\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 16  # 並列処理のスレッド数 16くらいでいい\n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeしないならTrue\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = DatasetConfig(kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: OFF\n",
      "Max samples to process: ALL\n",
      "Loading taxonomy data...\n",
      "Loading training metadata...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{config.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{config.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 unique species\n",
      "Total samples to process: 28564 out of 28564 available\n",
      "Samples by class:\n",
      "class\n",
      "Aves        27648\n",
      "Amphibia      583\n",
      "Mammalia      178\n",
      "Insecta       155\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_list = sorted(train_df['primary_label'].unique())\n",
    "label_id_list = list(range(len(label_list)))\n",
    "label2id = dict(zip(label_list, label_id_list))\n",
    "id2label = dict(zip(label_id_list, label_list))\n",
    "\n",
    "print(f'Found {len(label_list)} unique species')\n",
    "working_df = train_df.copy()\n",
    "working_df['target'] = working_df.primary_label.map(label2id)\n",
    "working_df['filepath'] = config.RAW_DIR + '/train_audio/' + working_df.filename\n",
    "working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "working_df[\"crop_strategy\"] = \"center\"\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')\n",
    "print(f'Samples by class:')\n",
    "print(working_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabio A. Sarria-Sの音声は最初にInsectaの鳴き声があるため，最初をcropしたい\n",
    "# crop_starategyを'head'に変更する\n",
    "\n",
    "# 1. \"Fabio A. Sarria-S\" の filename を抽出\n",
    "fabio_filenames = train_df.loc[\n",
    "    train_df['author'] == \"Fabio A. Sarria-S\", 'filename'\n",
    "].tolist()\n",
    "\n",
    "# 2. working_df の crop_strategy を 'head' に更新\n",
    "working_df['crop_strategy'] = working_df.get('crop_strategy', 'center')  # 初期化（なければcenter）\n",
    "\n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(fabio_filenames),\n",
    "    'crop_strategy'\n",
    "] = 'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rareなラベルに対し，multi-cropを行うためのflag設定\n",
    "\n",
    "# rareなラベルを抽出（例：50未満）\n",
    "label_counts = working_df['primary_label'].value_counts().rename_axis(\"label\").reset_index(name=\"sample_count\")\n",
    "rare_labels = label_counts[label_counts['sample_count'] < 50]['label'].tolist()\n",
    "\n",
    "# 初期値は0\n",
    "working_df['n_augment'] = 0\n",
    "working_df['multi_crop'] = False\n",
    "\n",
    "# rare種に対して必要なaugment数を計算して割り当て\n",
    "for rare_label in rare_labels:\n",
    "    base_rows = working_df[working_df['primary_label'] == rare_label]\n",
    "    n_exist = len(base_rows)\n",
    "    n_needed = 50 - n_exist\n",
    "\n",
    "    n_aug_per_sample = math.ceil(n_needed / n_exist)\n",
    "\n",
    "    # フラグとaugment数をセット\n",
    "    working_df.loc[\n",
    "        working_df['primary_label'] == rare_label, 'multi_crop'\n",
    "    ] = True\n",
    "    working_df.loc[\n",
    "        working_df['primary_label'] == rare_label, 'n_augment'\n",
    "    ] = n_aug_per_sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_strategyに基づいて音声データを切り出す\n",
    "def crop_audio(audio_data: np.ndarray, target_samples: int, strategy='center'):\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    if total_samples < target_samples:\n",
    "        n_copy = math.ceil(target_samples / total_samples)\n",
    "        audio_data = np.concatenate([audio_data] * n_copy)\n",
    "        total_samples = len(audio_data)\n",
    "\n",
    "    if strategy == 'head':\n",
    "        # 1秒遅らせて開始（ただし収まらない場合は0から）\n",
    "        buffer = int(1.0 * config.FS)\n",
    "        start_idx = min(buffer, total_samples - target_samples)\n",
    "    elif strategy == 'tail':\n",
    "        start_idx = total_samples - target_samples\n",
    "    elif strategy == 'center':\n",
    "        start_idx = total_samples // 2 - target_samples // 2\n",
    "    elif strategy == 'random':\n",
    "        max_start = total_samples - target_samples\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "    elif isinstance(strategy, (float, int)):\n",
    "        start_idx = int(strategy * config.FS)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "    end_idx = start_idx + target_samples\n",
    "    return audio_data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "        strategy = row.crop_strategy\n",
    "        try:\n",
    "            strategy = float(strategy)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        mel_list = []\n",
    "        name_list = []\n",
    "\n",
    "        # ✅ オリジナル clip\n",
    "        clip = crop_audio(audio_data, target_samples, strategy=strategy)\n",
    "        if len(clip) < target_samples:\n",
    "            clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "        mel = audio2melspec(clip)\n",
    "        if mel.shape != config.TARGET_SHAPE:\n",
    "            mel = cv2.resize(mel, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        mel_list.append(mel.astype(np.float32))\n",
    "        name_list.append(row.samplename)\n",
    "\n",
    "        # augmnetする数\n",
    "        n_crops = int(row.get('n_augment', 0))\n",
    "        \n",
    "        # augmentなしならそのまま返す\n",
    "        if n_crops <= 0:\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "\n",
    "        # 🔁 head の場合は複製して終了\n",
    "        if row.crop_strategy == 'head':\n",
    "            for i in range(n_crops):\n",
    "                mel_list.append(mel.astype(np.float32))\n",
    "                name_list.append(f\"{row.samplename}_crop{i}\")\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "\n",
    "        # レア種は均等分割 crop\n",
    "        total_samples = len(audio_data)\n",
    "        interval = max((total_samples - target_samples) // (n_crops + 1), 1)\n",
    "        for i in range(n_crops):\n",
    "            start_idx = i * interval\n",
    "            clip = audio_data[start_idx: start_idx + target_samples]\n",
    "            if len(clip) < target_samples:\n",
    "                clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "            mel_crop = audio2melspec(clip)\n",
    "            if mel_crop.shape != config.TARGET_SHAPE:\n",
    "                mel_crop = cv2.resize(mel_crop, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "            mel_list.append(mel_crop.astype(np.float32))\n",
    "            name_list.append(f\"{row.samplename}_crop{i}\")\n",
    "\n",
    "        return list(zip(name_list, mel_list)), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=config.N_JOBS)(\n",
    "    delayed(process_row)(row) for _, row in working_df.iloc[:total_samples].iterrows()\n",
    ")\n",
    "\n",
    "# 結果の整理\n",
    "all_bird_data = {}\n",
    "errors = []\n",
    "\n",
    "for result, err in results:\n",
    "    if result is not None:\n",
    "        for name, mel in result:\n",
    "            all_bird_data[name] = mel\n",
    "    if err is not None:\n",
    "        errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ working_df_augmented created with 3349 augmented rows.\n"
     ]
    }
   ],
   "source": [
    "# working_dfにaugmentしたデータ情報を追加\n",
    "augmented_rows = []\n",
    "\n",
    "for _, row in working_df.iterrows():\n",
    "    n_aug = int(row.get('n_augment', 0))\n",
    "    if n_aug > 0:\n",
    "        for i in range(n_aug):\n",
    "            new_row = row.copy()\n",
    "            new_row['samplename'] = f\"{row.samplename}_crop{i}\"\n",
    "            augmented_rows.append(new_row)\n",
    "\n",
    "# DataFrameにまとめる\n",
    "augmented_rows = pd.DataFrame(augmented_rows)\n",
    "working_df_augmented = pd.concat([working_df, augmented_rows], ignore_index=True)\n",
    "print(f\"✅ working_df_augmented created with {len(augmented_rows)} augmented rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldを決めておく\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "working_df_augmented['group_id'] = working_df_augmented['samplename'].map(lambda x: x.split('_crop')[0])\n",
    "\n",
    "# fold 列を初期化\n",
    "working_df_augmented['fold'] = -1\n",
    "\n",
    "# ✅ stratify + group 両立！\n",
    "sgkf = StratifiedGroupKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "groups = working_df_augmented['group_id']\n",
    "labels = working_df_augmented['primary_label']\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(sgkf.split(working_df_augmented, labels, groups=groups)):\n",
    "    working_df_augmented.loc[val_idx, 'fold'] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Config saved to: ../data/processed/melspec_20250412_1533/config.csv\n",
      "📝 Augmented training metadata saved to: ../data/processed/melspec_20250412_1533/train.csv\n",
      "📊 Total rows: 31913\n"
     ]
    }
   ],
   "source": [
    "# 4mins\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JST時刻でディレクトリ作成 ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# ✅ 保存先フォルダを debug に応じて分岐\n",
    "if config.debug:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melスペクトログラムの保存 ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\n✅ Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"📦 File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"📐 Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configの保存 ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(config).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"📝 Config saved to: {config_path}\")\n",
    "\n",
    "\n",
    "# ✅ train.csv として保存\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df_augmented.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"📝 Augmented training metadata saved to: {train_csv_path}\")\n",
    "print(f\"📊 Total rows: {len(working_df_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = np.load(\"../data/processed/mel_0411/birdclef2025_melspec_5sec_256_256.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
