{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:08.345462Z",
     "iopub.status.busy": "2025-05-13T10:59:08.345156Z",
     "iopub.status.idle": "2025-05-13T10:59:14.93201Z",
     "shell.execute_reply": "2025-05-13T10:59:14.931234Z",
     "shell.execute_reply.started": "2025-05-13T10:59:08.345438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:14.934318Z",
     "iopub.status.busy": "2025-05-13T10:59:14.933773Z",
     "iopub.status.idle": "2025-05-13T10:59:14.941619Z",
     "shell.execute_reply": "2025-05-13T10:59:14.940867Z",
     "shell.execute_reply.started": "2025-05-13T10:59:14.934291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "            self.RAW_DIR = \"/kaggle/input/birdclef-2025/\"\n",
    "            self.PROCESSED_DIR = \"\"\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # 全modelの保存先\n",
    "            self.model_path = self.models_dir # 各モデルの保存先．学習時に動的に変更．\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5.0 # 推論時のウィンドウサイズ\n",
    "        self.TARGET_DURATION = 5 # データセット作成時のウィンドウサイズ\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 3\n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeしないならTrue\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "        self.num_rare_samples = 50 # これ以下のサンプル数のspeciesはrare speciesとして扱う\n",
    "        self.is_crop_aug = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:14.943381Z",
     "iopub.status.busy": "2025-05-13T10:59:14.943034Z",
     "iopub.status.idle": "2025-05-13T10:59:14.965858Z",
     "shell.execute_reply": "2025-05-13T10:59:14.964908Z",
     "shell.execute_reply.started": "2025-05-13T10:59:14.943348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = DatasetConfig(kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:14.967054Z",
     "iopub.status.busy": "2025-05-13T10:59:14.966807Z",
     "iopub.status.idle": "2025-05-13T10:59:14.990737Z",
     "shell.execute_reply": "2025-05-13T10:59:14.989422Z",
     "shell.execute_reply.started": "2025-05-13T10:59:14.967025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:14.992177Z",
     "iopub.status.busy": "2025-05-13T10:59:14.991827Z",
     "iopub.status.idle": "2025-05-13T10:59:15.200304Z",
     "shell.execute_reply": "2025-05-13T10:59:15.199361Z",
     "shell.execute_reply.started": "2025-05-13T10:59:14.992141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Debug mode: {'ON' if config.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{config.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{config.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:15.202718Z",
     "iopub.status.busy": "2025-05-13T10:59:15.20246Z",
     "iopub.status.idle": "2025-05-13T10:59:15.668312Z",
     "shell.execute_reply": "2025-05-13T10:59:15.667466Z",
     "shell.execute_reply.started": "2025-05-13T10:59:15.202695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_list = sorted(train_df['primary_label'].unique()) # ① データフレーム中の primary_label 列から重複を除いたリストを取得し、アルファベット順にソート\n",
    "label_id_list = list(range(len(label_list)))   # ② 0 から始まる ID のリストを、ラベル数に合わせて作成\n",
    "label2id = dict(zip(label_list, label_id_list)) # ③ ラベル文字列 → 整数 ID の辞書を作成\n",
    "id2label = dict(zip(label_id_list, label_list)) # ④ 整数 ID → ラベル文字列 の逆辞書も作成\n",
    "\n",
    "print(f'Found {len(label_list)} unique species')\n",
    "working_df = train_df.copy()\n",
    "working_df['target'] = working_df.primary_label.map(label2id)\n",
    "working_df['filepath'] = config.RAW_DIR + '/train_audio/' + working_df.filename\n",
    "working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "working_df[\"crop_strategy\"] = \"center\"\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')\n",
    "print(f'Samples by class:')\n",
    "print(working_df['class'].value_counts())\n",
    "\n",
    "# 音源の長さ， foldをロードして追加． \n",
    "duration_fold_df = pd.read_csv(\"../data/processed/train_mel0413.csv\")[[\"filename\", \"duration_sec\", \"fold\"]]\n",
    "working_df = working_df.merge(duration_fold_df, on=\"filename\", how=\"left\")\n",
    "\n",
    "missing = working_df[\"duration_sec\"].isna().sum()\n",
    "print(f\"✅ Added 'duration_sec'. Missing values: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:15.669959Z",
     "iopub.status.busy": "2025-05-13T10:59:15.669712Z",
     "iopub.status.idle": "2025-05-13T10:59:15.674908Z",
     "shell.execute_reply": "2025-05-13T10:59:15.674033Z",
     "shell.execute_reply.started": "2025-05-13T10:59:15.669936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "working_df[\"valid_start_sec\"] = 0\n",
    "working_df[\"valid_end_sec\"] = working_df[\"duration_sec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:15.6761Z",
     "iopub.status.busy": "2025-05-13T10:59:15.6758Z",
     "iopub.status.idle": "2025-05-13T10:59:15.696389Z",
     "shell.execute_reply": "2025-05-13T10:59:15.695553Z",
     "shell.execute_reply.started": "2025-05-13T10:59:15.676077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "working_df['duration_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:15.697593Z",
     "iopub.status.busy": "2025-05-13T10:59:15.697352Z",
     "iopub.status.idle": "2025-05-13T10:59:15.751105Z",
     "shell.execute_reply": "2025-05-13T10:59:15.750252Z",
     "shell.execute_reply.started": "2025-05-13T10:59:15.697571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 手動で人の声除去\n",
    "\n",
    "# 4. 特定のファイルの valid_start_sec を変更\n",
    "# 特定のファイル（最初にスペイン語が含まれる）\n",
    "spanish_intro_filenames = [\n",
    "    '50186/CSA28885.ogg',\n",
    "    '52884/CSA14875.ogg'\n",
    "]\n",
    "# valid_start_sec を 4.0 に変更\n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(spanish_intro_filenames),\n",
    "    'valid_start_sec'\n",
    "] = 4.0\n",
    "\n",
    "\n",
    "# 途中で人の声のみになるので除去\n",
    "voice_only_ranges = {\n",
    "    '476537/CSA35459.ogg': 134,  # 2分14秒 = 134秒\n",
    "    '476537/CSA35461.ogg': 259,  # 4分19秒 = 259秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Eliana Barona- Cortés　の音源．話している部分．いらない部分\n",
    "# 24292/CSA34649.ogg 2min8以降\n",
    "# 24292/CSA34651.ogg 1min33以降\n",
    "# 50186/CSA34622.ogg 21s以降\n",
    "# 50186/CSA34678.ogg 43s以降\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA34649.ogg': 128,   # 2分8秒 = 128秒\n",
    "    '24292/CSA34651.ogg': 93,    # 1分33秒 = 93秒\n",
    "    '50186/CSA34622.ogg': 21,    # 21秒\n",
    "    '50186/CSA34678.ogg': 43,    # 43秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "# Alexandra Butrago-Cardona の音源チェック\n",
    "# 話している部分．いらない部分\n",
    "# 24292/CSA35021.ogg 36s以降\n",
    "# 52884/CSA34947.ogg 13s以降\n",
    "voice_only_ranges = {\n",
    "    '24292/CSA35021.ogg': 36,    # 36秒\n",
    "    '52884/CSA34947.ogg': 13,     # 13秒\n",
    "}\n",
    "for fname, end_sec in voice_only_ranges.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# Fabio A. Sarria-S の音声は 0〜7秒 だけ使用可能に設定．後半はただの説明なので\n",
    "fabio_filenames = train_df.loc[\n",
    "    train_df['author'] == \"Fabio A. Sarria-S\", 'filename'\n",
    "].tolist()\n",
    "# \n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(fabio_filenames), 'valid_end_sec'\n",
    "] = 7.0\n",
    "\n",
    "#  Fabioの解説で，必ずしも7secではないもの\n",
    "fabio_override = {\n",
    "    \"48124/CSA36346.ogg\": 24.0,\n",
    "    \"52884/CSA36344.ogg\": 55.0,\n",
    "    \"52884/CSA36342.ogg\": 14.0,  # ← 追加分\n",
    "}\n",
    "\n",
    "for fname, end_sec in fabio_override.items():\n",
    "    working_df.loc[\n",
    "        working_df['filename'] == fname,\n",
    "        'valid_end_sec'\n",
    "    ] = end_sec\n",
    "\n",
    "\n",
    "# crop戦略は基本center\n",
    "working_df[\"crop_strategy\"] = \"center\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T10:59:15.752525Z",
     "iopub.status.busy": "2025-05-13T10:59:15.752159Z",
     "iopub.status.idle": "2025-05-13T10:59:15.837587Z",
     "shell.execute_reply": "2025-05-13T10:59:15.83681Z",
     "shell.execute_reply.started": "2025-05-13T10:59:15.752487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# safezoneをworking_dfに反映．\n",
    "\n",
    "# safe_zoneを準備（すでに\"checked\"のみ、重複除去済み）\n",
    "safe_zone = pd.read_csv(\"../data/processed/safezone_1000_0501.csv\")\n",
    "safe_zone = safe_zone[safe_zone[\"check\"] == \"checked\"]\n",
    "safe_zone = safe_zone.drop_duplicates(subset=[\"filename\"])  #filename 列を基準にして、重複するファイル名を持つ行は最初の1つだけ残し、あとは削除\n",
    "\n",
    "# start, endをfloatに変換\n",
    "safe_zone[\"start\"] = pd.to_numeric(safe_zone[\"start\"], errors=\"coerce\") #errors=\"coerce\" を指定しているので、もし変換できない値があれば NaN に置き換え\n",
    "safe_zone[\"end\"] = pd.to_numeric(safe_zone[\"end\"], errors=\"coerce\")\n",
    "\n",
    "# safe_zoneから必要なカラムだけ持ってくる\n",
    "safe_zone_update = safe_zone[[\"filename\", \"start\", \"end\"]]\n",
    "\n",
    "# working_dfも用意されている想定\n",
    "\n",
    "# working_dfにsafe_zoneのstart, endをマージする\n",
    "working_df = working_df.merge(safe_zone_update, on=\"filename\", how=\"left\")\n",
    "\n",
    "# start, endが存在するものについて、valid_start_sec, valid_end_secを書き換え\n",
    "working_df[\"valid_start_sec\"] = working_df[\"start\"].combine_first(working_df[\"valid_start_sec\"])  #safe_zone に start・end があれば、それを valid_start_sec・valid_end_secに上書き\n",
    "working_df[\"valid_end_sec\"] = working_df[\"end\"].combine_first(working_df[\"valid_end_sec\"])\n",
    "\n",
    "# 使い終わったstart, endカラムを消す（必要なら）\n",
    "working_df = working_df.drop(columns=[\"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:03:25.851341Z",
     "iopub.status.busy": "2025-05-13T11:03:25.850959Z",
     "iopub.status.idle": "2025-05-13T11:03:25.891226Z",
     "shell.execute_reply": "2025-05-13T11:03:25.890463Z",
     "shell.execute_reply.started": "2025-05-13T11:03:25.851309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# safe_zoneを準備（すでに\"checked\"のみ、重複除去済み）\n",
    "safe_zone = pd.read_csv(\"../data/processed/safezone_1000_2000.csv\")\n",
    "safe_zone = safe_zone[safe_zone[\"is_checked\"] == \"checked\"]\n",
    "safe_zone = safe_zone.drop_duplicates(subset=[\"filename\"])  #filename 列を基準にして、重複するファイル名を持つ行は最初の1つだけ残し、あとは削除\n",
    "\n",
    "# start, endをfloatに変換\n",
    "safe_zone[\"start\"] = pd.to_numeric(safe_zone[\"start\"], errors=\"coerce\") #errors=\"coerce\" を指定しているので、もし変換できない値があれば NaN に置き換え\n",
    "safe_zone[\"end\"] = pd.to_numeric(safe_zone[\"end\"], errors=\"coerce\")\n",
    "\n",
    "# safe_zoneから必要なカラムだけ持ってくる\n",
    "safe_zone_update = safe_zone[[\"filename\", \"start\", \"end\"]]\n",
    "\n",
    "# working_dfも用意されている想定\n",
    "\n",
    "# working_dfにsafe_zoneのstart, endをマージする\n",
    "working_df = working_df.merge(safe_zone_update, on=\"filename\", how=\"left\")\n",
    "\n",
    "# start, endが存在するものについて、valid_start_sec, valid_end_secを書き換え\n",
    "working_df[\"valid_start_sec\"] = working_df[\"start\"].combine_first(working_df[\"valid_start_sec\"])  #safe_zone に start・end があれば、それを valid_start_sec・valid_end_secに上書き\n",
    "working_df[\"valid_end_sec\"] = working_df[\"end\"].combine_first(working_df[\"valid_end_sec\"])\n",
    "\n",
    "# 使い終わったstart, endカラムを消す（必要なら）\n",
    "working_df = working_df.drop(columns=[\"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:02:23.02168Z",
     "iopub.status.busy": "2025-05-13T11:02:23.021319Z",
     "iopub.status.idle": "2025-05-13T11:02:23.072505Z",
     "shell.execute_reply": "2025-05-13T11:02:23.071282Z",
     "shell.execute_reply.started": "2025-05-13T11:02:23.021652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# safe_zoneを準備（すでに\"checked\"のみ、重複除去済み）\n",
    "safe_zone = pd.read_csv(\"../data/processed/safezone_2000_3000.csv\")\n",
    "safe_zone = safe_zone[safe_zone[\"check\"] == \"checked\"]\n",
    "safe_zone = safe_zone.drop_duplicates(subset=[\"filename\"])  #filename 列を基準にして、重複するファイル名を持つ行は最初の1つだけ残し、あとは削除\n",
    "\n",
    "# start, endをfloatに変換\n",
    "safe_zone[\"start\"] = pd.to_numeric(safe_zone[\"start\"], errors=\"coerce\") #errors=\"coerce\" を指定しているので、もし変換できない値があれば NaN に置き換え\n",
    "safe_zone[\"end\"] = pd.to_numeric(safe_zone[\"end\"], errors=\"coerce\")\n",
    "\n",
    "# safe_zoneから必要なカラムだけ持ってくる\n",
    "safe_zone_update = safe_zone[[\"filename\", \"start\", \"end\"]]\n",
    "\n",
    "# working_dfも用意されている想定\n",
    "\n",
    "# working_dfにsafe_zoneのstart, endをマージする\n",
    "working_df = working_df.merge(safe_zone_update, on=\"filename\", how=\"left\")\n",
    "\n",
    "# start, endが存在するものについて、valid_start_sec, valid_end_secを書き換え\n",
    "working_df[\"valid_start_sec\"] = working_df[\"start\"].combine_first(working_df[\"valid_start_sec\"])  #safe_zone に start・end があれば、それを valid_start_sec・valid_end_secに上書き\n",
    "working_df[\"valid_end_sec\"] = working_df[\"end\"].combine_first(working_df[\"valid_end_sec\"])\n",
    "\n",
    "# 使い終わったstart, endカラムを消す（必要なら）\n",
    "working_df = working_df.drop(columns=[\"start\", \"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_augmented_rows(new_files, working_df, base_dir=\"../data/raw/bc2025_rare\"):\n",
    "    \"\"\"\n",
    "    新しいファイル情報を基に working_df を拡張するための行を準備する\n",
    "    \"\"\"\n",
    "    augmented_rows = []\n",
    "    \n",
    "    for item in new_files:\n",
    "        label = item[\"primary_label\"]\n",
    "        original_fname = item[\"filename\"]\n",
    "        \n",
    "        # ファイルパスを整形\n",
    "        fname = os.path.splitext(original_fname)[0] + '.ogg'\n",
    "        full_path = os.path.join(base_dir, fname)\n",
    "        \n",
    "        # 同じラベルの既存データを取得\n",
    "        match = working_df[working_df[\"primary_label\"] == label]\n",
    "        \n",
    "        if not match.empty:\n",
    "            new_row = match.iloc[0].copy()\n",
    "            new_row[\"filename\"] = fname\n",
    "            new_row[\"filepath\"] = full_path\n",
    "            sample_prefix = os.path.dirname(fname)\n",
    "            sample_name = os.path.splitext(os.path.basename(fname))[0]\n",
    "            new_row[\"samplename\"] = f\"{sample_prefix}-{sample_name}\"\n",
    "            new_row[\"fold\"] = 1  # foldは未割り当て\n",
    "            new_row[\"duration_time\"]= None  # duration_timeは未割り当て\n",
    "            new_row[\"valid_end_sec\"] = None\n",
    "            \n",
    "            augmented_rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(augmented_rows)\n",
    "\n",
    "# 使用例\n",
    "new_files = [\n",
    "    {\"filename\": \"1139490/2391.ogg\", \"primary_label\": \"1139490\"},\n",
    "    {\"filename\": \"42113/XC975063.ogg\", \"primary_label\": \"42113\"},\n",
    "    {\"filename\": \"66016/vaillanti-escape1.ogg\", \"primary_label\": \"66016\"},\n",
    "    {\"filename\": \"66016/vaillanti-escape3.ogg\", \"primary_label\": \"66016\"},\n",
    "    {\"filename\": \"66016/vaillanti-escape4.ogg\", \"primary_label\": \"66016\"},\n",
    "    {\"filename\": \"66578/Pristimantis_bogotensis15.ogg\", \"primary_label\": \"66578\"},\n",
    "    {\"filename\": \"868458/2388.ogg\", \"primary_label\": \"868458\"},\n",
    "    {\"filename\": \"turvul/XC39894.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC381486.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC520288.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC552488.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC748979.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC764680.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC780516.ogg\", \"primary_label\": \"turvul\"},\n",
    "    {\"filename\": \"turvul/XC904279.ogg\", \"primary_label\": \"turvul\"},\n",
    "]\n",
    "\n",
    "# ここで実際に拡張する\n",
    "augmented_df = prepare_augmented_rows(new_files, working_df)\n",
    "working_df = pd.concat([working_df, augmented_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T11:02:26.448936Z",
     "iopub.status.busy": "2025-05-13T11:02:26.448592Z",
     "iopub.status.idle": "2025-05-13T11:02:27.041456Z",
     "shell.execute_reply": "2025-05-13T11:02:27.040514Z",
     "shell.execute_reply.started": "2025-05-13T11:02:26.448904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# augmentationのための処理．各音源でどれくらい増やすのかを事前に決定\n",
    "\n",
    "# 初期化\n",
    "working_df['n_augment'] = 0\n",
    "working_df['multi_crop'] = False\n",
    "\n",
    "target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "# valid_end_sec が None なら duration_sec に補完\n",
    "working_df['valid_end_sec'] = working_df.apply(\n",
    "    lambda row: row['duration_sec'] if pd.isna(row['valid_end_sec']) else row['valid_end_sec'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# valid_start_sec が None なら 0 に補完（念のため）\n",
    "working_df['valid_start_sec'] = working_df['valid_start_sec'].fillna(0)\n",
    "\n",
    "# rareなラベルを抽出\n",
    "label_counts = working_df['primary_label'].value_counts().rename_axis(\"label\").reset_index(name=\"sample_count\")\n",
    "rare_labels = label_counts[label_counts['sample_count'] < config.num_rare_samples]['label'].tolist()\n",
    "\n",
    "# ✅ rare種ごとに crop 数を割り当てる\n",
    "for rare_label in rare_labels:\n",
    "    base_rows = working_df[working_df['primary_label'] == rare_label]\n",
    "    n_exist = len(base_rows)\n",
    "    n_needed = config.num_rare_samples - n_exist\n",
    "    n_aug_per_sample = math.ceil(n_needed / n_exist)\n",
    "\n",
    "    for idx, row in base_rows.iterrows():\n",
    "        usable_duration_sec = row['valid_end_sec'] - row['valid_start_sec']\n",
    "        usable_samples = int(usable_duration_sec * config.FS)\n",
    "\n",
    "        # 少なくとも2倍にする\n",
    "        max_possible = usable_samples // target_samples\n",
    "        n_actual = min(n_aug_per_sample, max_possible)\n",
    "\n",
    "        if n_actual > 0:\n",
    "            working_df.at[idx, 'multi_crop'] = True\n",
    "            working_df.at[idx, 'n_augment'] = n_actual\n",
    "            \n",
    "            \n",
    "if not config.is_crop_aug:\n",
    "    working_df['n_augment'] = 0\n",
    "    working_df['multi_crop'] = False\n",
    "\n",
    "# num_augmented\n",
    "print(f\"Total number of augmentations: {working_df['n_augment'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.938918Z",
     "iopub.status.idle": "2025-05-13T10:59:15.939325Z",
     "shell.execute_reply": "2025-05-13T10:59:15.939127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_maxdb(audio_data: np.ndarray,\n",
    "                  sr: int = config.FS,\n",
    "                  target_sec: float = config.TARGET_DURATION,\n",
    "                  chunk_len: float = 0.05) -> tuple[int, int]:\n",
    "\n",
    "    tgt_samples = int(target_sec * sr)\n",
    "    chunk       = int(chunk_len * sr)\n",
    "\n",
    "    # ---- チャンクごとのパワー合計 (Σx²) を計算 ----------------\n",
    "    pad_len  = int(np.ceil(len(audio_data) / chunk) * chunk - len(audio_data))\n",
    "    power_sq = np.pad(audio_data ** 2, (0, pad_len))\n",
    "    power_chunks = power_sq.reshape(-1, chunk).sum(axis=1)\n",
    "\n",
    "    # ---- 最大チャンクの中心を 5 s の中央に ---------------------\n",
    "    max_idx   = power_chunks.argmax()\n",
    "    center_t  = (max_idx + 0.5) * chunk_len          # [sec]\n",
    "    start_t   = max(center_t - target_sec / 2, 0.0)\n",
    "    end_t     = min(center_t + target_sec / 2, len(audio_data) / sr)\n",
    "\n",
    "    start = int(start_t * sr)\n",
    "    end   = int(end_t   * sr)\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def extract_maxrms(audio_data: np.ndarray,\n",
    "                   sr: int = config.FS,\n",
    "                   target_sec: float = config.TARGET_DURATION,\n",
    "                   chunk_len: float = 0.05):\n",
    "    \n",
    "    tgt_samples = int(target_sec * sr)\n",
    "    chunk       = int(chunk_len * sr)\n",
    "\n",
    "    pad_len = int(np.ceil(len(audio_data) / chunk) * chunk - len(audio_data))\n",
    "    audio_pad = np.pad(audio_data, (0, pad_len))\n",
    "\n",
    "    rms_chunks = np.sqrt(np.mean(audio_pad.reshape(-1, chunk) ** 2, axis=1))\n",
    "\n",
    "    max_idx   = rms_chunks.argmax()\n",
    "    center_t  = (max_idx + 0.5) * chunk_len\n",
    "    start_t   = max(center_t - target_sec / 2, 0)\n",
    "    end_t     = min(center_t + target_sec / 2, len(audio_data) / sr)\n",
    "\n",
    "    start = int(start_t * sr)\n",
    "    end   = int(end_t * sr)\n",
    "    return start, end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.940343Z",
     "iopub.status.idle": "2025-05-13T10:59:15.940772Z",
     "shell.execute_reply": "2025-05-13T10:59:15.94058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def snr(signal: np.ndarray,\n",
    "        peak_percentile: float = 99.5) -> float:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        1-D モノラル波形（float32/float64）。\n",
    "    peak_percentile : float, optional\n",
    "        “ピーク” を何パーセンタイルで測るか。\n",
    "        デフォルト 99.5 = 外れ値耐性を持たせた近似ピーク。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    snr_db : float\n",
    "        振幅ピークと RMS の比を dB で表した簡易 SNR。\n",
    "        値が大きいほどピークが背景より目立つ。\n",
    "    \"\"\"\n",
    "    # 必ず float32/64 で計算\n",
    "    x = signal.astype(np.float32, copy=False)\n",
    "\n",
    "    # ① 近似ピーク振幅（外れ値を除外）\n",
    "    peak = np.percentile(np.abs(x), peak_percentile)\n",
    "\n",
    "    # ② RMS（実効値）\n",
    "    rms = np.sqrt(np.mean(x**2)) + 1e-9        # 1e-9 でゼロ割り防止\n",
    "\n",
    "    # ③ dB 変換\n",
    "    snr_db = 20.0 * np.log10(peak / rms)\n",
    "    return snr_db\n",
    "\n",
    "def smart_crop(audio_data: np.ndarray,\n",
    "               sr: int = config.FS,\n",
    "               target_sec: float = config.TARGET_DURATION) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    1) “maxRMS” チャンクを中心に SNR ≥ 10 dB なら即採用\n",
    "    2) 高域パワー最大フレーム (SNR ≥ 8 dB) を試す\n",
    "    3) スペクトルエントロピー最小フレームを採用\n",
    "    戻り値は (start_sample, end_sample)\n",
    "    \"\"\"\n",
    "    tgt = int(target_sec * sr)\n",
    "\n",
    "    # ① max-RMS チャンク中心\n",
    "    start_rms, end_rms = extract_maxrms(audio_data,\n",
    "                                        sr=sr,\n",
    "                                        target_sec=target_sec)\n",
    "    center_clip = audio_data[start_rms:end_rms]\n",
    "    if len(center_clip) == tgt and snr(center_clip) > 10:\n",
    "        return start_rms, end_rms\n",
    "\n",
    "    # ② STFT / 高域パワー\n",
    "    S = np.abs(librosa.stft(audio_data, n_fft=1024, hop_length=256))**2\n",
    "    mel = librosa.feature.melspectrogram(S=S, sr=sr, fmin=4000, fmax=10000)\n",
    "    idx = mel.sum(0).argmax()\n",
    "    start = max(int(idx * 256 - tgt // 2), 0)\n",
    "    end   = start + tgt\n",
    "    if end <= len(audio_data):\n",
    "        clip = audio_data[start:end]\n",
    "        if snr(clip) > 8:\n",
    "            return start, end\n",
    "\n",
    "    # ③ スペクトルエントロピー最小\n",
    "    prob = S / (S.sum(0, keepdims=True) + 1e-12)\n",
    "    ent  = -(prob * np.log(prob + 1e-12)).sum(0)\n",
    "    idx  = ent.argmin()\n",
    "    start = max(int(idx * 256 - tgt // 2), 0)\n",
    "    end   = min(start + tgt, len(audio_data))     # ← ここで切り詰め\n",
    "\n",
    "    return start, end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.941499Z",
     "iopub.status.idle": "2025-05-13T10:59:15.94182Z",
     "shell.execute_reply": "2025-05-13T10:59:15.941704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def smart1_crop(audio_data: np.ndarray,\n",
    "               sr: int = config.FS,\n",
    "               target_sec: float = config.TARGET_DURATION) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    1) “center” チャンクを中心に SNR ≥ 10 dB なら即採用\n",
    "    2) 高域パワー最大フレーム (SNR ≥ 8 dB) を試す\n",
    "    3) スペクトルエントロピー最小フレームを採用\n",
    "    戻り値は (start_sample, end_sample)\n",
    "    \"\"\"\n",
    "    target_samples = int(target_sec * sr)\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    # ① max-RMS チャンク中心\n",
    "    start_center = total_samples // 2 - target_samples // 2\n",
    "    start_center = max(0, min(start_center, total_samples - target_samples))\n",
    "    end_center = start_center + target_samples\n",
    "    center_clip = audio_data[start_center:end_center]\n",
    "    if len(center_clip) == target_samples and snr(center_clip) > 10:\n",
    "        return start_center, end_center\n",
    "\n",
    "    # ② STFT / 高域パワー\n",
    "    S = np.abs(librosa.stft(audio_data, n_fft=1024, hop_length=256))**2\n",
    "    mel = librosa.feature.melspectrogram(S=S, sr=sr, fmin=4000, fmax=10000)\n",
    "    idx = mel.sum(0).argmax()\n",
    "    start = max(int(idx * 256 - target_samples // 2), 0)\n",
    "    end   = start + target_samples\n",
    "    if end <= len(audio_data):\n",
    "        clip = audio_data[start:end]\n",
    "        if snr(clip) > 8:\n",
    "            return start, end\n",
    "\n",
    "    # ③ スペクトルエントロピー最小\n",
    "    prob = S / (S.sum(0, keepdims=True) + 1e-12)\n",
    "    ent  = -(prob * np.log(prob + 1e-12)).sum(0)\n",
    "    idx  = ent.argmin()\n",
    "    start = max(int(idx * 256 - target_samples // 2), 0)\n",
    "    end   = min(start + target_samples, len(audio_data))     # ← ここで切り詰め\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.942604Z",
     "iopub.status.idle": "2025-05-13T10:59:15.942944Z",
     "shell.execute_reply": "2025-05-13T10:59:15.942775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# crop_strategyに基づいて音声データを切り出す\n",
    "# 現状centerしか使ってないのであまり意味がないコード．\n",
    "def crop_audio(audio_data: np.ndarray, target_samples: int, strategy='center'):\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    if total_samples < target_samples:\n",
    "        n_copy = math.ceil(target_samples / total_samples)\n",
    "        audio_data = np.concatenate([audio_data] * n_copy)\n",
    "        total_samples = len(audio_data)\n",
    "\n",
    "    if strategy == 'head':\n",
    "        # 1秒遅らせて開始（ただし収まらない場合は0から）\n",
    "        buffer = int(1.0 * config.FS)\n",
    "        start_idx = min(buffer, total_samples - target_samples)\n",
    "        end_idx = start_idx + target_samples\n",
    "    elif strategy == 'tail':\n",
    "        start_idx = total_samples - target_samples\n",
    "        start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "        end_idx = start_idx + target_samples\n",
    "    elif strategy == 'center':\n",
    "        start_idx = total_samples // 2 - target_samples // 2\n",
    "        start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "        end_idx = start_idx + target_samples\n",
    "    elif strategy == 'random':\n",
    "        max_start = total_samples - target_samples\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "        start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "        end_idx = start_idx + target_samples\n",
    "    elif isinstance(strategy, (float, int)):\n",
    "        start_idx = int(strategy * config.FS)\n",
    "        start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "        end_idx = start_idx + target_samples\n",
    "    elif strategy == \"maxRMS\":\n",
    "        start_idx, end_idx = extract_maxrms(audio_data)\n",
    "    elif strategy == \"maxdb\":\n",
    "        start_idx, end_idx = extract_maxdb(audio_data)\n",
    "    elif strategy == \"smart\":\n",
    "        start_idx, end_idx = smart_crop(audio_data)  #maxRMS + A + B\n",
    "    elif strategy == \"smart1\":\n",
    "        start_idx, end_idx = smart1_crop(audio_data)   #center + A + B\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "\n",
    "    return audio_data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.943957Z",
     "iopub.status.idle": "2025-05-13T10:59:15.944386Z",
     "shell.execute_reply": "2025-05-13T10:59:15.944183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# audioをmelに変換\n",
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.945253Z",
     "iopub.status.idle": "2025-05-13T10:59:15.945655Z",
     "shell.execute_reply": "2025-05-13T10:59:15.945475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 音源をmelに変える処理．並列化に対応\n",
    "# 元の関数（等間隔にaugment）\n",
    "def process_row(row):\n",
    "\n",
    "    strategy = \"smart\" \n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        mel_list = []\n",
    "        name_list = []\n",
    "\n",
    "        # === 有効範囲を秒 → サンプルに変換 ===\n",
    "        valid_start_sec = row.get(\"valid_start_sec\", 0)\n",
    "        valid_end_sec = row.get(\"valid_end_sec\", None)\n",
    "        duration_sec = len(audio_data) / config.FS\n",
    "\n",
    "        if pd.isna(valid_end_sec) or valid_end_sec is None:\n",
    "            valid_end_sec = duration_sec\n",
    "\n",
    "        valid_start_sample = int(valid_start_sec * config.FS)\n",
    "        valid_end_sample = int(valid_end_sec * config.FS)\n",
    "\n",
    "        usable_audio = audio_data[valid_start_sample:valid_end_sample]\n",
    "        total_usable_samples = len(usable_audio)\n",
    "\n",
    "        # === オリジナル clip ===\n",
    "        # strategy = row.crop_strategy\n",
    "        # try:\n",
    "        #     strategy = float(strategy)\n",
    "        # except ValueError:\n",
    "        #     pass\n",
    "\n",
    "        clip = crop_audio(usable_audio, target_samples, strategy=strategy)  # strategyはcenter固定 or 任意でも可\n",
    "        if len(clip) < target_samples:\n",
    "            clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "        mel = audio2melspec(clip)\n",
    "        if mel.shape != config.TARGET_SHAPE:\n",
    "            mel = cv2.resize(mel, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        mel_list.append(mel.astype(np.float32))\n",
    "        name_list.append(row.samplename)\n",
    "\n",
    "        # === n_augment に応じて crop ===\n",
    "        n_aug = int(row.get(\"n_augment\", 0))\n",
    "        if n_aug <= 0:\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "\n",
    "        interval = max((total_usable_samples - target_samples) // (n_aug + 1), 1)\n",
    "\n",
    "        for i in range(n_aug):\n",
    "            start_idx = min(i * interval, total_usable_samples - target_samples)\n",
    "            clip = usable_audio[start_idx: start_idx + target_samples]\n",
    "            if len(clip) < target_samples:\n",
    "                clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "            mel_crop = audio2melspec(clip)\n",
    "            if mel_crop.shape != config.TARGET_SHAPE:\n",
    "                mel_crop = cv2.resize(mel_crop, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "            mel_list.append(mel_crop.astype(np.float32))\n",
    "            name_list.append(f\"{row.samplename}_crop{i}\")\n",
    "\n",
    "        return list(zip(name_list, mel_list)), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.946449Z",
     "iopub.status.idle": "2025-05-13T10:59:15.94706Z",
     "shell.execute_reply": "2025-05-13T10:59:15.946672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 音源をmelに変える処理．並列化に対応\n",
    "# usable_audioをn_augment等分割し、それぞれの領域でcrop_audio \n",
    "def process_multisegment_row(row):\n",
    "\n",
    "    # 切り出す戦略を変えるにはここを変更\n",
    "    strategy = \"maxRMS\"\n",
    "    \n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        mel_list = []\n",
    "        name_list = []\n",
    "\n",
    "        # === 有効範囲を秒 → サンプルに変換 ===\n",
    "        valid_start_sec = row.get(\"valid_start_sec\", 0)\n",
    "        valid_end_sec = row.get(\"valid_end_sec\", None)\n",
    "        duration_sec = len(audio_data) / config.FS\n",
    "\n",
    "        if pd.isna(valid_end_sec) or valid_end_sec is None:\n",
    "            valid_end_sec = duration_sec\n",
    "\n",
    "        valid_start_sample = int(valid_start_sec * config.FS)\n",
    "        valid_end_sample = int(valid_end_sec * config.FS)\n",
    "\n",
    "        usable_audio = audio_data[valid_start_sample:valid_end_sample]\n",
    "        total_usable_samples = len(usable_audio)\n",
    "\n",
    "        # === オリジナル clip ===\n",
    "        # strategy = row.crop_strategy\n",
    "        # try:\n",
    "        #     strategy = float(strategy)\n",
    "        # except ValueError:\n",
    "        #     pass\n",
    "\n",
    "        clip = crop_audio(usable_audio, target_samples, strategy=strategy)  # strategyはcenter固定 or 任意でも可\n",
    "        if len(clip) < target_samples:\n",
    "            clip = np.pad(clip, (0, target_samples - len(clip)), mode='constant')\n",
    "        mel = audio2melspec(clip)\n",
    "        if mel.shape != config.TARGET_SHAPE:\n",
    "            mel = cv2.resize(mel, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        mel_list.append(mel.astype(np.float32))\n",
    "        name_list.append(row.samplename)\n",
    "\n",
    "        # === n_augment に応じて crop ===\n",
    "        n_aug = int(row.get(\"n_augment\", 0))\n",
    "        if n_aug <= 0:\n",
    "            return list(zip(name_list, mel_list)), None\n",
    "        \n",
    "        # ──────────────────────────────────────────────\n",
    "        # ★ 等分割ブロックごとにクロップ  ★\n",
    "        # usable_audio 全体を (n_aug+1) ブロックに等分\n",
    "        borders = np.linspace(0,          # 0 サンプル\n",
    "                              total_usable_samples,   # 最後\n",
    "                              n_aug + 2,              # 区間端点数 = n_aug+1 ブロック\n",
    "                              dtype=int)\n",
    "        \n",
    "        for i in range(1, n_aug + 1):     # 1 … n_aug\n",
    "            seg_start = borders[i    ]    # ブロック i の開始\n",
    "            seg_end   = borders[i + 1]    # ブロック i の終了\n",
    "            segment   = usable_audio[seg_start:seg_end]\n",
    "            seg_len   = len(segment)\n",
    "        \n",
    "            # ブロックが十分長い → 指定 strategy でクロップ\n",
    "            if seg_len >= target_samples:\n",
    "                clip = crop_audio(segment,\n",
    "                                  target_samples,\n",
    "                                  strategy=strategy)\n",
    "            # 短いブロック → usable_audio 全体からランダム抽出\n",
    "            else:\n",
    "                clip = crop_audio(usable_audio,\n",
    "                                  target_samples,\n",
    "                                  strategy=\"random\")\n",
    "        \n",
    "            # 長さ不足なら右側ゼロ埋め（保険）\n",
    "            if len(clip) < target_samples:\n",
    "                clip = np.pad(clip,\n",
    "                              (0, target_samples - len(clip)),\n",
    "                              mode=\"constant\")\n",
    "        \n",
    "            # Mel 化 → サイズ統一\n",
    "            mel_crop = audio2melspec(clip)\n",
    "            if mel_crop.shape != config.TARGET_SHAPE:\n",
    "                mel_crop = cv2.resize(mel_crop, config.TARGET_SHAPE,\n",
    "                                      interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "            mel_list.append(mel_crop.astype(np.float32))\n",
    "            name_list.append(f\"{row.samplename}_crop{i-1}\")\n",
    "        # ──────────────────────────────────────────────\n",
    "        \n",
    "        return list(zip(name_list, mel_list)), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.948115Z",
     "iopub.status.idle": "2025-05-13T10:59:15.948465Z",
     "shell.execute_reply": "2025-05-13T10:59:15.948346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mel変換を並列化\n",
    "# results = Parallel(n_jobs=config.N_JOBS)(\n",
    "#     delayed(process_row)(row) for _, row in working_df.iloc[:total_samples].iterrows()\n",
    "# )\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "\n",
    "total_samples = len(working_df)\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"Processing\", total=total_samples, dynamic_ncols=True, disable=False)):\n",
    "    results = Parallel(n_jobs=config.N_JOBS, verbose=0)(\n",
    "        delayed(process_row)(row) for _, row in working_df.iterrows()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# 結果の整理\n",
    "all_bird_data = {}\n",
    "errors = []\n",
    "\n",
    "for result, err in results:\n",
    "    if result is not None:\n",
    "        for name, mel in result:\n",
    "            all_bird_data[name] = mel\n",
    "    if err is not None:\n",
    "        errors.append(err)\n",
    "        \n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "if errors:\n",
    "    print(\"Errors:\")\n",
    "    for filepath, error in errors:\n",
    "        print(f\"  {filepath}: {error}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.949054Z",
     "iopub.status.idle": "2025-05-13T10:59:15.949402Z",
     "shell.execute_reply": "2025-05-13T10:59:15.949253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# working_dfにaugmentしたデータ情報を追加\n",
    "augmented_rows = []\n",
    "\n",
    "for _, row in working_df.iterrows():\n",
    "    n_aug = int(row.get('n_augment', 0))\n",
    "    if n_aug > 0:\n",
    "        for i in range(n_aug):\n",
    "            new_row = row.copy()\n",
    "            new_row['samplename'] = f\"{row.samplename}_crop{i}\"\n",
    "            augmented_rows.append(new_row)\n",
    "\n",
    "# DataFrameにまとめる\n",
    "augmented_rows = pd.DataFrame(augmented_rows)\n",
    "working_df_augmented = pd.concat([working_df, augmented_rows], ignore_index=True)\n",
    "print(f\"✅ working_df_augmented created with {len(augmented_rows)} augmented rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.95007Z",
     "iopub.status.idle": "2025-05-13T10:59:15.95039Z",
     "shell.execute_reply": "2025-05-13T10:59:15.950273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# errorになったファイルを除外\n",
    "\n",
    "# エラーになったファイルパスだけ抽出\n",
    "error_files = [e[0] for e in errors]\n",
    "\n",
    "# 削除対象の行を抽出\n",
    "to_remove = working_df_augmented[working_df_augmented['filepath'].isin(error_files)]\n",
    "\n",
    "# 削除されるファイルパスを表示\n",
    "print(\"削除されるファイル:\")\n",
    "for fname in to_remove['filename']:\n",
    "    print(fname)\n",
    "\n",
    "# 実際に削除\n",
    "working_df_augmented = working_df_augmented[~working_df_augmented['filepath'].isin(error_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-13T10:59:15.951169Z",
     "iopub.status.idle": "2025-05-13T10:59:15.951476Z",
     "shell.execute_reply": "2025-05-13T10:59:15.951366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# melとworking_dfを保存．working_dfはtrain.csvとして保存\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JST時刻でディレクトリ作成 ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# ✅ 保存先フォルダを debug に応じて分岐\n",
    "if config.debug:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melスペクトログラムの保存 ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\n✅ Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"📦 File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"📐 Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configの保存 ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(config).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"📝 Config saved to: {config_path}\")\n",
    "\n",
    "\n",
    "# ✅ train.csv として保存\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df_augmented.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"📝 Augmented training metadata saved to: {train_csv_path}\")\n",
    "print(f\"📊 Total rows: {len(working_df_augmented)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7005068,
     "sourceId": 11233182,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7201524,
     "sourceId": 11489000,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7310514,
     "sourceId": 11649451,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7383580,
     "sourceId": 11761347,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7406511,
     "sourceId": 11794895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
