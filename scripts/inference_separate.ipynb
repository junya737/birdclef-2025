{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.model_path = '/kaggle/input/bc25-models-7sec'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes_empty/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel-spec_0329/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.MODELS_DIR = \"../models/\"\n",
    "            self.model_path =  \"../models/baseline_7sec/\"\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0'\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5\n",
    "        self.TARGET_DURATION = 5\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.N_MELS = 128\n",
    "        self.FMIN = 50\n",
    "        self.FMAX = 14000\n",
    "\n",
    "        # ===== Device =====\n",
    "        \n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 10\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "\n",
    "            self.aug_prob = 0.5\n",
    "            self.mixup_alpha = 0.5\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "\n",
    "        # ===== Inference Mode =====\n",
    "        elif mode == \"inference\":\n",
    "            self.batch_size = 16\n",
    "            self.use_tta = False\n",
    "            self.tta_count = 3\n",
    "            self.threshold = 0.5\n",
    "\n",
    "            self.use_specific_folds = False\n",
    "            self.folds = [0, 1]  # Used only if use_specific_folds is True\n",
    "\n",
    "            self.debug_count = 3\n",
    "            \n",
    "            self.device = \"cpu\"\n",
    "            self.seed = 42\n",
    "            \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: configを2つにわけるべきかも．柔軟に変える方はnotebook側で，固定したい方はmodule側とか\"\n",
    "\"TODO: Debugモードになっていたらsubmissionでエラーになる\"\n",
    "cfg = CFG(mode='inference', kaggle_notebook=False)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import models_lib, utils_lib, preprocess_lib, inference_lib\n",
    "\n",
    "# Set seed\n",
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")\n",
    "print(f\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_audio_file(audio_path, cfg):\n",
    "    \"\"\"1ファイル分のmelspecデータを返す（row_id, melspecのリスト）\"\"\"\n",
    "    dataset = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n",
    "        total_segments = int(len(audio_data) / (cfg.FS * cfg.WINDOW_SIZE))\n",
    "\n",
    "        for segment_idx in range(total_segments):\n",
    "            start = int(segment_idx * cfg.FS * cfg.WINDOW_SIZE)\n",
    "            end = int(start + cfg.FS * cfg.WINDOW_SIZE)\n",
    "            segment_audio = audio_data[start:end]\n",
    "\n",
    "            mel_spec = preprocess_lib.process_audio_segment(segment_audio, cfg)\n",
    "            row_id = f\"{soundscape_id}_{(segment_idx + 1) * cfg.WINDOW_SIZE}\"\n",
    "\n",
    "            dataset.append({\n",
    "                \"row_id\": row_id,\n",
    "                \"mel_spec\": mel_spec\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "    return dataset\n",
    "\n",
    "def generate_melspec_dataset(cfg):\n",
    "    test_dir = Path(cfg.test_soundscapes)\n",
    "    if not test_dir.exists():\n",
    "        print(f\"Test directory {test_dir} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    test_files = list(test_dir.glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        print(\"No test audio files found.\")\n",
    "        return []\n",
    "\n",
    "    if cfg.debug:\n",
    "        print(f\"Debug mode enabled, using only {cfg.debug_count} files\")\n",
    "        test_files = test_files[:cfg.debug_count]\n",
    "\n",
    "    results = Parallel(n_jobs=2)(\n",
    "        delayed(process_audio_file)(path, cfg) for path in tqdm(test_files, desc=\"Parallel melspec gen\")\n",
    "    )\n",
    "    dataset = [item for sublist in results for item in sublist]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_from_dataset(dataset, cfg):\n",
    "    \"\"\"numpyのmelspecリストをtorch.Tensorにまとめて返す\"\"\"\n",
    "    all_specs = [item[\"mel_spec\"] for item in dataset]\n",
    "    tensors = torch.tensor(np.stack(all_specs), dtype=torch.float32).unsqueeze(1)  # (B, 1, H, W)\n",
    "    return tensors.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_from_dataset(dataset, models, cfg, species_ids):\n",
    "    \"\"\"melspecデータセットから推論結果を得る\"\"\"\n",
    "    dataloader = create_dataloader_from_dataset(dataset, cfg)\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            outputs = model(dataloader)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.append(probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)  # (N, num_classes)\n",
    "\n",
    "    # row_idと対応づけ\n",
    "    row_ids = [item[\"row_id\"] for item in dataset]\n",
    "    return row_ids, avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Generating dataset...\")\n",
    "    dataset = generate_melspec_dataset(cfg)\n",
    "\n",
    "    print(\"Loading models...\")\n",
    "    models = models_lib.load_models(cfg, num_classes)\n",
    "\n",
    "    print(\"Running inference...\")\n",
    "    if len(dataset) > 0 and len(models) > 0:\n",
    "        row_ids, predictions = run_inference_from_dataset(dataset, models, cfg, species_ids)\n",
    "    else:\n",
    "        print(\"No test data or models available, generating empty submission.\")\n",
    "        row_ids = []\n",
    "        predictions = []\n",
    "\n",
    "    submission_df = utils_lib.create_submission(row_ids, predictions, species_ids, cfg)\n",
    "    submission_path = os.path.join(cfg.OUTPUT_DIR, 'submission.csv')\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "    print(f\"Submission saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "No test audio files found.\n",
      "Loading models...\n",
      "Found a total of 5 model files.\n",
      "Loading model: ../models/baseline_7sec/model_fold0.pth\n",
      "Loading model: ../models/baseline_7sec/model_fold1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ../models/baseline_7sec/model_fold2.pth\n",
      "Loading model: ../models/baseline_7sec/model_fold3.pth\n",
      "Loading model: ../models/baseline_7sec/model_fold4.pth\n",
      "Running inference...\n",
      "No test data or models available, generating empty submission.\n",
      "Creating submission dataframe...\n",
      "Submission saved to ../data/result/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出用ファイルを読み込む\n",
    "submission = pd.read_csv(os.path.join(cfg.OUTPUT_DIR, 'submission.csv'))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shape: (0, 207)\n",
      "✅ Columns: ['row_id', '1139490', '1192948', '1194042', '126247', '1346504', '134933', '135045', '1462711', '1462737', '1564122', '21038', '21116', '21211', '22333', '22973', '22976', '24272', '24292', '24322', '41663', '41778', '41970', '42007', '42087', '42113', '46010', '47067', '476537', '476538', '48124', '50186', '517119', '523060', '528041', '52884', '548639', '555086', '555142', '566513', '64862', '65336', '65344', '65349', '65373', '65419', '65448', '65547', '65962', '66016', '66531', '66578', '66893', '67082', '67252', '714022', '715170', '787625', '81930', '868458', '963335', 'amakin1', 'amekes', 'ampkin1', 'anhing', 'babwar', 'bafibi1', 'banana', 'baymac', 'bbwduc', 'bicwre1', 'bkcdon', 'bkmtou1', 'blbgra1', 'blbwre1', 'blcant4', 'blchaw1', 'blcjay1', 'blctit1', 'blhpar1', 'blkvul', 'bobfly1', 'bobher1', 'brtpar1', 'bubcur1', 'bubwre1', 'bucmot3', 'bugtan', 'butsal1', 'cargra1', 'cattyr', 'chbant1', 'chfmac1', 'cinbec1', 'cocher1', 'cocwoo1', 'colara1', 'colcha1', 'compau', 'compot1', 'cotfly1', 'crbtan1', 'crcwoo1', 'crebob1', 'cregua1', 'creoro1', 'eardov1', 'fotfly', 'gohman1', 'grasal4', 'grbhaw1', 'greani1', 'greegr', 'greibi1', 'grekis', 'grepot1', 'gretin1', 'grnkin', 'grysee1', 'gybmar', 'gycwor1', 'labter1', 'laufal1', 'leagre', 'linwoo1', 'littin1', 'mastit1', 'neocor', 'norscr1', 'olipic1', 'orcpar', 'palhor2', 'paltan1', 'pavpig2', 'piepuf1', 'pirfly1', 'piwtyr1', 'plbwoo1', 'plctan1', 'plukit1', 'purgal2', 'ragmac1', 'rebbla1', 'recwoo1', 'rinkin1', 'roahaw', 'rosspo1', 'royfly1', 'rtlhum', 'rubsee1', 'rufmot1', 'rugdov', 'rumfly1', 'ruther1', 'rutjac1', 'rutpuf1', 'saffin', 'sahpar1', 'savhaw1', 'secfly1', 'shghum1', 'shtfly1', 'smbani', 'snoegr', 'sobtyr1', 'socfly1', 'solsan', 'soulap1', 'spbwoo1', 'speowl1', 'spepar1', 'srwswa1', 'stbwoo2', 'strcuc1', 'strfly1', 'strher', 'strowl1', 'tbsfin1', 'thbeup1', 'thlsch3', 'trokin', 'tropar', 'trsowl', 'turvul', 'verfly', 'watjac1', 'wbwwre1', 'whbant1', 'whbman1', 'whfant1', 'whmtyr1', 'whtdov', 'whttro1', 'whwswa1', 'woosto', 'y00678', 'yebela1', 'yebfly1', 'yebsee1', 'yecspi2', 'yectyr1', 'yehbla2', 'yehcar1', 'yelori1', 'yeofly1', 'yercac1', 'ywcpar']\n",
      "✅ Dtypes:\n",
      " row_id     object\n",
      "1139490    object\n",
      "1192948    object\n",
      "1194042    object\n",
      "126247     object\n",
      "            ...  \n",
      "yehcar1    object\n",
      "yelori1    object\n",
      "yeofly1    object\n",
      "yercac1    object\n",
      "ywcpar     object\n",
      "Length: 207, dtype: object\n",
      "✅ Nulls:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Shape:\", submission.shape)\n",
    "print(\"✅ Columns:\", submission.columns.tolist())\n",
    "print(\"✅ Dtypes:\\n\", submission.dtypes)\n",
    "print(\"✅ Nulls:\\n\", submission.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
