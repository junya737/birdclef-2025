{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from module import config_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # å…¨modelã®ä¿å­˜å…ˆ\n",
    "            self.model_path = self.models_dir # å„ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆï¼å­¦ç¿’æ™‚ã«å‹•çš„ã«å¤‰æ›´ï¼\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5.0 # æ¨è«–æ™‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "        self.TARGET_DURATION = 5 # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆæ™‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 16\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 16  # ä¸¦åˆ—å‡¦ç†ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•° 16ãã‚‰ã„ã§ã„ã„\n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeã—ãªã„ãªã‚‰True\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = DatasetConfig(kaggle_notebook=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: ON\n",
      "Max samples to process: 50\n",
      "Loading taxonomy data...\n",
      "Loading training metadata...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{config.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{config.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 unique species\n",
      "Total samples to process: 50 out of 28564 available\n",
      "Samples by class:\n",
      "class\n",
      "Aves        27648\n",
      "Amphibia      583\n",
      "Mammalia      178\n",
      "Insecta       155\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_list = sorted(train_df['primary_label'].unique())\n",
    "label_id_list = list(range(len(label_list)))\n",
    "label2id = dict(zip(label_list, label_id_list))\n",
    "id2label = dict(zip(label_id_list, label_list))\n",
    "\n",
    "print(f'Found {len(label_list)} unique species')\n",
    "working_df = train_df.copy()\n",
    "working_df['target'] = working_df.primary_label.map(label2id)\n",
    "working_df['filepath'] = config.RAW_DIR + '/train_audio/' + working_df.filename\n",
    "working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "working_df[\"crop_strategy\"] = \"center\"\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')\n",
    "print(f'Samples by class:')\n",
    "print(working_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabio A. Sarria-Sã®éŸ³å£°ã¯æœ€åˆã«Insectaã®é³´ãå£°ãŒã‚ã‚‹ãŸã‚ï¼Œæœ€åˆã‚’cropã—ãŸã„\n",
    "# crop_starategyã‚’'head'ã«å¤‰æ›´ã™ã‚‹\n",
    "\n",
    "# 1. \"Fabio A. Sarria-S\" ã® filename ã‚’æŠ½å‡º\n",
    "fabio_filenames = train_df.loc[\n",
    "    train_df['author'] == \"Fabio A. Sarria-S\", 'filename'\n",
    "].tolist()\n",
    "\n",
    "# 2. working_df ã® crop_strategy ã‚’ 'head' ã«æ›´æ–°\n",
    "working_df['crop_strategy'] = working_df.get('crop_strategy', 'center')  # åˆæœŸåŒ–ï¼ˆãªã‘ã‚Œã°centerï¼‰\n",
    "\n",
    "working_df.loc[\n",
    "    working_df['filename'].isin(fabio_filenames),\n",
    "    'crop_strategy'\n",
    "] = 'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_strategyã«åŸºã¥ã„ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ‡ã‚Šå‡ºã™\n",
    "def crop_audio(audio_data: np.ndarray, target_samples: int, strategy='center'):\n",
    "    total_samples = len(audio_data)\n",
    "\n",
    "    if total_samples < target_samples:\n",
    "        n_copy = math.ceil(target_samples / total_samples)\n",
    "        audio_data = np.concatenate([audio_data] * n_copy)\n",
    "        total_samples = len(audio_data)\n",
    "\n",
    "    if strategy == 'head':\n",
    "        # 1ç§’é…ã‚‰ã›ã¦é–‹å§‹ï¼ˆãŸã ã—åã¾ã‚‰ãªã„å ´åˆã¯0ã‹ã‚‰ï¼‰\n",
    "        buffer = int(1.0 * config.FS)\n",
    "        start_idx = min(buffer, total_samples - target_samples)\n",
    "    elif strategy == 'tail':\n",
    "        start_idx = total_samples - target_samples\n",
    "    elif strategy == 'center':\n",
    "        start_idx = total_samples // 2 - target_samples // 2\n",
    "    elif strategy == 'random':\n",
    "        max_start = total_samples - target_samples\n",
    "        start_idx = np.random.randint(0, max_start + 1)\n",
    "    elif isinstance(strategy, (float, int)):\n",
    "        start_idx = int(strategy * config.FS)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    start_idx = max(0, min(start_idx, total_samples - target_samples))\n",
    "    end_idx = start_idx + target_samples\n",
    "    return audio_data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "        strategy = row.crop_strategy\n",
    "\n",
    "        # æ–‡å­—åˆ—ã§æ•°å€¤ãŒæ¸¡ã£ã¦ã‚‹å ´åˆï¼ˆä¾‹: '10.0'ï¼‰ã‚’floatã«å¤‰æ›\n",
    "        if isinstance(strategy, str):\n",
    "            try:\n",
    "                strategy = float(strategy)\n",
    "            except ValueError:\n",
    "                pass  # å¤‰æ›ã§ããªã„ãªã‚‰ãã®ã¾ã¾ä½¿ã†ï¼ˆä¾‹: 'head'ï¼‰\n",
    "\n",
    "        cropped_audio = crop_audio(audio_data, target_samples, strategy=strategy)\n",
    "\n",
    "        if len(cropped_audio) < target_samples:\n",
    "            cropped_audio = np.pad(cropped_audio, (0, target_samples - len(cropped_audio)), mode='constant')\n",
    "\n",
    "        mel_spec = audio2melspec(cropped_audio)\n",
    "        if mel_spec.shape != config.TARGET_SHAPE:\n",
    "            mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        return row.samplename, mel_spec.astype(np.float32), None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, None, (row.filepath, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=config.N_JOBS)(\n",
    "    delayed(process_row)(row) for _, row in working_df.iloc[:total_samples].iterrows()\n",
    ")\n",
    "\n",
    "# çµæœã®æ•´ç†\n",
    "all_bird_data = {name: spec for name, spec, err in results if name is not None}\n",
    "errors = [err for name, spec, err in results if err is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldã‚’æ±ºã‚ã¦ãŠã\n",
    "\n",
    "\n",
    "working_df['group_id'] = working_df['samplename'].map(lambda x: x.split('_crop')[0])\n",
    "\n",
    "# fold åˆ—ã‚’åˆæœŸåŒ–\n",
    "working_df['fold'] = -1\n",
    "\n",
    "\n",
    "sgkf = StratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
    "groups = working_df['group_id']\n",
    "labels = working_df['primary_label']\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(sgkf.split(working_df, labels, groups=groups)):\n",
    "    working_df.loc[val_idx, 'fold'] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Mel-spectrograms saved to: ../data/processed/data_debugs/birdclef2025_melspec_5sec_256_256.npy\n",
      "ğŸ“¦ File size: 12.50 MB\n",
      "ğŸ“ Example shape: (256, 256)\n",
      "ğŸ“ Config saved to: ../data/processed/data_debugs/config.csv\n",
      "ğŸ“ Augmented training metadata saved to: ../data/processed/data_debugs/train.csv\n",
      "ğŸ“Š Total rows: 28564\n"
     ]
    }
   ],
   "source": [
    "# 4mins\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JSTæ™‚åˆ»ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# âœ… ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ debug ã«å¿œã˜ã¦åˆ†å²\n",
    "if config.debug:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(config.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ä¿å­˜ ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\nâœ… Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"ğŸ“¦ File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"ğŸ“ Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configã®ä¿å­˜ ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(config).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"ğŸ“ Config saved to: {config_path}\")\n",
    "\n",
    "\n",
    "# âœ… train.csv ã¨ã—ã¦ä¿å­˜\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"ğŸ“ training metadata saved to: {train_csv_path}\")\n",
    "print(f\"ğŸ“Š Total rows: {len(working_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = np.load(\"../data/processed/mel_0411/birdclef2025_melspec_5sec_256_256.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
