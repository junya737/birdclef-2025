{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # kaggle notebookならここを変更\n",
    "            self.model_path = \"/kaggle/input/birdclef-2025-baseline-fold0-0404\"\n",
    "            \n",
    "            self.device = \"cpu\"\n",
    "            self.batch_size = 8\n",
    "            self.n_jobs = 3\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes_empty//'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel-spec_0329/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.MODELS_DIR = \"../models/\"\n",
    "            \n",
    "            # ローカルならここを変更\n",
    "            self.model_path =  \"../models/mel_cleaned0413_vino/\"\n",
    "            \n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.batch_size = 32\n",
    "            self.n_jobs = 3\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0'\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5\n",
    "        self.TARGET_DURATION = 5\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = None # 下で指定する．\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        \n",
    "        self.seed = 42\n",
    "        \n",
    "        \n",
    "        # ===== Inference Mode =====\n",
    "        if mode == \"inference\":\n",
    "            self.use_tta = False\n",
    "            self.tta_count = 3\n",
    "            self.threshold = 0.5\n",
    "\n",
    "            self.use_specific_folds = False\n",
    "            self.folds = [0, 1, 2, 3, 4]  # Used only if use_specific_folds is True\n",
    "\n",
    "            self.debug_count = 3\n",
    "            self.ensemble_strategy = \"mean\" # \"mean\", \"max\", \"min\", \"median\" など\n",
    "            \n",
    "            \n",
    "            \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"inference\"  \n",
    "KAGGLE_NOTEBOOK = False\n",
    "\n",
    "\n",
    "cfg = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    !pip install -U openvino-telemetry  --no-index --find-links /kaggle/input/pip-hub\n",
    "    !pip install -U openvino  --no-index --find-links /kaggle/input/pip-hub\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "    \n",
    "from openvino.runtime import Core\n",
    "from module import models_lib, utils_lib, preprocess_lib, inference_lib\n",
    "\n",
    "# Set seed\n",
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_configs():\n",
    "    cfg_list = []\n",
    "\n",
    "    # model A\n",
    "    cfg1 = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "    cfg1.model_path = \"../models/fold0_safezone1000_head_vino/\"\n",
    "    cfg1.HOP_LENGTH = 64\n",
    "    cfg_list.append(cfg1)\n",
    "\n",
    "    # model B\n",
    "    cfg2 = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "    cfg2.HOP_LENGTH = 512\n",
    "    cfg2.model_path = \"../models/fold0_safezone1000_head_hoplength512_vino/\"\n",
    "    cfg_list.append(cfg2)\n",
    "\n",
    "    # model C など必要に応じて追加可能\n",
    "    return cfg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")\n",
    "print(f\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel変換\n",
    "def process_audio_file(audio_path, cfg):\n",
    "    \"\"\"1ファイル分のmelspecデータを返す（row_id, melspecのリスト）\"\"\"\n",
    "    dataset = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n",
    "        total_segments = int(len(audio_data) / (cfg.FS * cfg.WINDOW_SIZE))\n",
    "\n",
    "        for segment_idx in range(total_segments):\n",
    "            start = int(segment_idx * cfg.FS * cfg.WINDOW_SIZE)\n",
    "            end = int(start + cfg.FS * cfg.WINDOW_SIZE)\n",
    "            segment_audio = audio_data[start:end]\n",
    "\n",
    "            mel_spec = preprocess_lib.process_audio_segment(segment_audio, cfg)\n",
    "            row_id = f\"{soundscape_id}_{(segment_idx + 1) * cfg.WINDOW_SIZE}\"\n",
    "\n",
    "            dataset.append({\n",
    "                \"row_id\": row_id,\n",
    "                \"mel_spec\": mel_spec\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 並列化してmelspecを生成\n",
    "def generate_melspec_dataset(cfg):\n",
    "    test_dir = Path(cfg.test_soundscapes)\n",
    "    if not test_dir.exists():\n",
    "        print(f\"Test directory {test_dir} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    test_files = list(test_dir.glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        print(\"No test audio files found.\")\n",
    "        return []\n",
    "\n",
    "    if cfg.debug:\n",
    "        print(f\"Debug mode enabled, using only {cfg.debug_count} files\")\n",
    "        test_files = test_files[:cfg.debug_count]\n",
    "\n",
    "    results = Parallel(n_jobs=cfg.n_jobs)(\n",
    "        delayed(process_audio_file)(path, cfg) for path in tqdm(test_files, desc=\"Parallel melspec gen\")\n",
    "    )\n",
    "    dataset = [item for sublist in results for item in sublist]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# openvinoモデルの読み込み\n",
    "def load_openvino_models(vino_dir, cfg):\n",
    "    models = []\n",
    "    vino_dir = Path(vino_dir)\n",
    "\n",
    "    if cfg.use_specific_folds:\n",
    "        fold_ids = cfg.folds\n",
    "        xml_files = [vino_dir / f\"model_fold{f}.xml\" for f in fold_ids]\n",
    "    else:\n",
    "        xml_files = sorted(vino_dir.glob(\"model_fold*.xml\"))\n",
    "\n",
    "    for xml_path in xml_files:\n",
    "        bin_path = xml_path.with_suffix(\".bin\")\n",
    "\n",
    "        if not xml_path.exists() or not bin_path.exists():\n",
    "            print(f\"⚠️ Warning: Missing files for {xml_path.stem}\")\n",
    "            continue\n",
    "\n",
    "        core = Core()\n",
    "        model_ir = core.read_model(xml_path)\n",
    "        compiled_model = core.compile_model(model_ir, device_name=\"CPU\")\n",
    "        models.append(compiled_model)\n",
    "\n",
    "        # 🔍 モデルのファイル名（fold情報）をログに出す\n",
    "        print(f\"✅ Loaded model: {xml_path.name}\")\n",
    "\n",
    "    print(f\"🎉 Total {len(models)} OpenVINO model(s) loaded from {vino_dir}\")\n",
    "    return models\n",
    "\n",
    "# openvinoモデルによる推論\n",
    "def run_inference_openvino(dataset, models_ir, cfg, species_ids):\n",
    "    row_ids = []\n",
    "    all_preds = []\n",
    "\n",
    "    for i in range(0, len(dataset), cfg.batch_size):\n",
    "        batch = dataset[i:i+cfg.batch_size]\n",
    "\n",
    "        mel_list = [item[\"mel_spec\"] for item in batch]\n",
    "        input_tensor = np.stack(mel_list).astype(np.float32)  # (B, H, W)\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=1)  # (B, 1, H, W)\n",
    "\n",
    "        preds_per_model = []\n",
    "        for model in models_ir:\n",
    "            input_layer = model.input(0)\n",
    "            output_layer = model.output(0)\n",
    "            result = model([input_tensor])[output_layer]\n",
    "            probs = 1 / (1 + np.exp(-result))  # sigmoid\n",
    "            preds_per_model.append(probs)\n",
    "\n",
    "        # アンサンブル戦略の選択\n",
    "        if cfg.ensemble_strategy == \"mean\":\n",
    "            avg_preds = np.mean(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"max\":\n",
    "            avg_preds = np.max(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"min\":\n",
    "            avg_preds = np.min(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"median\":\n",
    "            avg_preds = np.median(preds_per_model, axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ensemble strategy: {cfg.ensemble_strategy}\")\n",
    "\n",
    "        all_preds.append(avg_preds)\n",
    "        row_ids.extend([item[\"row_id\"] for item in batch])\n",
    "\n",
    "    predictions = np.concatenate(all_preds, axis=0)\n",
    "    return row_ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_save(cfg, species_ids):\n",
    "    print(f\"\\n📌 Processing model at: {cfg.model_path}\")\n",
    "    print(\"Generating dataset...\")\n",
    "    dataset = generate_melspec_dataset(cfg)\n",
    "\n",
    "    print(\"Loading OpenVINO models...\")\n",
    "    vino_dir = Path(cfg.model_path).with_name(Path(cfg.model_path).name)\n",
    "    models_ir = load_openvino_models(vino_dir, cfg)\n",
    "\n",
    "    if not models_ir:\n",
    "        raise RuntimeError(\"No OpenVINO models found.\")\n",
    "\n",
    "    print(\"Running OpenVINO inference...\")\n",
    "    if len(dataset) > 0:\n",
    "        row_ids, predictions = run_inference_openvino(dataset, models_ir, cfg, species_ids)\n",
    "    else:\n",
    "        print(\"No test data available, generating empty submission.\")\n",
    "        row_ids = []\n",
    "        predictions = []\n",
    "\n",
    "    # smoothing前の予測値を保存\n",
    "    submission_df = utils_lib.create_submission(row_ids, predictions, species_ids, cfg)\n",
    "\n",
    "    return submission_df\n",
    "\n",
    "\n",
    "# 予測値のdf_listを受け取ってアンサンブル\n",
    "def ensemble_submissions_dfs(dfs, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    複数の submission DataFrame をアンサンブル\n",
    "\n",
    "    Parameters:\n",
    "        dfs (List[pd.DataFrame]): 各 submission.csv を読み込んだ DataFrame のリスト\n",
    "        method (str): アンサンブル戦略（mean, max, median）\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: アンサンブル後の submission\n",
    "    \"\"\"\n",
    "    assert all(df.columns[0] == \"row_id\" for df in dfs), \"All DataFrames must start with 'row_id' column\"\n",
    "    row_ids = dfs[0]['row_id'].values\n",
    "    preds = np.stack([df.iloc[:, 1:].values for df in dfs], axis=0)  # (n_models, n_rows, n_classes)\n",
    "\n",
    "    if method == \"mean\":\n",
    "        combined = np.mean(preds, axis=0)\n",
    "    elif method == \"max\":\n",
    "        combined = np.max(preds, axis=0)\n",
    "    elif method == \"median\":\n",
    "        combined = np.median(preds, axis=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ensemble method: {method}\")\n",
    "\n",
    "    result_df = pd.DataFrame(combined, columns=dfs[0].columns[1:])\n",
    "    result_df.insert(0, \"row_id\", row_ids)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def smooth_submission_df(submission_df, cfg, weights=None):\n",
    "    \"\"\"\n",
    "    Smooth predictions using weighted moving average over a 5-frame window: [-2, -1, 0, +1, +2],\n",
    "    then blend with per-class global average within each soundscape segment group.\n",
    "\n",
    "    Parameters:\n",
    "        submission_df: pd.DataFrame with 'row_id' and prediction columns.\n",
    "        cfg: config object (interface compatibility).\n",
    "        weights: List of 5 floats (default = [0.1, 0.2, 0.4, 0.2, 0.1]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with smoothed predictions.\n",
    "    \"\"\"\n",
    "    print(\"Smoothing submission predictions with global average blend...\")\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.array([0.1, 0.2, 0.4, 0.2, 0.1])\n",
    "    else:\n",
    "        weights = np.array(weights)\n",
    "\n",
    "    sub = submission_df.copy()\n",
    "    cols = sub.columns[1:]\n",
    "    groups = sub['row_id'].astype(str).str.rsplit('_', n=1).str[0].values\n",
    "    unique_groups = np.unique(groups)\n",
    "\n",
    "    for group in unique_groups:\n",
    "        idx = np.where(groups == group)[0]\n",
    "        preds = sub.iloc[idx][cols].values  # (T, C)\n",
    "        T, C = preds.shape\n",
    "\n",
    "        # エッジ処理：端を繰り返すようにパディング\n",
    "        padded = np.pad(preds, ((2, 2), (0, 0)), mode='edge')  # (T+4, C)\n",
    "\n",
    "        # 平滑化：5点加重平均（[-2, -1, 0, +1, +2]）\n",
    "        smoothed = (\n",
    "            padded[0:T]   * weights[0] +\n",
    "            padded[1:T+1] * weights[1] +\n",
    "            padded[2:T+2] * weights[2] +\n",
    "            padded[3:T+3] * weights[3] +\n",
    "            padded[4:T+4] * weights[4]\n",
    "        )\n",
    "\n",
    "        # 各クラスの平均予測を20%混ぜる（全セグメントに対して一様に加える）\n",
    "        classwise_mean = smoothed.mean(axis=0, keepdims=True)  # shape: (1, C)\n",
    "        smoothed = smoothed * 0.8 + classwise_mean * 0.2\n",
    "\n",
    "        sub.iloc[idx, 1:] = smoothed\n",
    "\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Processing model at: ../models/fold0_safezone1000_head_vino/\n",
      "Generating dataset...\n",
      "No test audio files found.\n",
      "Loading OpenVINO models...\n",
      "✅ Loaded model: model_fold0.xml\n",
      "🎉 Total 1 OpenVINO model(s) loaded from ../models/fold0_safezone1000_head_vino\n",
      "Running OpenVINO inference...\n",
      "No test data available, generating empty submission.\n",
      "Creating submission dataframe...\n",
      "\n",
      "📌 Processing model at: ../models/fold0_safezone1000_head_hoplength512_vino/\n",
      "Generating dataset...\n",
      "No test audio files found.\n",
      "Loading OpenVINO models...\n",
      "✅ Loaded model: model_fold0.xml\n",
      "🎉 Total 1 OpenVINO model(s) loaded from ../models/fold0_safezone1000_head_hoplength512_vino\n",
      "Running OpenVINO inference...\n",
      "No test data available, generating empty submission.\n",
      "Creating submission dataframe...\n"
     ]
    }
   ],
   "source": [
    "cfg_list = load_all_configs()  # 複数CFGを返す関数\n",
    "inference_dfs = []\n",
    "\n",
    "for cfg in cfg_list:\n",
    "    df = run_inference_and_save(cfg, species_ids)\n",
    "    inference_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensembled (before smoothing) submission.\n",
      "Smoothing submission predictions with global average blend...\n",
      "Saved smoothed final submission.\n"
     ]
    }
   ],
   "source": [
    "# アンサンブル\n",
    "ensemble_df = ensemble_submissions_dfs(inference_dfs, method=\"mean\")\n",
    "ensemble_df.to_csv(os.path.join(cfg_list[0].OUTPUT_DIR, 'submission_before_smoothing.csv'), index=False)\n",
    "print(\"Saved ensembled (before smoothing) submission.\")\n",
    "\n",
    "# スムージング\n",
    "smoothed_df = smooth_submission_df(ensemble_df, cfg_list[0])\n",
    "smoothed_df.to_csv(os.path.join(cfg_list[0].OUTPUT_DIR, 'submission.csv'), index=False)\n",
    "print(\"Saved smoothed final submission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出用ファイルを読み込む\n",
    "submission = pd.read_csv(os.path.join(cfg.OUTPUT_DIR, 'submission.csv'))\n",
    "submission.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(cfg.OUTPUT_DIR, 'submission_before_smoothing.csv'))\n",
    "submission.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shape: (0, 207)\n",
      "✅ Columns: ['row_id', '1139490', '1192948', '1194042', '126247', '1346504', '134933', '135045', '1462711', '1462737', '1564122', '21038', '21116', '21211', '22333', '22973', '22976', '24272', '24292', '24322', '41663', '41778', '41970', '42007', '42087', '42113', '46010', '47067', '476537', '476538', '48124', '50186', '517119', '523060', '528041', '52884', '548639', '555086', '555142', '566513', '64862', '65336', '65344', '65349', '65373', '65419', '65448', '65547', '65962', '66016', '66531', '66578', '66893', '67082', '67252', '714022', '715170', '787625', '81930', '868458', '963335', 'amakin1', 'amekes', 'ampkin1', 'anhing', 'babwar', 'bafibi1', 'banana', 'baymac', 'bbwduc', 'bicwre1', 'bkcdon', 'bkmtou1', 'blbgra1', 'blbwre1', 'blcant4', 'blchaw1', 'blcjay1', 'blctit1', 'blhpar1', 'blkvul', 'bobfly1', 'bobher1', 'brtpar1', 'bubcur1', 'bubwre1', 'bucmot3', 'bugtan', 'butsal1', 'cargra1', 'cattyr', 'chbant1', 'chfmac1', 'cinbec1', 'cocher1', 'cocwoo1', 'colara1', 'colcha1', 'compau', 'compot1', 'cotfly1', 'crbtan1', 'crcwoo1', 'crebob1', 'cregua1', 'creoro1', 'eardov1', 'fotfly', 'gohman1', 'grasal4', 'grbhaw1', 'greani1', 'greegr', 'greibi1', 'grekis', 'grepot1', 'gretin1', 'grnkin', 'grysee1', 'gybmar', 'gycwor1', 'labter1', 'laufal1', 'leagre', 'linwoo1', 'littin1', 'mastit1', 'neocor', 'norscr1', 'olipic1', 'orcpar', 'palhor2', 'paltan1', 'pavpig2', 'piepuf1', 'pirfly1', 'piwtyr1', 'plbwoo1', 'plctan1', 'plukit1', 'purgal2', 'ragmac1', 'rebbla1', 'recwoo1', 'rinkin1', 'roahaw', 'rosspo1', 'royfly1', 'rtlhum', 'rubsee1', 'rufmot1', 'rugdov', 'rumfly1', 'ruther1', 'rutjac1', 'rutpuf1', 'saffin', 'sahpar1', 'savhaw1', 'secfly1', 'shghum1', 'shtfly1', 'smbani', 'snoegr', 'sobtyr1', 'socfly1', 'solsan', 'soulap1', 'spbwoo1', 'speowl1', 'spepar1', 'srwswa1', 'stbwoo2', 'strcuc1', 'strfly1', 'strher', 'strowl1', 'tbsfin1', 'thbeup1', 'thlsch3', 'trokin', 'tropar', 'trsowl', 'turvul', 'verfly', 'watjac1', 'wbwwre1', 'whbant1', 'whbman1', 'whfant1', 'whmtyr1', 'whtdov', 'whttro1', 'whwswa1', 'woosto', 'y00678', 'yebela1', 'yebfly1', 'yebsee1', 'yecspi2', 'yectyr1', 'yehbla2', 'yehcar1', 'yelori1', 'yeofly1', 'yercac1', 'ywcpar']\n",
      "✅ Dtypes:\n",
      " row_id     object\n",
      "1139490    object\n",
      "1192948    object\n",
      "1194042    object\n",
      "126247     object\n",
      "            ...  \n",
      "yehcar1    object\n",
      "yelori1    object\n",
      "yeofly1    object\n",
      "yercac1    object\n",
      "ywcpar     object\n",
      "Length: 207, dtype: object\n",
      "✅ Nulls:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Shape:\", submission.shape)\n",
    "print(\"✅ Columns:\", submission.columns.tolist())\n",
    "print(\"✅ Dtypes:\\n\", submission.dtypes)\n",
    "print(\"✅ Nulls:\\n\", submission.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
