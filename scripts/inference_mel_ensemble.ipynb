{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥\n",
    "            self.model_path = \"/kaggle/input/birdclef-2025-baseline-fold0-0404\"\n",
    "            \n",
    "            self.device = \"cpu\"\n",
    "            self.batch_size = 8\n",
    "            self.n_jobs = 3\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes_empty//'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel-spec_0329/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.MODELS_DIR = \"../models/\"\n",
    "            \n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥\n",
    "            self.model_path =  \"../models/mel_cleaned0413_vino/\"\n",
    "            \n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.batch_size = 32\n",
    "            self.n_jobs = 3\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0'\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5\n",
    "        self.TARGET_DURATION = 5\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = None # ‰∏ã„ÅßÊåáÂÆö„Åô„ÇãÔºé\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        \n",
    "        self.seed = 42\n",
    "        \n",
    "        \n",
    "        # ===== Inference Mode =====\n",
    "        if mode == \"inference\":\n",
    "            self.use_tta = False\n",
    "            self.tta_count = 3\n",
    "            self.threshold = 0.5\n",
    "\n",
    "            self.use_specific_folds = False\n",
    "            self.folds = [0, 1, 2, 3, 4]  # Used only if use_specific_folds is True\n",
    "\n",
    "            self.debug_count = 3\n",
    "            self.ensemble_strategy = \"mean\" # \"mean\", \"max\", \"min\", \"median\" „Å™„Å©\n",
    "            \n",
    "            \n",
    "            \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"inference\"  \n",
    "KAGGLE_NOTEBOOK = False\n",
    "\n",
    "\n",
    "cfg = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    !pip install -U openvino-telemetry  --no-index --find-links /kaggle/input/pip-hub\n",
    "    !pip install -U openvino  --no-index --find-links /kaggle/input/pip-hub\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "    \n",
    "from openvino.runtime import Core\n",
    "from module import models_lib, utils_lib, preprocess_lib, inference_lib\n",
    "\n",
    "# Set seed\n",
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_configs():\n",
    "    cfg_list = []\n",
    "\n",
    "    # model A\n",
    "    cfg1 = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "    cfg1.model_path = \"../models/fold0_safezone1000_head_vino/\"\n",
    "    cfg1.HOP_LENGTH = 64\n",
    "    cfg_list.append(cfg1)\n",
    "\n",
    "    # model B\n",
    "    cfg2 = CFG(mode=MODE, kaggle_notebook=KAGGLE_NOTEBOOK)\n",
    "    cfg2.HOP_LENGTH = 512\n",
    "    cfg2.model_path = \"../models/fold0_safezone1000_head_hoplength512_vino/\"\n",
    "    cfg_list.append(cfg2)\n",
    "\n",
    "    # model C „Å™„Å©ÂøÖË¶Å„Å´Âøú„Åò„Å¶ËøΩÂä†ÂèØËÉΩ\n",
    "    return cfg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")\n",
    "print(f\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melÂ§âÊèõ\n",
    "def process_audio_file(audio_path, cfg):\n",
    "    \"\"\"1„Éï„Ç°„Ç§„É´ÂàÜ„ÅÆmelspec„Éá„Éº„Çø„ÇíËøî„ÅôÔºàrow_id, melspec„ÅÆ„É™„Çπ„ÉàÔºâ\"\"\"\n",
    "    dataset = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "    try:\n",
    "        audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n",
    "        total_segments = int(len(audio_data) / (cfg.FS * cfg.WINDOW_SIZE))\n",
    "\n",
    "        for segment_idx in range(total_segments):\n",
    "            start = int(segment_idx * cfg.FS * cfg.WINDOW_SIZE)\n",
    "            end = int(start + cfg.FS * cfg.WINDOW_SIZE)\n",
    "            segment_audio = audio_data[start:end]\n",
    "\n",
    "            mel_spec = preprocess_lib.process_audio_segment(segment_audio, cfg)\n",
    "            row_id = f\"{soundscape_id}_{(segment_idx + 1) * cfg.WINDOW_SIZE}\"\n",
    "\n",
    "            dataset.append({\n",
    "                \"row_id\": row_id,\n",
    "                \"mel_spec\": mel_spec\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# ‰∏¶ÂàóÂåñ„Åó„Å¶melspec„ÇíÁîüÊàê\n",
    "def generate_melspec_dataset(cfg):\n",
    "    test_dir = Path(cfg.test_soundscapes)\n",
    "    if not test_dir.exists():\n",
    "        print(f\"Test directory {test_dir} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    test_files = list(test_dir.glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        print(\"No test audio files found.\")\n",
    "        return []\n",
    "\n",
    "    if cfg.debug:\n",
    "        print(f\"Debug mode enabled, using only {cfg.debug_count} files\")\n",
    "        test_files = test_files[:cfg.debug_count]\n",
    "\n",
    "    results = Parallel(n_jobs=cfg.n_jobs)(\n",
    "        delayed(process_audio_file)(path, cfg) for path in tqdm(test_files, desc=\"Parallel melspec gen\")\n",
    "    )\n",
    "    dataset = [item for sublist in results for item in sublist]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# openvino„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø\n",
    "def load_openvino_models(vino_dir, cfg):\n",
    "    models = []\n",
    "    vino_dir = Path(vino_dir)\n",
    "\n",
    "    if cfg.use_specific_folds:\n",
    "        fold_ids = cfg.folds\n",
    "        xml_files = [vino_dir / f\"model_fold{f}.xml\" for f in fold_ids]\n",
    "    else:\n",
    "        xml_files = sorted(vino_dir.glob(\"model_fold*.xml\"))\n",
    "\n",
    "    for xml_path in xml_files:\n",
    "        bin_path = xml_path.with_suffix(\".bin\")\n",
    "\n",
    "        if not xml_path.exists() or not bin_path.exists():\n",
    "            print(f\"‚ö†Ô∏è Warning: Missing files for {xml_path.stem}\")\n",
    "            continue\n",
    "\n",
    "        core = Core()\n",
    "        model_ir = core.read_model(xml_path)\n",
    "        compiled_model = core.compile_model(model_ir, device_name=\"CPU\")\n",
    "        models.append(compiled_model)\n",
    "\n",
    "        # üîç „É¢„Éá„É´„ÅÆ„Éï„Ç°„Ç§„É´ÂêçÔºàfoldÊÉÖÂ†±Ôºâ„Çí„É≠„Ç∞„Å´Âá∫„Åô\n",
    "        print(f\"‚úÖ Loaded model: {xml_path.name}\")\n",
    "\n",
    "    print(f\"üéâ Total {len(models)} OpenVINO model(s) loaded from {vino_dir}\")\n",
    "    return models\n",
    "\n",
    "# openvino„É¢„Éá„É´„Å´„Çà„ÇãÊé®Ë´ñ\n",
    "def run_inference_openvino(dataset, models_ir, cfg, species_ids):\n",
    "    row_ids = []\n",
    "    all_preds = []\n",
    "\n",
    "    for i in range(0, len(dataset), cfg.batch_size):\n",
    "        batch = dataset[i:i+cfg.batch_size]\n",
    "\n",
    "        mel_list = [item[\"mel_spec\"] for item in batch]\n",
    "        input_tensor = np.stack(mel_list).astype(np.float32)  # (B, H, W)\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=1)  # (B, 1, H, W)\n",
    "\n",
    "        preds_per_model = []\n",
    "        for model in models_ir:\n",
    "            input_layer = model.input(0)\n",
    "            output_layer = model.output(0)\n",
    "            result = model([input_tensor])[output_layer]\n",
    "            probs = 1 / (1 + np.exp(-result))  # sigmoid\n",
    "            preds_per_model.append(probs)\n",
    "\n",
    "        # „Ç¢„É≥„Çµ„É≥„Éñ„É´Êà¶Áï•„ÅÆÈÅ∏Êäû\n",
    "        if cfg.ensemble_strategy == \"mean\":\n",
    "            avg_preds = np.mean(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"max\":\n",
    "            avg_preds = np.max(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"min\":\n",
    "            avg_preds = np.min(preds_per_model, axis=0)\n",
    "        elif cfg.ensemble_strategy == \"median\":\n",
    "            avg_preds = np.median(preds_per_model, axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ensemble strategy: {cfg.ensemble_strategy}\")\n",
    "\n",
    "        all_preds.append(avg_preds)\n",
    "        row_ids.extend([item[\"row_id\"] for item in batch])\n",
    "\n",
    "    predictions = np.concatenate(all_preds, axis=0)\n",
    "    return row_ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_save(cfg, species_ids):\n",
    "    print(f\"\\nüìå Processing model at: {cfg.model_path}\")\n",
    "    print(\"Generating dataset...\")\n",
    "    dataset = generate_melspec_dataset(cfg)\n",
    "\n",
    "    print(\"Loading OpenVINO models...\")\n",
    "    vino_dir = Path(cfg.model_path).with_name(Path(cfg.model_path).name)\n",
    "    models_ir = load_openvino_models(vino_dir, cfg)\n",
    "\n",
    "    if not models_ir:\n",
    "        raise RuntimeError(\"No OpenVINO models found.\")\n",
    "\n",
    "    print(\"Running OpenVINO inference...\")\n",
    "    if len(dataset) > 0:\n",
    "        row_ids, predictions = run_inference_openvino(dataset, models_ir, cfg, species_ids)\n",
    "    else:\n",
    "        print(\"No test data available, generating empty submission.\")\n",
    "        row_ids = []\n",
    "        predictions = []\n",
    "\n",
    "    # smoothingÂâç„ÅÆ‰∫àÊ∏¨ÂÄ§„Çí‰øùÂ≠ò\n",
    "    submission_df = utils_lib.create_submission(row_ids, predictions, species_ids, cfg)\n",
    "\n",
    "    return submission_df\n",
    "\n",
    "\n",
    "# ‰∫àÊ∏¨ÂÄ§„ÅÆdf_list„ÇíÂèó„ÅëÂèñ„Å£„Å¶„Ç¢„É≥„Çµ„É≥„Éñ„É´\n",
    "def ensemble_submissions_dfs(dfs, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Ë§áÊï∞„ÅÆ submission DataFrame „Çí„Ç¢„É≥„Çµ„É≥„Éñ„É´\n",
    "\n",
    "    Parameters:\n",
    "        dfs (List[pd.DataFrame]): ÂêÑ submission.csv „ÇíË™≠„ÅøËæº„Çì„Å† DataFrame „ÅÆ„É™„Çπ„Éà\n",
    "        method (str): „Ç¢„É≥„Çµ„É≥„Éñ„É´Êà¶Áï•Ôºàmean, max, medianÔºâ\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: „Ç¢„É≥„Çµ„É≥„Éñ„É´Âæå„ÅÆ submission\n",
    "    \"\"\"\n",
    "    assert all(df.columns[0] == \"row_id\" for df in dfs), \"All DataFrames must start with 'row_id' column\"\n",
    "    row_ids = dfs[0]['row_id'].values\n",
    "    preds = np.stack([df.iloc[:, 1:].values for df in dfs], axis=0)  # (n_models, n_rows, n_classes)\n",
    "\n",
    "    if method == \"mean\":\n",
    "        combined = np.mean(preds, axis=0)\n",
    "    elif method == \"max\":\n",
    "        combined = np.max(preds, axis=0)\n",
    "    elif method == \"median\":\n",
    "        combined = np.median(preds, axis=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ensemble method: {method}\")\n",
    "\n",
    "    result_df = pd.DataFrame(combined, columns=dfs[0].columns[1:])\n",
    "    result_df.insert(0, \"row_id\", row_ids)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def smooth_submission_df(submission_df, cfg, weights=None):\n",
    "    \"\"\"\n",
    "    Smooth predictions using weighted moving average over a 5-frame window: [-2, -1, 0, +1, +2],\n",
    "    then blend with per-class global average within each soundscape segment group.\n",
    "\n",
    "    Parameters:\n",
    "        submission_df: pd.DataFrame with 'row_id' and prediction columns.\n",
    "        cfg: config object (interface compatibility).\n",
    "        weights: List of 5 floats (default = [0.1, 0.2, 0.4, 0.2, 0.1]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with smoothed predictions.\n",
    "    \"\"\"\n",
    "    print(\"Smoothing submission predictions with global average blend...\")\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.array([0.1, 0.2, 0.4, 0.2, 0.1])\n",
    "    else:\n",
    "        weights = np.array(weights)\n",
    "\n",
    "    sub = submission_df.copy()\n",
    "    cols = sub.columns[1:]\n",
    "    groups = sub['row_id'].astype(str).str.rsplit('_', n=1).str[0].values\n",
    "    unique_groups = np.unique(groups)\n",
    "\n",
    "    for group in unique_groups:\n",
    "        idx = np.where(groups == group)[0]\n",
    "        preds = sub.iloc[idx][cols].values  # (T, C)\n",
    "        T, C = preds.shape\n",
    "\n",
    "        # „Ç®„ÉÉ„Ç∏Âá¶ÁêÜÔºöÁ´Ø„ÇíÁπ∞„ÇäËøî„Åô„Çà„ÅÜ„Å´„Éë„Éá„Ç£„É≥„Ç∞\n",
    "        padded = np.pad(preds, ((2, 2), (0, 0)), mode='edge')  # (T+4, C)\n",
    "\n",
    "        # Âπ≥ÊªëÂåñÔºö5ÁÇπÂä†ÈáçÂπ≥ÂùáÔºà[-2, -1, 0, +1, +2]Ôºâ\n",
    "        smoothed = (\n",
    "            padded[0:T]   * weights[0] +\n",
    "            padded[1:T+1] * weights[1] +\n",
    "            padded[2:T+2] * weights[2] +\n",
    "            padded[3:T+3] * weights[3] +\n",
    "            padded[4:T+4] * weights[4]\n",
    "        )\n",
    "\n",
    "        # ÂêÑ„ÇØ„É©„Çπ„ÅÆÂπ≥Âùá‰∫àÊ∏¨„Çí20%Ê∑∑„Åú„ÇãÔºàÂÖ®„Çª„Ç∞„É°„É≥„Éà„Å´ÂØæ„Åó„Å¶‰∏ÄÊßò„Å´Âä†„Åà„ÇãÔºâ\n",
    "        classwise_mean = smoothed.mean(axis=0, keepdims=True)  # shape: (1, C)\n",
    "        smoothed = smoothed * 0.8 + classwise_mean * 0.2\n",
    "\n",
    "        sub.iloc[idx, 1:] = smoothed\n",
    "\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Processing model at: ../models/fold0_safezone1000_head_vino/\n",
      "Generating dataset...\n",
      "No test audio files found.\n",
      "Loading OpenVINO models...\n",
      "‚úÖ Loaded model: model_fold0.xml\n",
      "üéâ Total 1 OpenVINO model(s) loaded from ../models/fold0_safezone1000_head_vino\n",
      "Running OpenVINO inference...\n",
      "No test data available, generating empty submission.\n",
      "Creating submission dataframe...\n",
      "\n",
      "üìå Processing model at: ../models/fold0_safezone1000_head_hoplength512_vino/\n",
      "Generating dataset...\n",
      "No test audio files found.\n",
      "Loading OpenVINO models...\n",
      "‚úÖ Loaded model: model_fold0.xml\n",
      "üéâ Total 1 OpenVINO model(s) loaded from ../models/fold0_safezone1000_head_hoplength512_vino\n",
      "Running OpenVINO inference...\n",
      "No test data available, generating empty submission.\n",
      "Creating submission dataframe...\n"
     ]
    }
   ],
   "source": [
    "cfg_list = load_all_configs()  # Ë§áÊï∞CFG„ÇíËøî„ÅôÈñ¢Êï∞\n",
    "inference_dfs = []\n",
    "\n",
    "for cfg in cfg_list:\n",
    "    df = run_inference_and_save(cfg, species_ids)\n",
    "    inference_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensembled (before smoothing) submission.\n",
      "Smoothing submission predictions with global average blend...\n",
      "Saved smoothed final submission.\n"
     ]
    }
   ],
   "source": [
    "# „Ç¢„É≥„Çµ„É≥„Éñ„É´\n",
    "ensemble_df = ensemble_submissions_dfs(inference_dfs, method=\"mean\")\n",
    "ensemble_df.to_csv(os.path.join(cfg_list[0].OUTPUT_DIR, 'submission_before_smoothing.csv'), index=False)\n",
    "print(\"Saved ensembled (before smoothing) submission.\")\n",
    "\n",
    "# „Çπ„É†„Éº„Ç∏„É≥„Ç∞\n",
    "smoothed_df = smooth_submission_df(ensemble_df, cfg_list[0])\n",
    "smoothed_df.to_csv(os.path.join(cfg_list[0].OUTPUT_DIR, 'submission.csv'), index=False)\n",
    "print(\"Saved smoothed final submission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÊèêÂá∫Áî®„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "submission = pd.read_csv(os.path.join(cfg.OUTPUT_DIR, 'submission.csv'))\n",
    "submission.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(os.path.join(cfg.OUTPUT_DIR, 'submission_before_smoothing.csv'))\n",
    "submission.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape: (0, 207)\n",
      "‚úÖ Columns: ['row_id', '1139490', '1192948', '1194042', '126247', '1346504', '134933', '135045', '1462711', '1462737', '1564122', '21038', '21116', '21211', '22333', '22973', '22976', '24272', '24292', '24322', '41663', '41778', '41970', '42007', '42087', '42113', '46010', '47067', '476537', '476538', '48124', '50186', '517119', '523060', '528041', '52884', '548639', '555086', '555142', '566513', '64862', '65336', '65344', '65349', '65373', '65419', '65448', '65547', '65962', '66016', '66531', '66578', '66893', '67082', '67252', '714022', '715170', '787625', '81930', '868458', '963335', 'amakin1', 'amekes', 'ampkin1', 'anhing', 'babwar', 'bafibi1', 'banana', 'baymac', 'bbwduc', 'bicwre1', 'bkcdon', 'bkmtou1', 'blbgra1', 'blbwre1', 'blcant4', 'blchaw1', 'blcjay1', 'blctit1', 'blhpar1', 'blkvul', 'bobfly1', 'bobher1', 'brtpar1', 'bubcur1', 'bubwre1', 'bucmot3', 'bugtan', 'butsal1', 'cargra1', 'cattyr', 'chbant1', 'chfmac1', 'cinbec1', 'cocher1', 'cocwoo1', 'colara1', 'colcha1', 'compau', 'compot1', 'cotfly1', 'crbtan1', 'crcwoo1', 'crebob1', 'cregua1', 'creoro1', 'eardov1', 'fotfly', 'gohman1', 'grasal4', 'grbhaw1', 'greani1', 'greegr', 'greibi1', 'grekis', 'grepot1', 'gretin1', 'grnkin', 'grysee1', 'gybmar', 'gycwor1', 'labter1', 'laufal1', 'leagre', 'linwoo1', 'littin1', 'mastit1', 'neocor', 'norscr1', 'olipic1', 'orcpar', 'palhor2', 'paltan1', 'pavpig2', 'piepuf1', 'pirfly1', 'piwtyr1', 'plbwoo1', 'plctan1', 'plukit1', 'purgal2', 'ragmac1', 'rebbla1', 'recwoo1', 'rinkin1', 'roahaw', 'rosspo1', 'royfly1', 'rtlhum', 'rubsee1', 'rufmot1', 'rugdov', 'rumfly1', 'ruther1', 'rutjac1', 'rutpuf1', 'saffin', 'sahpar1', 'savhaw1', 'secfly1', 'shghum1', 'shtfly1', 'smbani', 'snoegr', 'sobtyr1', 'socfly1', 'solsan', 'soulap1', 'spbwoo1', 'speowl1', 'spepar1', 'srwswa1', 'stbwoo2', 'strcuc1', 'strfly1', 'strher', 'strowl1', 'tbsfin1', 'thbeup1', 'thlsch3', 'trokin', 'tropar', 'trsowl', 'turvul', 'verfly', 'watjac1', 'wbwwre1', 'whbant1', 'whbman1', 'whfant1', 'whmtyr1', 'whtdov', 'whttro1', 'whwswa1', 'woosto', 'y00678', 'yebela1', 'yebfly1', 'yebsee1', 'yecspi2', 'yectyr1', 'yehbla2', 'yehcar1', 'yelori1', 'yeofly1', 'yercac1', 'ywcpar']\n",
      "‚úÖ Dtypes:\n",
      " row_id     object\n",
      "1139490    object\n",
      "1192948    object\n",
      "1194042    object\n",
      "126247     object\n",
      "            ...  \n",
      "yehcar1    object\n",
      "yelori1    object\n",
      "yeofly1    object\n",
      "yercac1    object\n",
      "ywcpar     object\n",
      "Length: 207, dtype: object\n",
      "‚úÖ Nulls:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Shape:\", submission.shape)\n",
    "print(\"‚úÖ Columns:\", submission.columns.tolist())\n",
    "print(\"‚úÖ Dtypes:\\n\", submission.dtypes)\n",
    "print(\"‚úÖ Nulls:\\n\", submission.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
