import os
import pandas as pd
import torch
from glob import glob
from tqdm import tqdm
from datetime import datetime, timedelta, timezone


def detect_speech_segments(audio_dir, debug=False, debug_count=50, threshold=0.5):
    print("ğŸ” Silero VAD ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­...")
    model, (get_speech_timestamps, _, read_audio, _, _) = torch.hub.load(
        repo_or_dir='snakers4/silero-vad',
        model='silero_vad',
        trust_repo=True
    )

    print(f"ğŸ“‚ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿å…ƒ: {audio_dir}")
    ogg_files = sorted(glob(os.path.join(audio_dir, "*", "*.ogg")))
    print(f"ğŸ§ å…¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(ogg_files)}")

    if debug:
        ogg_files = ogg_files[:debug_count]
        print(f"ğŸš¨ [DEBUG MODE] æœ€åˆã® {debug_count} ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†ã—ã¾ã™")

    speech_rows = []

    for fname in tqdm(ogg_files):
        try:
            wav = read_audio(fname)
            speech_segments = get_speech_timestamps(wav, model, return_seconds=True, threshold=threshold)

            for seg in speech_segments:
                speech_rows.append({
                    "filename": os.path.relpath(fname, audio_dir),
                    "start": round(seg["start"], 2),
                    "end": round(seg["end"], 2)
                })

        except Exception as e:
            print(f"[Error] {fname}: {e}")

    speech_df = pd.DataFrame(speech_rows)

    # === JSTæ™‚åˆ»ã§ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ===
    JST = timezone(timedelta(hours=9), 'JST')
    timestamp = datetime.now(JST).strftime("%Y%m%d_%H%M")
    output_dir = f"../data/processed/human_voice_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)

    output_csv = os.path.join(output_dir, "human_voice.csv")
    speech_df.to_csv(output_csv, index=False)

    print(f"\nâœ… æ¤œå‡ºçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_csv}")
    print(speech_df.head())

# ==== å®Ÿè¡Œä¾‹ ====
AUDIO_DIR = "../data/raw/train_audio"


detect_speech_segments(AUDIO_DIR, debug=False)

