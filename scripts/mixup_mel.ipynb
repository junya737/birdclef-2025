{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.81525Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from module import config_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    def __init__(self, kaggle_notebook=False, debug=False):\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # å…¨modelã®ä¿å­˜å…ˆ\n",
    "            self.model_path = self.models_dir # å„ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆï¼å­¦ç¿’æ™‚ã«å‹•çš„ã«å¤‰æ›´ï¼\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            \n",
    "            self.train_csv = '../data/processed/mel_CropAugment/train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_CropAugment/birdclef2025_melspec_5sec_256_256.npy'\n",
    "\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5.0 # æ¨è«–æ™‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "        self.TARGET_DURATION = 5 # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆæ™‚ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 16\n",
    "        self.N_MELS = 148\n",
    "        self.FMIN = 20\n",
    "        self.FMAX = 16000\n",
    "        self.N_MAX = 50 if self.debug else None        \n",
    "        self.N_JOBS = 16  # ä¸¦åˆ—å‡¦ç†ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•° 16ãã‚‰ã„ã§ã„ã„\n",
    "        self.LOAD_ENGINE = 'torchaudio'  # librosa or torchaudio\n",
    "        self.SKIP_RESIZE = False  # resizeã—ãªã„ãªã‚‰True\n",
    "        self.seed = 42\n",
    "        self.n_fold = 5\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = DatasetConfig(kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.55526Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: OFF\n",
      "Max samples to process: ALL\n",
      "Loading taxonomy data...\n",
      "Loading training metadata...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if cfg.debug else 'OFF'}\")\n",
    "print(f\"Max samples to process: {cfg.N_MAX if cfg.N_MAX is not None else 'ALL'}\")\n",
    "\n",
    "print(\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(f'{cfg.RAW_DIR}/taxonomy.csv')\n",
    "species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "\n",
    "print(\"Loading training metadata...\")\n",
    "train_df = pd.read_csv(f'{cfg.RAW_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_aug = pd.read_csv(cfg.train_csv)\n",
    "# mixupã®æœ‰ç„¡ã‚’ç¤ºã™ã‚«ãƒ©ãƒ ã‚’è¿½åŠ \n",
    "if 'is_mixup' not in working_df_aug.columns:\n",
    "    working_df_aug['is_mixup'] = False\n",
    "if 'mix_partner' not in working_df_aug.columns:\n",
    "    working_df_aug['mix_partner'] = None\n",
    "if 'mixup_weight' not in working_df_aug.columns:\n",
    "    working_df_aug['mixup_weight'] = None\n",
    "\n",
    "# === 2. Rare label æŠ½å‡ºï¼ˆä¾‹: <50ä»¶ï¼‰ ===\n",
    "label_counts = working_df_aug['primary_label'].value_counts()\n",
    "# âœ… ãƒ¬ã‚¢ç¨®å€™è£œã® primary_label ã‚’æŠ½å‡º\n",
    "rare_labels = working_df_aug.loc[working_df_aug['n_augment'] > 0, 'primary_label'].unique().tolist()\n",
    "\n",
    "# âœ… ãã®ã†ã¡ã® crop ã ã‘ã‚’å¯¾è±¡ã«\n",
    "rare_crop_df = working_df_aug[\n",
    "    (working_df_aug['primary_label'].isin(rare_labels)) &\n",
    "    (working_df_aug['samplename'].str.contains('_crop')) &\n",
    "    (~working_df_aug['samplename'].str.contains('_mix_'))  # æ—¢å­˜mixupé™¤å¤–\n",
    "]\n",
    "\n",
    "# === ãƒ©ãƒ™ãƒ«æƒ…å ± ===\n",
    "label2id = {label: idx for idx, label in enumerate(sorted(working_df_aug['primary_label'].unique()))}\n",
    "num_classes = len(label2id)\n",
    "\n",
    "# === ãƒ¬ã‚¢ç¨®cropï¼ˆaugmentationã•ã‚ŒãŸï¼‰ã ã‘ã‚’æŠ½å‡º ===\n",
    "rare_crop_df = working_df_aug[\n",
    "    (working_df_aug['n_augment'] > 0) &\n",
    "    (working_df_aug['samplename'].str.contains('_crop')) &\n",
    "    (~working_df_aug['samplename'].str.contains('_mix_'))\n",
    "].copy()\n",
    "\n",
    "# === ã‚³ãƒ¢ãƒ³ç¨®æŠ½å‡º ===\n",
    "num_common_labels = 50 # 50ä½ã§ãƒ‡ãƒ¼ã‚¿æ•°180ç¨‹åº¦ï¼\n",
    "label_counts = working_df_aug['primary_label'].value_counts()\n",
    "common_labels = label_counts.head(num_common_labels).index.tolist()\n",
    "\n",
    "common_df = working_df_aug[working_df_aug['primary_label'].isin(common_labels)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¬ã‚¢ç¨®ã«ã‚³ãƒ¢ãƒ³ç¨®ã‚’æ··ãœã¦ä¸Šæ›¸ãï¼cropã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¯ã™ã¹ã¦mixupå¯¾è±¡\n",
    "all_bird_data = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "\n",
    "for idx, row in rare_crop_df.iterrows():\n",
    "    s_rare = row['samplename']\n",
    "    label = row['primary_label']\n",
    "    if s_rare not in all_bird_data:\n",
    "        continue\n",
    "\n",
    "    # === ã‚³ãƒ¢ãƒ³ç¨®ã®cropã‚’1ã¤ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ ä¹±æ•°å›ºå®š\n",
    "    s_common_row = common_df.sample(1, random_state=cfg.seed + idx).iloc[0]\n",
    "    s_common = s_common_row['samplename']\n",
    "    common_label = s_common_row['primary_label']\n",
    "\n",
    "    if s_common not in all_bird_data:\n",
    "        continue\n",
    "\n",
    "    # === Mixupå®Ÿè¡Œ ===\n",
    "    m1 = all_bird_data[s_rare]\n",
    "    m2 = all_bird_data[s_common]\n",
    "\n",
    "    lam = np.random.uniform(0.7, 0.9)\n",
    "    mixed = np.clip(lam * m1 + (1 - lam) * m2, 0, 1)\n",
    "\n",
    "    # === melã‚’ä¸Šæ›¸ã ===\n",
    "    all_bird_data[s_rare] = mixed\n",
    "\n",
    "    # === working_dfã®è©²å½“è¡Œã‚’æ›´æ–° ===\n",
    "    working_df_aug.loc[idx, 'is_mixup'] = True\n",
    "    working_df_aug.loc[idx, 'mix_partner'] = s_common\n",
    "    working_df_aug.loc[idx, 'mixup_weight'] = round(float(lam), 4)\n",
    "\n",
    "    # === secondary_labels ã‚’è¿½åŠ ãƒ»æ›´æ–° ===\n",
    "    try:\n",
    "        current_sec = row['secondary_labels']\n",
    "        current_sec_list = eval(current_sec) if isinstance(current_sec, str) else []\n",
    "    except:\n",
    "        current_sec_list = []\n",
    "\n",
    "    # --- å‹ãƒ»å½¢å¼ã®å®‰å…¨å‡¦ç† ---\n",
    "    if not isinstance(current_sec_list, list):\n",
    "        current_sec_list = []\n",
    "\n",
    "    # âœ… ç©ºæ–‡å­—ã‚„Noneã‚’é™¤å»\n",
    "    current_sec_list = [s for s in current_sec_list if s and s.strip() != '']\n",
    "\n",
    "    # âœ… ã‚³ãƒ¢ãƒ³ç¨®ãƒ©ãƒ™ãƒ«ãŒå…¥ã£ã¦ã„ãªã‘ã‚Œã°è¿½åŠ \n",
    "    if common_label not in current_sec_list:\n",
    "        current_sec_list.append(common_label)\n",
    "\n",
    "    working_df_aug.loc[idx, 'secondary_labels'] = str(current_sec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Mel-spectrograms saved to: ../data/processed/melspec_20250412_1803/birdclef2025_melspec_5sec_256_256.npy\n",
      "ğŸ“¦ File size: 7980.93 MB\n",
      "ğŸ“ Example shape: (256, 256)\n",
      "ğŸ“ Config saved to: ../data/processed/melspec_20250412_1803/config.csv\n",
      "ğŸ“ Augmented training metadata saved to: ../data/processed/melspec_20250412_1803/train.csv\n",
      "ğŸ“Š Total rows: 31913\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# === JSTæ™‚åˆ»ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ===\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.now(jst)\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# âœ… ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ debug ã«å¿œã˜ã¦åˆ†å²\n",
    "if cfg.debug:\n",
    "    output_dir = os.path.join(cfg.PROCESSED_DIR, \"data_debugs\")\n",
    "else:\n",
    "    output_dir = os.path.join(cfg.PROCESSED_DIR, f\"melspec_{timestamp}\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 1. melã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆall_bird_dataï¼‰ã®ä¿å­˜ ===\n",
    "output_path = os.path.join(output_dir, \"birdclef2025_melspec_5sec_256_256.npy\")\n",
    "\n",
    "wrapped_array = np.array(all_bird_data, dtype=object)\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(wrapped_array, f, protocol=5)\n",
    "\n",
    "print(f\"\\nâœ… Mel-spectrograms saved to: {output_path}\")\n",
    "print(f\"ğŸ“¦ File size: {os.path.getsize(output_path) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"ğŸ“ Example shape: {next(iter(all_bird_data.values())).shape}\")\n",
    "\n",
    "# === 2. configã®ä¿å­˜ ===\n",
    "config_path = os.path.join(output_dir, \"config.csv\")\n",
    "config_dict = {k: v for k, v in vars(cfg).items() if not k.startswith(\"__\")}\n",
    "\n",
    "with open(config_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"key\", \"value\"])\n",
    "    for key, value in config_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "print(f\"ğŸ“ Config saved to: {config_path}\")\n",
    "\n",
    "# === 3. augmented metadata ã®ä¿å­˜ ===\n",
    "train_csv_path = os.path.join(output_dir, \"train.csv\")\n",
    "working_df_aug.to_csv(train_csv_path, index=False)\n",
    "\n",
    "print(f\"ğŸ“ Augmented training metadata saved to: {train_csv_path}\")\n",
    "print(f\"ğŸ“Š Total rows: {len(working_df_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
