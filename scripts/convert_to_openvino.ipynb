{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from module import models_lib, utils_lib, preprocess_lib, inference_lib\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from module import models_lib\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "from openvino.runtime import Core\n",
    "from module import models_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥\n",
    "            self.model_path = \"/kaggle/input/birdclef-2025-baseline-fold0-0404\"\n",
    "            \n",
    "            self.device = \"cpu\"\n",
    "            self.batch_size = 8\n",
    "            self.n_jobs = 2\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel-spec_0329/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.MODELS_DIR = \"../models/\"\n",
    "            \n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥\n",
    "            self.model_path =  \"../models/mel_cleaned_contrast02/\"\n",
    "            \n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.batch_size = 32\n",
    "            self.n_jobs = 16\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0'\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5\n",
    "        self.TARGET_DURATION = 5\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.N_MELS = 128\n",
    "        self.FMIN = 50\n",
    "        self.FMAX = 14000\n",
    "        \n",
    "        self.seed = 42\n",
    "\n",
    "\n",
    "        # ===== Inference Mode =====\n",
    "        if mode == \"inference\":\n",
    "            self.use_tta = False\n",
    "            self.tta_count = 3\n",
    "            self.threshold = 0.5\n",
    "\n",
    "            self.use_specific_folds = False\n",
    "            self.folds = [0, 1, 2, 3, 4]  # Used only if use_specific_folds is True\n",
    "\n",
    "            self.debug_count = 3\n",
    "            \n",
    "            \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(cfg, num_classes):\n",
    "    \"\"\"\n",
    "    Load all found model files and prepare them for ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    model_files = models_lib.find_model_files(cfg)\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
    "        return models\n",
    "    \n",
    "    print(f\"Found a total of {len(model_files)} model files.\")\n",
    "    \n",
    "    if cfg.use_specific_folds:\n",
    "        filtered_files = []\n",
    "        for fold in cfg.folds:\n",
    "            fold_files = [f for f in model_files if f\"fold{fold}\" in f]\n",
    "            filtered_files.extend(fold_files)\n",
    "        model_files = filtered_files\n",
    "        print(f\"Using {len(model_files)} model files for the specified folds ({cfg.folds}).\")\n",
    "    \n",
    "    for model_path in model_files:\n",
    "        try:\n",
    "            print(f\"Loading model: {model_path}\")\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device))\n",
    "            \n",
    "            model = models_lib.BirdCLEFModelForInference(cfg, num_classes)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(cfg.device)\n",
    "            # Êé®Ë´ñ„É¢„Éº„Éâ\n",
    "            model.eval()\n",
    "            \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_path}: {e}\")\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode='inference', kaggle_notebook=False)\n",
    "\n",
    "# Set seed\n",
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Saving ONNX & IR files to: /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino\n",
      "üì¶ Loading all fold models...\n",
      "Found a total of 5 model files.\n",
      "Loading model: ../models/mel_cleaned_contrast02/model_fold0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ../models/mel_cleaned_contrast02/model_fold1.pth\n",
      "Loading model: ../models/mel_cleaned_contrast02/model_fold2.pth\n",
      "Loading model: ../models/mel_cleaned_contrast02/model_fold3.pth\n",
      "Loading model: ../models/mel_cleaned_contrast02/model_fold4.pth\n",
      "\n",
      "üîÅ [Fold 0] Converting model...\n",
      "‚úÖ Exported ONNX: model_fold0.onnx\n",
      "‚úÖ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold0.xml\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold0.bin\n",
      "\n",
      "üîÅ [Fold 1] Converting model...\n",
      "‚úÖ Exported ONNX: model_fold1.onnx\n",
      "‚úÖ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold1.xml\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold1.bin\n",
      "\n",
      "üîÅ [Fold 2] Converting model...\n",
      "‚úÖ Exported ONNX: model_fold2.onnx\n",
      "‚úÖ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold2.xml\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold2.bin\n",
      "\n",
      "üîÅ [Fold 3] Converting model...\n",
      "‚úÖ Exported ONNX: model_fold3.onnx\n",
      "‚úÖ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold3.xml\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold3.bin\n",
      "\n",
      "üîÅ [Fold 4] Converting model...\n",
      "‚úÖ Exported ONNX: model_fold4.onnx\n",
      "‚úÖ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold4.xml\n",
      "   - /root/program/birdclef-2025/models/mel_cleaned_contrast02_vino/model_fold4.bin\n"
     ]
    }
   ],
   "source": [
    "# model.pth„ÇíopenvinoÂΩ¢Âºè„Å´Â§âÊèõÔºé\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import os\n",
    "\n",
    "# === ÂàùÊúüË®≠ÂÆö ===\n",
    "cfg = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "\n",
    "# ‰øùÂ≠òÂÖà: \"model_path_vino/\"\n",
    "# „É¢„Éá„É´ÂÖÉ„Éá„Ç£„É¨„ÇØ„Éà„É™Ôºà„Åü„Å®„Åà„Å∞ ../models/baseline_fold0_0404Ôºâ\n",
    "model_dir = Path(cfg.model_path).resolve()  # Áµ∂ÂØæ„Éë„Çπ„Å´Â§âÊèõ\n",
    "vino_dir = model_dir.parent / (model_dir.name + \"_vino\")  # ‚Üê ÂÖÑÂºü„Éï„Ç©„É´„ÉÄ„Å®„Åó„Å¶ _vino „Çí‰ΩúÊàê\n",
    "\n",
    "vino_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Saving ONNX & IR files to: {vino_dir}\")\n",
    "\n",
    "# === dataset-metadata.json„ÅÆ‰ΩúÊàê ===\n",
    "japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "dataset_metadata = {\n",
    "    \"title\": f\"bc25-models-{current_time}\",\n",
    "    \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"CC0-1.0\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "metadata_path = os.path.join(vino_dir, \"dataset-metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(dataset_metadata, f, indent=2)\n",
    "    \n",
    "\n",
    "# === „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÔºàÂÖ®foldÔºâ===\n",
    "print(\"üì¶ Loading all fold models...\")\n",
    "models = models_lib.load_models(cfg, num_classes)\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"\\nüîÅ [Fold {fold}] Converting model...\")\n",
    "    model = model.to(\"cpu\")  \n",
    "    model.eval()\n",
    "\n",
    "    # Step 1: Export to ONNX\n",
    "    onnx_path = vino_dir / f\"model_fold{fold}.onnx\"\n",
    "    dummy_input = torch.randn(1, cfg.in_channels, *cfg.TARGET_SHAPE)  # ‚Üê „Åì„Åì„Å†„Åë‰øÆÊ≠£ÔºÅ\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "        opset_version=11\n",
    "    )\n",
    "    print(f\"‚úÖ Exported ONNX: {onnx_path.name}\")\n",
    "\n",
    "    # Step 2: Convert to OpenVINO IR\n",
    "    result = subprocess.run(\n",
    "        [\"ovc\", str(onnx_path)],\n",
    "        cwd=str(vino_dir),  # ‚Üê „Åì„Çå„ÅåÈáçË¶ÅÔºÅ\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ùå OpenVINO conversion failed for fold{fold}:\")\n",
    "        print(\"----- stderr -----\")\n",
    "        print(result.stderr)\n",
    "        print(\"----- stdout -----\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"‚úÖ Converted to OpenVINO IR:\")\n",
    "        print(f\"   - {(vino_dir / f'model_fold{fold}.xml').resolve()}\")\n",
    "        print(f\"   - {(vino_dir / f'model_fold{fold}.bin').resolve()}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
