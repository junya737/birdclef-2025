{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from module import models_lib, utils_lib, preprocess_lib, inference_lib\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from module import models_lib\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from openvino.runtime import Core\n",
    "from module import models_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # kaggle notebookならここを変更\n",
    "            self.model_path = \"/kaggle/input/birdclef-2025-baseline-fold0-0404\"\n",
    "            \n",
    "            self.device = \"cpu\"\n",
    "            self.batch_size = 8\n",
    "            self.n_jobs = 2\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            self.train_csv = '../data/raw/train.csv'\n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel-spec_0329/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.MODELS_DIR = \"../models/\"\n",
    "            \n",
    "            # ローカルならここを変更\n",
    "            self.model_path =  \"../models/fld0_sfzn1_hd_hl16_psdMxp///\"\n",
    "            \n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.batch_size = 32\n",
    "            self.n_jobs = 16\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0' #   tf_efficientnetv2_b3\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5\n",
    "        self.TARGET_DURATION = 5\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.N_MELS = 128\n",
    "        self.FMIN = 50\n",
    "        self.FMAX = 14000\n",
    "        \n",
    "        self.seed = 42\n",
    "\n",
    "\n",
    "        # ===== Inference Mode =====\n",
    "        if mode == \"inference\":\n",
    "            self.use_tta = False\n",
    "            self.tta_count = 3\n",
    "            self.threshold = 0.5\n",
    "\n",
    "            self.use_specific_folds = False\n",
    "            self.folds = [0, 1, 2, 3, 4]  # Used only if use_specific_folds is True\n",
    "\n",
    "            self.debug_count = 3\n",
    "            \n",
    "            \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.selected_folds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BirdCLEFModelForInference(nn.Module):\n",
    "    def __init__(self, cfg, num_classes):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=False,  \n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.0,    \n",
    "            drop_path_rate=0.0\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "class BirdCLEFModelForInference_Coat(nn.Module):\n",
    "    def __init__(self, cfg, num_classes):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=False,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.0,\n",
    "            drop_path_rate=0.0,\n",
    "        )\n",
    "        \n",
    "        # CoaT系だけ reset_classifier('avg') が必要\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(cfg, num_classes):\n",
    "    \"\"\"\n",
    "    Load all found model files and prepare them for ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    model_files = models_lib.find_model_files(cfg)\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
    "        return models\n",
    "    \n",
    "    print(f\"Found a total of {len(model_files)} model files.\")\n",
    "    \n",
    "    if cfg.use_specific_folds:\n",
    "        filtered_files = []\n",
    "        for fold in cfg.folds:\n",
    "            fold_files = [f for f in model_files if f\"fold{fold}\" in f]\n",
    "            filtered_files.extend(fold_files)\n",
    "        model_files = filtered_files\n",
    "        print(f\"Using {len(model_files)} model files for the specified folds ({cfg.folds}).\")\n",
    "    \n",
    "    for model_path in model_files:\n",
    "        try:\n",
    "            print(f\"Loading model: {model_path}\")\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device))\n",
    "            \n",
    "            if 'coat' in cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForInference_Coat(cfg, num_classes)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForInference(cfg, num_classes)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(cfg.device)\n",
    "            # 推論モード\n",
    "            model.eval()\n",
    "            \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_path}: {e}\")\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode='inference', kaggle_notebook=False)\n",
    "\n",
    "# Set seed\n",
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Saving ONNX & IR files to: /root/program/birdclef-2025/models/fld0_sfzn1_hd_hl16_psdMxp_vino\n",
      "📦 Loading all fold models...\n",
      "Found a total of 1 model files.\n",
      "Loading model: ../models/fld0_sfzn1_hd_hl16_psdMxp/model_fold0.pth\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "🔁 [Fold 0] Converting model...\n",
      "✅ Exported ONNX: model_fold0.onnx\n",
      "✅ Converted to OpenVINO IR:\n",
      "   - /root/program/birdclef-2025/models/fld0_sfzn1_hd_hl16_psdMxp_vino/model_fold0.xml\n",
      "   - /root/program/birdclef-2025/models/fld0_sfzn1_hd_hl16_psdMxp_vino/model_fold0.bin\n"
     ]
    }
   ],
   "source": [
    "# model.pthをopenvino形式に変換．\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import os\n",
    "\n",
    "# === 初期設定 ===\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()\n",
    "num_classes = len(species_ids)\n",
    "\n",
    "# 保存先: \"model_path_vino/\"\n",
    "# モデル元ディレクトリ（たとえば ../models/baseline_fold0_0404）\n",
    "model_dir = Path(cfg.model_path).resolve()  # 絶対パスに変換\n",
    "vino_dir = model_dir.parent / (model_dir.name + \"_vino\")  # ← 兄弟フォルダとして _vino を作成\n",
    "\n",
    "vino_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"📁 Saving ONNX & IR files to: {vino_dir}\")\n",
    "\n",
    "# === dataset-metadata.jsonの作成 ===\n",
    "japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "\n",
    "# dataset-metadata.jsonを保存\n",
    "dataset_metadata = {\n",
    "    \"title\": f\"bc25-models-{current_time}\",\n",
    "    \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"CC0-1.0\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "metadata_path = os.path.join(vino_dir, \"dataset-metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(dataset_metadata, f, indent=2)\n",
    "    \n",
    "\n",
    "# === モデル読み込み（全fold）===\n",
    "print(\"📦 Loading all fold models...\")\n",
    "models = load_models(cfg, num_classes)\n",
    "\n",
    "for fold, model in enumerate(models):\n",
    "    print(f\"\\n🔁 [Fold {fold}] Converting model...\")\n",
    "    model = model.to(\"cpu\")  \n",
    "    model.eval()\n",
    "\n",
    "    # Step 1: Export to ONNX\n",
    "    onnx_path = vino_dir / f\"model_fold{fold}.onnx\"\n",
    "    dummy_input = torch.randn(1, cfg.in_channels, *cfg.TARGET_SHAPE)  # ← ここだけ修正！\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "        opset_version=11\n",
    "    )\n",
    "    print(f\"✅ Exported ONNX: {onnx_path.name}\")\n",
    "\n",
    "    # Step 2: Convert to OpenVINO IR\n",
    "    result = subprocess.run(\n",
    "        [\"ovc\", str(onnx_path)],\n",
    "        cwd=str(vino_dir),  # ← これが重要！\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"❌ OpenVINO conversion failed for fold{fold}:\")\n",
    "        print(\"----- stderr -----\")\n",
    "        print(result.stderr)\n",
    "        print(\"----- stdout -----\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"✅ Converted to OpenVINO IR:\")\n",
    "        print(f\"   - {(vino_dir / f'model_fold{fold}.xml').resolve()}\")\n",
    "        print(f\"   - {(vino_dir / f'model_fold{fold}.bin').resolve()}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
