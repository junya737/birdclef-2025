{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cuda:0\n",
      "['sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFModelForTrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        # Ê¥ªÊÄßÂåñÈñ¢Êï∞‰∏çÂú®Ôºé\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "class BirdCLEFModelForTrain_Coat(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # CoaTÂ∞ÇÁî®: drop_path_rate„Çí0„Å´„Åô„Çã\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.0  # <= „Åì„Åì„Çí0.0„Å´ÔºÅ\n",
    "        )\n",
    "        \n",
    "        # CoaT„ÅØ reset_classifier „ÅåÂøÖË¶Å\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')  # <= global_pool='avg'\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BirdCLEFModelForTrain_Swin(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        backbone_out = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)  # 2D„Éó„Éº„É™„É≥„Ç∞„Å´Â§âÊõ¥ÔºÅÔºÅ\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if features.ndim == 4:\n",
    "            # CNNÁ≥ª (B, C, H, W)\n",
    "            features = self.pooling(features)\n",
    "            features = features.flatten(1)\n",
    "        elif features.ndim == 3:\n",
    "            # TransformerÁ≥ª (B, N, C)\n",
    "            features = features.mean(dim=1)\n",
    "        elif features.ndim == 2:\n",
    "            # „ÇÇ„ÅÜ (B, C) „Å´„Å™„Å£„Å¶„ÇãÔºà‰æã„Åà„Å∞ SwinTinyÔºâ\n",
    "            pass  # ‰Ωï„ÇÇÂä†Â∑•„Åó„Å™„ÅÑ\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n",
    "\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            self.train_csv = \"/kaggle/input/dataset-0419/melspec_20250419_1808/train.csv\"\n",
    "            self.spectrogram_npy = \"/kaggle/input/dataset-0419/melspec_20250419_1808/birdclef2025_melspec_5sec_256_256.npy\"\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # ÂÖ®model„ÅÆ‰øùÂ≠òÂÖà\n",
    "            self.model_path = self.models_dir # ÂêÑ„É¢„Éá„É´„ÅÆ‰øùÂ≠òÂÖàÔºéÂ≠¶ÁøíÊôÇ„Å´ÂãïÁöÑ„Å´Â§âÊõ¥Ôºé\n",
    "\n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            self.train_csv = '../data/processed/mel_sfzn3_hd_hl512///train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_sfzn3_hd_hl512///birdclef2025_melspec_5sec_256_256.npy'\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = \"efficientnet_b0\" # tf_efficientnetv2_b3   efficientnet_b0\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainerÂÜÖÈÉ®„ÅßÊ±∫„Åæ„Çã„ÅÆ„Åß„Åì„Åì„Åß„ÅØÊåáÂÆö„Åó„Å™„ÅÑÔºé\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0] # fold„ÅÆÈÅ∏Êäû\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # „É¨„Ç¢Á®Æ„ÅØÂÖ®ÈÉ®train fold„Å´„Åô„Çã\n",
    "            self.aug_prob = 0.5 # spec augment„ÅÆÁ¢∫Áéá\n",
    "            \n",
    "            # mixup„ÅÆË®≠ÂÆö\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha =  0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labels„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            \n",
    "            \n",
    "            ## ÁèæÁä∂‰Ωø„Å£„Å¶„Å™„ÅÑÔºé\n",
    "            # self.mixup_alpha_real = 0.5\n",
    "            # self.mixup_alpha_pseudo = 0.5\n",
    "            self.use_pseudo_mixup = False  # pseudo lable„Åßmixup„Åô„Çã„Åã„Å©„ÅÜ„Åã\n",
    "            # self.pseudo_mix_prob = 0.4  # mixup„Åßpseudo lable„Çí‰Ωø„ÅÜÁ¢∫Áéá\n",
    "            # self.pseudo_conf_threshold = 0.5\n",
    "\n",
    "            ###\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=True)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train„ÅÆÂá¶ÁêÜ„Çí„ÇØ„É©„Çπ„ÅßÂÆüË°åÔºé\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # label„Å®index„ÅÆÂØæÂøú\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"üì• Loading pseudo label CSV and melspecs...\")\n",
    "\n",
    "        # row_id „Çí index „Å´„Åó„Å¶Ë™≠„ÅøËæº„ÇÄÔºà‚Üê „Åì„Åì„Åå„Éù„Ç§„É≥„ÉàÔºÅÔºâ\n",
    "        self.pseudo_df = pd.read_csv(self.cfg.pseudo_label_csv, index_col=\"row_id\")\n",
    "\n",
    "        # ‰ø°È†ºÂ∫¶„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Ôºà‰æã: ÊúÄÂ§ßÂÄ§„Åå 0.5 Êú™Ê∫Ä„ÅÆË°å„ÇíÈô§„ÅèÔºâ\n",
    "        confidence_threshold = self.cfg.pseudo_conf_threshold\n",
    "        max_probs = self.pseudo_df.max(axis=1)\n",
    "        self.pseudo_df = self.pseudo_df[max_probs > confidence_threshold]\n",
    "        self.pseudo_df = self.pseudo_df.reset_index(drop=False)\n",
    "        print(f\"‚úÖ Filtered pseudo labels: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # melspec „ÅØ key „Åå row_id „ÅÆ dict „ÇíÊÉ≥ÂÆö\n",
    "        self.pseudo_melspecs = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True)\n",
    "        print(f\"‚úÖ Loaded pseudo mel-spectrograms: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                    df=train_df,\n",
    "                    cfg=self.cfg,\n",
    "                    spectrograms=self.spectrograms,\n",
    "                    mode=\"train\",\n",
    "                    label2idx=self.label2index,\n",
    "                    idx2label=self.index2label \n",
    "                    )\n",
    "            \n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # üëá ROC AUC „ÅØ„Éê„Ç§„Éä„É™„É©„Éô„É´„ÇíÂøÖË¶Å„Å®„Åô„Çã„ÅÆ„Åß„ÄÅsoft label„Çí2ÂÄ§Âåñ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „Éê„Ç§„Éä„É™ÂåñÔºàÈÄ£Á∂öÂÄ§„Åß„ÇÇint„Åß„ÇÇÂÆâÂÖ®Ôºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # „Ç®„É©„ÉºÂá∫„Åü„Å®„Åç„ÇÇÂÆâÂøÉ\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „É©„Éô„É´„Çí„Éê„Ç§„Éä„É™ÂåñÔºàsoft labelÂØæÂøúÔºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csv„ÅÆfold„Çí‰Ωø„ÅÜÔºé\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "            # coat„ÅåÊñáÂ≠óÂàó„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞\n",
    "            if 'coat' in self.cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Coat(self.cfg).to(self.cfg.device)\n",
    "            \n",
    "            elif 'swin' in self.cfg.model_name:\n",
    "                print(\"Using Swin model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Swin(self.cfg).to(self.cfg.device)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "                \n",
    "                \n",
    "                \n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # „Çπ„Ç≥„Ç¢ÂèñÂæó\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwise„Çπ„Ç≥„Ç¢„ÇíÈô§Â§ñ„Åó„Åü val_metrics „ÅÆ„É≠„Ç∞\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # „É≠„Ç∞Áî®„Çπ„Ç≥„Ç¢„ÅÆÊõ¥Êñ∞Ôºàclasswise„ÅØÈô§Â§ñÔºâ\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "           \n",
    "                \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É¨„Ç¢Á®Æ„ÅØfold=-1„Å´„Åô„ÇãÔºé\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # ÂêÑ„É©„Éô„É´„ÅÆÂá∫ÁèæÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„ÅÆ„Éá„Éº„Çø„Å†„Åë fold = -1 „Å´‰∏äÊõ∏„Åç\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_debug\n",
      "{0: '1139490', 1: '1192948', 2: '1194042', 3: '126247', 4: '1346504', 5: '134933', 6: '135045', 7: '1462711', 8: '1462737', 9: '1564122', 10: '21038', 11: '21116', 12: '21211', 13: '22333', 14: '22973', 15: '22976', 16: '24272', 17: '24292', 18: '24322', 19: '41663', 20: '41778', 21: '41970', 22: '42007', 23: '42087', 24: '42113', 25: '46010', 26: '47067', 27: '476537', 28: '476538', 29: '48124', 30: '50186', 31: '517119', 32: '523060', 33: '528041', 34: '52884', 35: '548639', 36: '555086', 37: '555142', 38: '566513', 39: '64862', 40: '65336', 41: '65344', 42: '65349', 43: '65373', 44: '65419', 45: '65448', 46: '65547', 47: '65962', 48: '66016', 49: '66531', 50: '66578', 51: '66893', 52: '67082', 53: '67252', 54: '714022', 55: '715170', 56: '787625', 57: '81930', 58: '868458', 59: '963335', 60: 'amakin1', 61: 'amekes', 62: 'ampkin1', 63: 'anhing', 64: 'babwar', 65: 'bafibi1', 66: 'banana', 67: 'baymac', 68: 'bbwduc', 69: 'bicwre1', 70: 'bkcdon', 71: 'bkmtou1', 72: 'blbgra1', 73: 'blbwre1', 74: 'blcant4', 75: 'blchaw1', 76: 'blcjay1', 77: 'blctit1', 78: 'blhpar1', 79: 'blkvul', 80: 'bobfly1', 81: 'bobher1', 82: 'brtpar1', 83: 'bubcur1', 84: 'bubwre1', 85: 'bucmot3', 86: 'bugtan', 87: 'butsal1', 88: 'cargra1', 89: 'cattyr', 90: 'chbant1', 91: 'chfmac1', 92: 'cinbec1', 93: 'cocher1', 94: 'cocwoo1', 95: 'colara1', 96: 'colcha1', 97: 'compau', 98: 'compot1', 99: 'cotfly1', 100: 'crbtan1', 101: 'crcwoo1', 102: 'crebob1', 103: 'cregua1', 104: 'creoro1', 105: 'eardov1', 106: 'fotfly', 107: 'gohman1', 108: 'grasal4', 109: 'grbhaw1', 110: 'greani1', 111: 'greegr', 112: 'greibi1', 113: 'grekis', 114: 'grepot1', 115: 'gretin1', 116: 'grnkin', 117: 'grysee1', 118: 'gybmar', 119: 'gycwor1', 120: 'labter1', 121: 'laufal1', 122: 'leagre', 123: 'linwoo1', 124: 'littin1', 125: 'mastit1', 126: 'neocor', 127: 'norscr1', 128: 'olipic1', 129: 'orcpar', 130: 'palhor2', 131: 'paltan1', 132: 'pavpig2', 133: 'piepuf1', 134: 'pirfly1', 135: 'piwtyr1', 136: 'plbwoo1', 137: 'plctan1', 138: 'plukit1', 139: 'purgal2', 140: 'ragmac1', 141: 'rebbla1', 142: 'recwoo1', 143: 'rinkin1', 144: 'roahaw', 145: 'rosspo1', 146: 'royfly1', 147: 'rtlhum', 148: 'rubsee1', 149: 'rufmot1', 150: 'rugdov', 151: 'rumfly1', 152: 'ruther1', 153: 'rutjac1', 154: 'rutpuf1', 155: 'saffin', 156: 'sahpar1', 157: 'savhaw1', 158: 'secfly1', 159: 'shghum1', 160: 'shtfly1', 161: 'smbani', 162: 'snoegr', 163: 'sobtyr1', 164: 'socfly1', 165: 'solsan', 166: 'soulap1', 167: 'spbwoo1', 168: 'speowl1', 169: 'spepar1', 170: 'srwswa1', 171: 'stbwoo2', 172: 'strcuc1', 173: 'strfly1', 174: 'strher', 175: 'strowl1', 176: 'tbsfin1', 177: 'thbeup1', 178: 'thlsch3', 179: 'trokin', 180: 'tropar', 181: 'trsowl', 182: 'turvul', 183: 'verfly', 184: 'watjac1', 185: 'wbwwre1', 186: 'whbant1', 187: 'whbman1', 188: 'whfant1', 189: 'whmtyr1', 190: 'whtdov', 191: 'whttro1', 192: 'whwswa1', 193: 'woosto', 194: 'y00678', 195: 'yebela1', 196: 'yebfly1', 197: 'yebsee1', 198: 'yecspi2', 199: 'yectyr1', 200: 'yehbla2', 201: 'yehcar1', 202: 'yelori1', 203: 'yeofly1', 204: 'yercac1', 205: 'ywcpar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_safezone1000_head_hoplength512//birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 28558 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 80 samples\n",
      "Validation set: 20 samples\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f17267162d4df889bcca44f4f19930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9981980e2ed4059b6a604525b37cff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2960, Train AUC: 0.4536, Train MAP: 0.0901\n",
      "Val Loss: 0.0283, Val AUC: 0.5135, Val MAP: 0.2365\n",
      "New best AUC: 0.5135 at epoch 1\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f8b6399a7748b692e95f332cb6ae4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1dd14045724855ab5a58af698e401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0268, Train AUC: 0.5516, Train MAP: 0.1352\n",
      "Val Loss: 0.0171, Val AUC: 0.6881, Val MAP: 0.3291\n",
      "New best AUC: 0.6881 at epoch 2\n",
      "\n",
      "Best AUC for fold 0: 0.6881\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.6881\n",
      "Mean AUC: 0.6881\n",
      "============================================================\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´„ÅØmodels_{current_time}„Å´‰øùÂ≠ò„Åï„Çå„ÇãÔºé\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    # taxonomy„ÅØ„É©„Éô„É´„Å®index„ÅÆÂØæÂøú„ÇíÂèñ„Çã„Åü„ÇÅ„Å´ÂøÖË¶ÅÔºé\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 7, val_auc: 0.957, train_auc: 0.971\n",
      "Missing log for fold 1: ../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02///log_fold1.csv\n",
      "Missing log for fold 2: ../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02///log_fold2.csv\n",
      "Missing log for fold 3: ../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02///log_fold3.csv\n",
      "Missing log for fold 4: ../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02///log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.957 | 0.971 | 0.574 | 0.577 | 0.013 | 0.013 | 7.00 | efficientnet_b0 | 32 | 7 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.035360</td>\n",
       "      <td>0.604228</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.796759</td>\n",
       "      <td>0.101499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.903867</td>\n",
       "      <td>0.297577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.901582</td>\n",
       "      <td>0.243883</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.938465</td>\n",
       "      <td>0.407597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.939867</td>\n",
       "      <td>0.336863</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.946567</td>\n",
       "      <td>0.492074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.959758</td>\n",
       "      <td>0.433008</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.952268</td>\n",
       "      <td>0.553037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.969517</td>\n",
       "      <td>0.542809</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>0.956976</td>\n",
       "      <td>0.566064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.971278</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.957283</td>\n",
       "      <td>0.574178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000475            1.84    0.035360   0.604228   0.015301   \n",
       "1      2  0.000406            1.83    0.022393   0.828661   0.127097   \n",
       "2      3  0.000306            1.84    0.018877   0.901582   0.243883   \n",
       "3      4  0.000195            1.83    0.016670   0.939867   0.336863   \n",
       "4      5  0.000095            1.64    0.015222   0.959758   0.433008   \n",
       "5      6  0.000026            1.99    0.013972   0.969517   0.542809   \n",
       "6      7  0.000001            1.82    0.013242   0.971278   0.577181   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.025625  0.796759  0.101499  \n",
       "1  0.019402  0.903867  0.297577  \n",
       "2  0.016396  0.938465  0.407597  \n",
       "3  0.014618  0.946567  0.492074  \n",
       "4  0.013733  0.952268  0.553037  \n",
       "5  0.013088  0.956976  0.566064  \n",
       "6  0.012820  0.957283  0.574178  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir = \"../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02///\"\n",
    "\n",
    "# „Çπ„Ç≥„Ç¢Ê†ºÁ¥çËæûÊõ∏Ôºàfold„Åî„Å®„ÅÆË®òÈå≤Ôºâ\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# ÂêÑfold„ÅÆ„Éô„Çπ„Éà„Çπ„Ç≥„Ç¢ÂèéÈõÜ\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# Âπ≥Âùá„Çπ„Ç≥„Ç¢„ÇíÊï¥ÂΩ¢Ôºà.3f„ÅßË°®Á§∫„ÄÅepoch„Å†„Åë.2fÔºâ\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv Ë™≠„ÅøËæº„Åø\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# configÊÉÖÂ†±„ÅÆÁµ±Âêà\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# MarkdownÂá∫Âäõ\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAHWCAYAAACIZjNQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBvElEQVR4nOzdd3yN5//H8dc5J0siw0yiQuzYm9pas1RRRVVrVMevX2q15Utbq4MOqqrlS4supYuqKoJSe6u9R6zYRBKyzvn9cTchEgRJ7uTk/Xw8rodz7nOf+3xOrrT17n1fn9vicDgciIiIiIiISIayml2AiIiIiIhITqDwJSIiIiIikgkUvkRERERERDKBwpeIiIiIiEgmUPgSERERERHJBApfIiIiIiIimUDhS0REREREJBMofImIiIiIiGQChS8REREREZFMoPAlIiKSw/Xo0YPcuXObXYaIiNNT+BIRkQwzY8YMLBYLmzZtMrsUU/Xo0QOLxZLq8PDwMLs8ERHJJC5mFyAiIpITuLu78+WXX6bYbrPZTKhGRETMoPAlIiKSCVxcXHj22WfNLkNEREykyw5FRMR0W7du5bHHHsPHx4fcuXPTpEkT1q1bl2yfuLg4Ro4cSalSpfDw8CBfvnzUr1+f0NDQpH3Cw8Pp2bMnhQsXxt3dncDAQNq2bcvRo0dv+9kff/wxFouFY8eOpXhtyJAhuLm5cenSJQAOHDhAhw4dCAgIwMPDg8KFC/P0009z5cqVdPk5JF6m+ffff/Pyyy+TL18+fHx86NatW1INN/viiy8oX7487u7uFCpUiN69e3P58uUU+61fv55WrVqRJ08evLy8qFSpEp9++mmK/U6ePEm7du3InTs3BQoU4PXXXychISFdvpuIiOjMl4iImGzXrl00aNAAHx8fBg0ahKurK//73/9o3LgxK1asoHbt2gCMGDGC0aNH88ILL1CrVi0iIiLYtGkTW7ZsoVmzZgB06NCBXbt28eqrrxIcHMzZs2cJDQ0lLCyM4ODgVD+/U6dODBo0iB9//JE33ngj2Ws//vgjzZs3J0+ePMTGxtKiRQtiYmJ49dVXCQgI4OTJk8yfP5/Lly/j6+t71+96/vz5FNvc3Nzw8fFJtq1Pnz74+fkxYsQI9u3bx6RJkzh27BjLly/HYrEk/TxGjhxJ06ZNeeWVV5L227hxI6tXr8bV1RWA0NBQHn/8cQIDA+nXrx8BAQHs2bOH+fPn069fv6TPTEhIoEWLFtSuXZuPP/6YJUuWMHbsWEqUKMErr7xy1+8mIiJp4BAREckg06dPdwCOjRs33nafdu3aOdzc3ByHDh1K2nbq1CmHt7e3o2HDhknbKleu7GjduvVtj3Pp0iUH4Pjoo4/uuc46deo4qlevnmzbhg0bHIDjm2++cTgcDsfWrVsdgOOnn3665+N3797dAaQ6WrRokbRf4s+revXqjtjY2KTtH374oQNw/Pbbbw6Hw+E4e/asw83NzdG8eXNHQkJC0n4TJ050AI5p06Y5HA6HIz4+3lGsWDFH0aJFHZcuXUpWk91uT1HfqFGjku1TtWrVFD8XERG5f7rsUERETJOQkMDixYtp164dxYsXT9oeGBjIM888w6pVq4iIiADAz8+PXbt2ceDAgVSPlStXLtzc3Fi+fHmql+jdSefOndm8eTOHDh1K2jZ79mzc3d1p27YtQNKZrUWLFhEdHX1Pxwfw8PAgNDQ0xRgzZkyKfV966aWkM1cAr7zyCi4uLixYsACAJUuWEBsbS//+/bFab/yn/MUXX8THx4c//vgDMC7nPHLkCP3798fPzy/ZZySeQbvZ//3f/yV73qBBAw4fPnzP31VERFKn8CUiIqY5d+4c0dHRlClTJsVrZcuWxW63c/z4cQBGjRrF5cuXKV26NBUrVuSNN95g+/btSfu7u7vzwQcf8Oeff+Lv70/Dhg358MMPCQ8Pv2sdHTt2xGq1Mnv2bAAcDgc//fRT0jo0gGLFijFw4EC+/PJL8ufPT4sWLfj888/TvN7LZrPRtGnTFKNKlSop9i1VqlSy57lz5yYwMDBp7Vri+rRbf25ubm4UL1486fXEMFmhQoW71ufh4UGBAgWSbcuTJ889B1kREbk9hS8REckWGjZsyKFDh5g2bRoVKlTgyy+/pFq1asnat/fv35/9+/czevRoPDw8ePvttylbtixbt26947ELFSpEgwYN+PHHHwFYt24dYWFhdO7cOdl+Y8eOZfv27QwdOpRr167Rt29fypcvz4kTJ9L/C2cytbwXEcl4Cl8iImKaAgUK4Onpyb59+1K8tnfvXqxWK0FBQUnb8ubNS8+ePfnhhx84fvw4lSpVYsSIEcneV6JECV577TUWL17Mzp07iY2NZezYsXetpXPnzvzzzz/s27eP2bNn4+npSZs2bVLsV7FiRd566y3+/vtvVq5cycmTJ5k8efK9f/k7uPXSysjISE6fPp3UNKRo0aIAKX5usbGxHDlyJOn1EiVKALBz5850rU9ERO6PwpeIiJjGZrPRvHlzfvvtt2Tt4M+cOcPMmTOpX79+0mV/Fy5cSPbe3LlzU7JkSWJiYgCIjo7m+vXryfYpUaIE3t7eSfvcSYcOHbDZbPzwww/89NNPPP7443h5eSW9HhERQXx8fLL3VKxYEavVmqbj34spU6YQFxeX9HzSpEnEx8fz2GOPAdC0aVPc3NyYMGECDocjab+vvvqKK1eu0Lp1awCqVatGsWLFGD9+fIoW9De/T0REModazYuISIabNm0aCxcuTLG9X79+vPvuu4SGhlK/fn3+85//4OLiwv/+9z9iYmL48MMPk/YtV64cjRs3pnr16uTNm5dNmzbx888/06dPHwD2799PkyZN6NSpE+XKlcPFxYU5c+Zw5swZnn766bvWWLBgQR555BHGjRvH1atXU1xyuGzZMvr06UPHjh0pXbo08fHxfPvtt9hsNjp06HDX48fHx/Pdd9+l+lr79u2TBb3Y2Nik77Jv3z6++OIL6tevzxNPPAEYZwyHDBnCyJEjadmyJU888UTSfjVr1ky6mbPVamXSpEm0adOGKlWq0LNnTwIDA9m7dy+7du1i0aJFd61bRETSkcndFkVExIkltk6/3Th+/LjD4XA4tmzZ4mjRooUjd+7cDk9PT8cjjzziWLNmTbJjvfvuu45atWo5/Pz8HLly5XKEhIQ43nvvvaSW7OfPn3f07t3bERIS4vDy8nL4+vo6ateu7fjxxx/TXO/UqVMdgMPb29tx7dq1ZK8dPnzY8fzzzztKlCjh8PDwcOTNm9fxyCOPOJYsWXLX496p1TzgOHLkSLKf14oVKxwvvfSSI0+ePI7cuXM7unbt6rhw4UKK406cONEREhLicHV1dfj7+zteeeWVFC3lHQ6HY9WqVY5mzZo5vL29HV5eXo5KlSo5Pvvss2T1eXl5pXjf8OHDHfqrgohI+rE4HLruQEREJCuYMWMGPXv2ZOPGjdSoUcPsckREJJ1pzZeIiIiIiEgmUPgSERERERHJBApfIiIiIiIimUBrvkRERERERDKBznyJiIiIiIhkAoUvERERERGRTKCbLN8nu93OqVOn8Pb2xmKxmF2OiIiIiIiYxOFwcPXqVQoVKoTVevvzWwpf9+nUqVMEBQWZXYaIiIiIiGQRx48fp3Dhwrd9XeHrPnl7ewPGD9jHx8fUWuLi4li8eDHNmzfH1dXV1FokfWhOnZPm1floTp2T5tX5aE6dU1aa14iICIKCgpIywu0ofN2nxEsNfXx8skT48vT0xMfHx/RfPEkfmlPnpHl1PppT56R5dT6aU+eUFef1bsuR1HBDREREREQkEyh8iYiIiIiIZAKFLxERERERkUygNV8iIiIi4hQcDgfx8fEkJCQk2x4XF4eLiwvXr19P8ZpkX5k5rzabDRcXlwe+xZTCl4iIiIhke7GxsZw+fZro6OgUrzkcDgICAjh+/Ljuz+pEMntePT09CQwMxM3N7b6PofAlIiIiItma3W7nyJEj2Gw2ChUqhJubW7K/jNvtdiIjI8mdO/cdb4Ar2UtmzavD4SA2NpZz585x5MgRSpUqdd+fp/AlIiIiItlabGwsdrudoKAgPD09U7xut9uJjY3Fw8ND4cuJZOa85sqVC1dXV44dO5b0mfdDv30iIiIi4hQUrCQjpcfvl35DRUREREREMoHCl4iIiIiISCZQ+BIRERERcSLBwcGMHz/e7DIkFQpfIiIiIiImsFgsdxwjRoy4r+Nu3LiRl1566YFqa9y4Mf3793+gY0hK6nboJK5d01SKiIiIZCenT59Oejx79myGDRvGvn37krblzp076bHD4SAhIQEXl7v/na9AgQLpW6ikG535yuZOnIAnn7QxbFhd7HazqxERERHJGhwOiIoyZzgcaasxICAgafj6+mKxWJKe7927F29vb/7880+qV6+Ou7s7q1at4tChQ7Rt2xZ/f39y585NzZo1WbJkSbLj3nrZocVi4csvv6R9+/Z4enpSqlQp5s2b90A/319++YXy5cvj7u5OcHAwY8eOTfb6F198QalSpfDw8MDf35+nnnoq6bWff/6ZihUrkitXLvLly0fTpk2Jiop6oHqyC50uyeZsNlixwsLVq3n47rt4evUyuyIRERER80VHw40TR1bAL9M+OzISvLzS51j//e9/+fjjjylevDh58uTh+PHjtGrVivfeew93d3e++eYb2rRpw759+yhSpMhtjzNy5Eg+/PBDPvroIz777DO6du3KsWPHyJs37z3XtHnzZjp16sSIESPo3Lkza9as4T//+Q/58uWjR48ebNq0ib59+/Ltt99St25dLl68yMqVKwHjbF+XLl348MMPad++PVevXmXlypU40ppYszmFr2wuMBCGDrUzZIiNt96y0bEj+PiYXZWIiIiIpIdRo0bRrFmzpOd58+alcuXKSc/feecd5syZw7x58+jTp89tj9OjRw+6dOkCwPvvv8+ECRPYsGEDLVu2vOeaxo0bR5MmTXj77bcBKF26NLt37+ajjz6iR48ehIWF4eXlxeOPP463tzdFixalatWqgBG+4uPjefLJJylatCgAFStWvOcasqsscdnh559/TnBwMB4eHtSuXZsNGzbccf+ffvqJkJAQPDw8qFixIgsWLEj2+ogRIwgJCcHLy4s8efLQtGlT1q9fn2yf4ODgFIsax4wZk+7fLTO8+qqdQoUiCQ+38O67ZlcjIiIiYj5PT+MMVGQkRETYOXHiMhER9qRtGTk8PdPve9SoUSPZ88jISF5//XXKli2Ln58fuXPnZs+ePYSFhd3xOJUqVUp67OXlhY+PD2fPnr2vmvbs2UO9evWSbatXrx4HDhwgISGBZs2aUbRoUYoXL85zzz3H999/T3R0NACVK1emSZMmVKxYkY4dOzJ16lQuXbp0X3VkR6aHr9mzZzNw4ECGDx/Oli1bqFy5Mi1atLjtL8OaNWvo0qULvXr1YuvWrbRr14527dqxc+fOpH1Kly7NxIkT2bFjB6tWrSI4OJjmzZtz7ty5ZMcaNWoUp0+fThqvvvpqhn7XjOLmBs8/b3z/8eNh/35z6xERERExm8ViXPpnxrBY0u97eN1y/eLrr7/OnDlzeP/991m5ciXbtm2jYsWKxMbG3vE4rq6ut/x8LNgzqGGAt7c3W7Zs4YcffiAwMJBhw4ZRuXJlLl++jM1mIzQ0lD///JNy5crx2WefUaZMGY4cOZIhtWQ1poevcePG8eKLL9KzZ0/KlSvH5MmT8fT0ZNq0aanu/+mnn9KyZUveeOMNypYtyzvvvEO1atWYOHFi0j7PPPMMTZs2pXjx4pQvX55x48YRERHB9u3bkx3L29s72ULHW3+5s5MaNc7w2GN24uJg4ECzqxERERGRjLB69Wp69OhB+/btqVixIgEBARw9ejRTayhbtiyrV69OUVfp0qWx2WwAuLi40LRpUz788EO2b9/O0aNHWbZsGWAEv3r16jFy5Ei2bt2Km5sbc+bMydTvYBZT13zFxsayefNmhgwZkrTNarXStGlT1q5dm+p71q5dy8Bb0kWLFi2YO3fubT9jypQp+Pr6Jrs+FmDMmDG88847FClShGeeeYYBAwbctn1nTEwMMTExSc8jIiIAiIuLIy4u7q7fNSMlfv7o0TEsWeLBH39YmDcvnsceyxkLF51R4pya/bsl6Uvz6nw0p85J85r9xMXF4XA4sNvtqZ7NSWzmkLhPVpRYV2p/3lxzyZIl+fXXX2ndujUWi4Vhw4Zht9tTfLdbn6f2s7ndzyvR2bNn2bJlS7JtgYGBDBgwgNq1azNq1Cg6derE2rVrmThxIhMnTsRutzN//nyOHDlCgwYNyJMnDwsWLMBut1OqVCnWrl3LsmXLaNasGQULFmT9+vWcO3eOMmXK3PPcZPa8Jv6c4+LikkJmorT++8LU8HX+/HkSEhLw9/dPtt3f35+9e/em+p7w8PBU9w8PD0+2bf78+Tz99NNER0cTGBhIaGgo+fPnT3q9b9++VKtWjbx587JmzRqGDBnC6dOnGTduXKqfO3r0aEaOHJli++LFi/FMzwt7H8DRo4tp3bocc+eW4pVXrvPpp8twdVUAy85CQ0PNLkEygObV+WhOnZPmNftwcXEhICCAyMjIO15+d/Xq1Uys6t5cv34dh8OR9D/4E9dIXb16Fav1xsVqI0eOpE+fPtSvX5+8efPSr18/Ll26RGxsbNJ77XY7169fT3oOcO3atWTPHQ5Hin1uFh8fzw8//MAPP/yQbPubb77J66+/zvTp0xk9ejTvvvsu/v7+DBkyhCeffJKIiAhcXV356aefGDFiBDExMRQvXpwvv/ySoKAg9u3bx19//cX48eO5evUqQUFBvPPOO9SrV++2tdxNZs1rbGws165d4++//yY+Pj7Za4nzdTcWh4l9HU+dOsVDDz3EmjVrqFOnTtL2QYMGsWLFihRNMgDc3Nz4+uuvk7q1gHEfgZEjR3LmzJmkbVFRUZw+fZrz588zdepUli1bxvr16ylYsGCqtUybNo2XX36ZyMhI3N3dU7ye2pmvoKAgzp8/j4/J7QXj4uIIDQ2lWbNmXLvmSvnyLpw5Y2HMmAQGDsya/3dH7uzmOb31Gm3JvjSvzkdz6pw0r9nP9evXOX78eFIDt1s5HA6uXr2Kt7c3lvRckCWmyux5vX79OkePHiUoKCjF71lERAT58+fnypUrd8wGpp75yp8/PzabLVloAjhz5gwBAQGpvicgICBN+3t5eVGyZElKlizJww8/TKlSpfjqq6+SXeJ4s9q1axMfH8/Ro0cpU6ZMitfd3d1TDWWurq5Z5l/Mrq6ueHq6MmYM9OwJ771no3t3G7f5UUo2kJV+vyT9aF6dj+bUOWles4+EhAQsFgtWqzXZWaJEiZekJe4jziGz59VqtWKxWFL9d0Na/11h6m+fm5sb1atXZ+nSpUnb7HY7S5cuTXYm7GZ16tRJtj8YlwXcbv+bj3vzmatbbdu2DavVetszY9lJt25QqxZcvQq3yZoiIiIiIpLJTL/J8sCBA+nevTs1atSgVq1ajB8/nqioKHr27AlAt27deOihhxg9ejQA/fr1o1GjRowdO5bWrVsza9YsNm3axJQpUwDjcsP33nuPJ554gsDAQM6fP8/nn3/OyZMn6dixI2A07Vi/fj2PPPII3t7erF27lgEDBvDss8+SJ08ec34Q6chqhQkT4OGHYcYMeOUVI4yJiIiIiIh5TA9fnTt35ty5cwwbNozw8HCqVKnCwoULk5pqhIWFJTuNWLduXWbOnMlbb73F0KFDKVWqFHPnzqVChQoA2Gw29u7dy9dff8358+fJly8fNWvWZOXKlZQvXx4wLiGcNWtW0iLAYsWKMWDAgBRdFLOz2rWhe3f4+mvo2xfWrDFCmYiIiIiImMP08AXQp08f+vTpk+pry5cvT7GtY8eOSWexbuXh4cGvv/56x8+rVq0a69atu+c6s5vRo+GXX2D9evj2WyOMiYiIiIiIOXQuxIkFBsLbbxuP//tfYw2YiIiIiIiYQ+HLyfXrB6VKQXg4vPuu2dWIiIiIiORcCl9Ozt0dPvnEePzJJ7B/v7n1iIiIiIjkVApfOUDr1vDYYxAXB07UU0REREREJFtR+MohPvkEXF3hjz/gzz/NrkZERERE0kvjxo3p379/0vPg4GDGjx9/x/dYLBbmzp37wJ+dXsfJKRS+cogyZYz1XwD9+0NsrKnliIiIiOR4bdq0oWXLlqm+tnLlSiwWC9u3b7/n427cuJGXXnrpQctLZsSIEVSpUiXF9tOnT/PYY4+l62fdasaMGfj5+WXoZ2QWha8c5O23wd/fWPc1YYLZ1YiIiIjkbL169SI0NJQTJ06keG369OnUqFGDSpUq3fNxCxQogKenZ3qUeFcBAQG4u7tnymc5A4WvHMTHx7j3F8CoUUYHRBERERGn5HBAfJQ5w+FIU4mPP/44BQoUYMaMGcm2R0ZG8tNPP9GrVy8uXLhAly5deOihh/D09KRixYr88MMPdzzurZcdHjhwgIYNG+Lh4UG5cuUIDQ1N8Z7BgwdTunRpPD09KV68OG+//TZxcXGAceZp5MiR/PPPP1gsFiwWS1LNt152uGPHDh599FFy5cpFvnz5eOmll4iMjEx6vUePHrRr146PP/6YwMBA8uXLR+/evZM+636EhYXRtm1bcufOjY+PD506deLMmTNJr//zzz888sgjeHt74+PjQ/Xq1dm0aRMAx44do02bNuTJkwcvLy/Kly/PggUL7ruWu8kSN1mWzNO9O0yaBBs3wtChMG2a2RWJiIiIZICEaPgxN2CcbfDLzM/uFAkuXnfdzcXFhW7dujFjxgzefPNNLBYLAD/99BMJCQl06dKFyMhIqlevzuDBg/Hx8eGPP/7gueeeo0SJEtSqVeuun2G323nyySfx9/dn/fr1XLlyJdn6sETe3t7MmDGDQoUKsWPHDl588UW8vb0ZNGgQnTt3ZufOnSxcuJAlS5YA4Ovrm+IYUVFRtGjRgjp16rBx40bOnj3LCy+8QJ8+fZIFzL/++ovAwED++usvDh48SOfOnalSpQovvvjiXb9Pat+vffv25M6dmxUrVhAfH0/v3r3p3Lkzy5cvB6Br165UrVqVSZMmYbPZ2LZtG66urgD07t2b2NhY/v77b7y8vNi9eze5c+e+5zrSSuErh7Fa4bPP4OGHYfp0+L//gzT8cysiIiIiGeD555/no48+YsWKFTRu3BgwLjns0KEDvr6++Pr68vrrryft/+qrr7Jo0SJ+/PHHNIWvJUuWsHfvXhYtWkShQoUAeP/991Os03rrrbeSHgcHB/P6668za9YsBg0aRK5cucidOzcuLi4EBATc9rNmzpzJ9evX+eabb/DyMsLnxIkTadOmDR988AH+/v4A5MmTh4kTJ2Kz2QgJCaF169YsXbr0vsLXihUr2LFjB0eOHCEoKAiAb775hvLly7Nx40Zq1qxJWFgYb7zxBiEhIQCUKlUq6f1hYWF06NCBihUrAlC8ePF7ruFeKHzlQLVrQ7du8M030LcvrFljhDIRERERp2HzNM5AYZwdiYiIwMfHB2tm/KXHlvb1ViEhIdStW5dp06bRuHFjDh48yMqVKxk1ahQACQkJvP/++/z444+cPHmS2NhYYmJi0ryma8+ePQQFBSUFL4A6deqk2G/27NlMmDCBQ4cOERkZSXx8PD4+Pmn+HomfVbly5aTgBVCvXj3sdjv79u1LCl/ly5fHZrMl7RMYGMiOHTvu6bMS7d+/n6CgoKTgBVCuXDn8/PzYs2cPNWvWZODAgbzwwgt8++23NG3alI4dO1KiRAkA+vbtyyuvvMLixYtp2rQpHTp0uK91dmmlv3LnUGPGQO7csH49fPed2dWIiIiIpDOLxbj0z4zx7+WDadWrVy9++eUXrl69yvTp0ylRogSNGjUC4KOPPuLTTz9l8ODB/PXXX2zbto0WLVoQm46tq9euXUvXrl1p1aoV8+fPZ+vWrbz55pvp+hk3S7zkL5HFYsFut2fIZ4HRqXHXrl20bt2aZcuWUa5cOebMmQPACy+8wOHDh3nuuefYsWMHNWrU4LPPPsuwWhS+cqjAQKP7IcDgwXD1qrn1iIiIiORUnTp1wmq1MnPmTL755huef/75pPVfq1evpm3btjz77LNUrlyZ4sWLs3///jQfu2zZshw/fpzTp08nbVu3bl2yfdasWUPRokV58803qVGjBqVKleLYsWPJ9nFzcyMhIeGun/XPP/8QFRWVtG316tVYrVbKlCmT5prvRenSpTl+/DjHjx9P2rZ7924uX75MuXLlku03YMAAFi9ezJNPPsn06dOTXgsKCuL//u//+PXXX3nttdeYOnVqhtQKCl85Wr9+ULKk0fXw3XfNrkZEREQkZ8qdOzedO3dmyJAhnD59mh49eiS9VqpUKUJDQ1mzZg179uzh5ZdfTtbJ726aNm1K6dKl6d69O//88w8rV67kzTffTLZPqVKlCAsLY9asWRw6dIgJEyYknRlKFBwczJEjR9i2bRvnz58nJiYmxWd17doVDw8Punfvzs6dO/nrr7949dVXee6555IuObxfCQkJbNu2LdnYs2cPjRs3pmLFinTt2pUtW7awYcMGunXrRqNGjahRowbXrl2jT58+LF++nGPHjrF69Wo2btxI2bJlAejfvz+LFi3iyJEjbNmyhb/++ivptYyg8JWDubtDYhfSTz6BAwdMLUdEREQkx+rVqxeXLl2iRYsWydZnvfXWW1SrVo0WLVrQuHFjAgICaNeuXZqPa7VamTNnDteuXaNWrVq88MILvPfee8n2eeKJJxgwYAB9+vShSpUqrFmzhrcTL5H6V4cOHWjZsiWPPPIIBQoUSLXdvaenJ4sWLeLixYvUrFmTp556iiZNmjBx4sR7+2GkIjIykqpVqyYbbdu2xWKxMGfOHPLkyUPDhg1p2rQpxYsXZ/bs2QDYbDYuXLhAt27dKF26NJ06deKxxx5j5MiRgBHqevfuTdmyZWnZsiWlS5fmiy++eOB6b8ficKTxRgSSTEREBL6+vly5cuWeFyOmt7i4OBYsWECrVq1SXEObFq1awZ9/wuOPw++/Z0CBcs8edE4la9K8Oh/NqXPSvGY/169f58iRIxQrVgwPD48Ur2d6ww3JFJk9r3f6PUtrNtBvn/DJJ+DiAvPnGyFMRERERETSn8KXUKaMsf4LoH9/yKDGNiIiIiIiOZrClwAwbBj4+8P+/cZNmEVEREREJH0pfAkAPj4werTxeORIowOiiIiIiIikH4UvSdK9O9Ssadzza+hQs6sRERERuTfqIycZKT1+vxS+JInVChMmGI+nT4eNG82tR0RERCQtErtSRkdHm1yJOLPE368H6YLqkl7FiHN4+GHo1g2++Qb69oXVq41QJiIiIpJV2Ww2/Pz8OHv2LGDcb8pisSS9brfbiY2N5fr162o170Qya14dDgfR0dGcPXsWPz8/bDbbfR9L4UtSGDMGfv0V1q2D774zwpiIiIhIVhYQEACQFMBu5nA4uHbtGrly5UoWyiR7y+x59fPzS/o9u18KX5JCYCC89Rb8978weDC0bw/e3mZXJSIiInJ7FouFwMBAChYsSFxcXLLX4uLi+Pvvv2nYsKFunO1EMnNeXV1dH+iMVyKFL0lV//7w5Zdw8CC8955xNkxEREQkq7PZbCn+kmyz2YiPj8fDw0Phy4lkx3nVRa+SKnd3+OQT4/G4cXDggLn1iIiIiIhkdwpfclutW0PLlhAXBwMHml2NiIiIiEj2pvAlt2WxwPjx4OIC8+fDn3+aXZGIiIiISPal8CV3VKYM9OtnPO7fH2JjTS1HRERERCTbUviSu3r7bShYEPbvh88+M7saEREREZHsSeFL7srX90a3w1Gj4MwZc+sREREREcmOFL4kTbp3h5o1ISIChg41uxoRERERkexH4UvSxGqFCROMx9OmwcaN5tYjIiIiIpLdKHxJmj38MDz3nPG4b1+w282tR0REREQkO1H4knsyZgzkzg3r1sH335tdjYiIiIhI9qHwJfekUCF46y3j8aBBcPWqufWIiIiIiGQXCl9yz/r3h5IlITwc3nvP7GpERERERLIHhS+5Z+7u8MknxuNPPoGDB82tR0REREQkO1D4kvvSujW0bAmxsTBwoNnViIiIiIhkfQpfcl8sFuOsl4sL/P47LFxodkUiIiIiIlmbwpfct5AQo+U8GOvAYmNNLUdEREREJEtT+JIHMmwYFCwI+/bBxIlmVyMiIiIiknUpfMkD8fWF0aONxyNHwpkz5tYjIiIiIpJVKXzJA+vRA2rUgIgIGDrU7GpERERERLImhS95YFYrTJhgPJ4+HTZuNLceEREREZGsSOFL0kWdOvDcc+BwGE047HazKxIRERERyVoUviTdjBkDXl6wbh18/73Z1YiIiIiIZC0KX5JuChWCt982Hg8eDFevmluPiIiIiEhWovAl6ap/fyhZEk6fhvffN7saEREREZGsQ+FL0pW7O4wbZzweNw4OHjS3HhERERGRrELhS9Ld449DixYQGwsDB5pdjYiIiIhI1qDwJenOYoHx48HFBX7/HRYuNLsiERERERHzKXxJhggJMVrOg7EOLDbW1HJEREREREyn8CUZZtgwKFgQ9u2DiRPNrkZERERExFwKX5JhfH1h9Gjj8ciRcOaMufWIiIiIiJhJ4UsyVI8eUKMGRETA0KFmVyMiIiIiYh6FL8lQVitMmGA8nj4dNm0ytx4REREREbMofEmGq1MHnnsOHA6jCYfDYXZFIiIiIiKZT+FLMsWYMeDlBWvXwvffm12NiIiIiEjmU/iSTFGoELz1lvF40CC4etXcekREREREMpvCl2SaAQOgRAk4fRref9/sakREREREMpfCl2Qad3f45BPj8bhxcPCgufWIiIiIiGQmhS/JVI8/Di1aQGwsDBxodjUiIiIiIplH4UsylcUC48eDiwv8/jssWmR2RSIiIiIimUPhSzJdSIjRch6gf3+IizO1HBERERGRTKHwJaYYNgwKFoS9e2HiRLOrERERERHJeFkifH3++ecEBwfj4eFB7dq12bBhwx33/+mnnwgJCcHDw4OKFSuyYMGCZK+PGDGCkJAQvLy8yJMnD02bNmX9+vXJ9rl48SJdu3bFx8cHPz8/evXqRWRkZLp/N0mdr++NjocjRsCZM6aWIyIiIiKS4UwPX7Nnz2bgwIEMHz6cLVu2ULlyZVq0aMHZs2dT3X/NmjV06dKFXr16sXXrVtq1a0e7du3YuXNn0j6lS5dm4sSJ7Nixg1WrVhEcHEzz5s05d+5c0j5du3Zl165dhIaGMn/+fP7++29eeumlDP++ckPPnlC9OkREwJtvml2NiIiIiEjGsjgcDoeZBdSuXZuaNWsy8d9rz+x2O0FBQbz66qv897//TbF/586diYqKYv78+UnbHn74YapUqcLkyZNT/YyIiAh8fX1ZsmQJTZo0Yc+ePZQrV46NGzdSo0YNABYuXEirVq04ceIEhQoVSnGMmJgYYmJikh0zKCiI8+fP4+Pj80A/gwcVFxdHaGgozZo1w9XV1dRa7tXatRYaNXLBYnGwZk0C1aub+uuYZWTnOZXb07w6H82pc9K8Oh/NqXPKSvMaERFB/vz5uXLlyh2zgUsm1pRCbGwsmzdvZsiQIUnbrFYrTZs2Ze3atam+Z+3atQy8pUd5ixYtmDt37m0/Y8qUKfj6+lK5cuWkY/j5+SUFL4CmTZtitVpZv3497du3T3Gc0aNHM3LkyBTbFy9ejKen512/a2YIDQ01u4T70qhRNVasCKJHjwjGjFmJxWJ2RVlHdp1TuTPNq/PRnDonzavz0Zw6p6wwr9HR0Wnaz9Twdf78eRISEvD390+23d/fn71796b6nvDw8FT3Dw8PT7Zt/vz5PP3000RHRxMYGEhoaCj58+dPOkbBggWT7e/i4kLevHlTHCfRkCFDkoW+xDNfzZs315mvB1SlCpQv72Dfvrxcvtyarl119iu7z6mkTvPqfDSnzknz6nw0p84pK81rREREmvYzNXxlpEceeYRt27Zx/vx5pk6dSqdOnVi/fn2K0JVW7u7uuLu7p9ju6upq+mQnykq13IuiReGtt2DIEBg61IUOHcDb2+yqsobsOqdyZ5pX56M5dU6aV+ejOXVOWWFe0/r5pjbcyJ8/PzabjTO3tLo7c+YMAQEBqb4nICAgTft7eXlRsmRJHn74Yb766itcXFz46quvko5xa0OP+Ph4Ll68eNvPlYw1YACUKAGnT9/ogigiIiIi4kxMDV9ubm5Ur16dpUuXJm2z2+0sXbqUOnXqpPqeOnXqJNsfjOs8b7f/zcdNbJhRp04dLl++zObNm5NeX7ZsGXa7ndq1a9/v15EH4O4O48YZj8eNg4MHza1HRERERCS9md5qfuDAgUydOpWvv/6aPXv28MorrxAVFUXPnj0B6NatW7KGHP369WPhwoWMHTuWvXv3MmLECDZt2kSfPn0AiIqKYujQoaxbt45jx46xefNmnn/+eU6ePEnHjh0BKFu2LC1btuTFF19kw4YNrF69mj59+vD000+n2ulQMkebNtCiBcTGwmuvmV2NiIiIiEj6Mn3NV+fOnTl37hzDhg0jPDycKlWqsHDhwqSmGmFhYVitNzJi3bp1mTlzJm+99RZDhw6lVKlSzJ07lwoVKgBgs9nYu3cvX3/9NefPnydfvnzUrFmTlStXUr58+aTjfP/99/Tp04cmTZpgtVrp0KEDEyZMyNwvL8lYLDB+PFSsCPPmwaJFRhgTEREREXEGpocvgD59+iSdubrV8uXLU2zr2LFj0lmsW3l4ePDrr7/e9TPz5s3LzJkz76lOyXghIfDqq/DJJ9C/P2zfDloXKyIiIiLOwPTLDkVuNWwYFCgAe/fCv/feFhERERHJ9hS+JMvx84PRo43HI0bALY0pRURERESyJYUvyZJ69oTq1SEiAoYONbsaEREREZEHp/AlWZLVCon9T6ZNg5vuCiAiIiIiki0pfEmWVbcuPPssOBzQt6/xp4iIiIhIdqXwJVnaBx+AlxesWQNqTikiIiIi2ZnCl2RphQrBm28ajwcNgshIc+sREREREblfCl+S5Q0YAMWLw6lT8P77ZlcjIiIiInJ/FL4ky/PwMG66DDB2LBw6ZG49IiIiIiL3Q+FLsoU2baB5c4iNhYEDza5GREREROTeKXxJtmCxwPjx4OIC8+bB4sVmVyQiIiIicm8UviTbKFsWXn3VeNyvH8TFmVuPiIiIiMi9UPiSbGXYMChQAPbuhYkTza5GRERERCTtFL4kW/Hzu9HxcMQIOHvWzGpERERERNJO4UuynZ49oXp1iIi4cQ8wEREREZGsTuFLsh2bDSZMMB5/9RVs3mxuPSIiIiIiaaHwJdlS3brQtSs4HNC3r/GniIiIiEhWpvAl2dYHH4CXF6xZAzNnml2NiIiIiMidKXxJtvXQQzfWfA0aBJGR5tYjIiIiInInCl+SrQ0YAMWLw6lTN7ogioiIiIhkRQpfkq15eMC4ccbjsWPh0CFz6xERERERuR2FL8n2nngCmjeH2Fh47TWzqxERERERSZ3Cl2R7FguMHw8uLvDbb7B4sdkViYiIiIikpPAlTqFsWejTx3jcvz/ExZlajoiIiIhICgpf4jSGD4cCBWDPHvj8c7OrERERERFJTuFLnIaf342OhyNGwNmzZlYjIiIiIpKcwpc4lZ49oVo1uHLlxj3ARERERESyAoUvcSo2G0yYYDz+6ivYvNncekREREREEil8idOpVw+6dgWHA/r2Nf4UERERETGbwpc4pQ8+AC8vWLMGZs40uxoREREREYUvcVIPPQRDhxqPBw2CyEhz6xERERERUfgSpzVwIBQvDqdOwejRZlcjIiIiIjmdwpc4LQ8PGDfOePzxx3DokLn1iIiIiEjOpvAlTu2JJ6BZM4iNhddeM7saEREREcnJFL7EqVksMH680YL+t98gNNTsikREREQkp1L4EqdXrhy8+qrxuF8/iIsztx4RERERyZkUviRHGD4cChSAPXvg88/NrkZEREREciKFL8kR/PzgvfeMxyNGwLlzZlYjIiIiIjmRwpfkGM8/D9WqwZUr8OabZlcjIiIiIjmNwpfkGDYbTJhgPP7yS9i82dx6RERERCRnUfiSHKVePXjmGXA4jOYbDofZFYmIiIhITqHwJTnOhx+ClxesXg0//GB2NSIiIiKSUyh8SY7z0EMwdKjxeNAgiIw0tx4RERERyRkUviRHGjgQiheHkydh9GizqxERERGRnEDhS3IkDw8YO9Z4PHYsHD5sbj0iIiIi4vwUviTHatsWmjWDmBh47TWzqxERERERZ6fwJTmWxQLjxxst6OfOhdBQsysSEREREWem8CU5Wrly0KeP8bhfP4iLM7ceEREREXFeCl+S440YAfnzw5498MUXZlcjIiIiIs5K4UtyPD8/eP994/Hw4XDunKnliIiIiIiTUvgSAZ5/HqpWhStX4M03za5GRERERJyRwpcIRtONCROMx19+CVu2mFuPiIiIiDgfhS+Rf9WvD888Aw4H9O1r/CkiIiIikl4UvkRu8sEH4OkJq1fDDz+YXY2IiIiIOBOFL5GbFC4MQ4cajwcNgqgoc+sREREREeeh8CVyi9deg2LF4ORJGD3a7GpERERExFkofIncwsMDxo0zHn/8MRw+bG49IiIiIuIcFL5EUtG2LTRtCjExxpkwEREREZEHpfDlDBx2sytwOhYLfPqp0YJ+7lxYssTsikREREQku1P4yu4cDmyb/o/yMdPAHm92NU6lXDno08d43K8fxMWZW4+IiIiIZG8KX9ndhfVYj86gZPw8bKvaQexlsytyKiNGQP78sHs3fPGF2dWIiIiISHam8JXd5X+Y+IdnEo8b1jOLYfHDELHf7Kqchp8fvPee8Xj4cDh3ztRyRERERCQbU/hyAo6gp1jlMRpHrsIQsQ8W1YLTi80uy2n06gVVq8KVK/DWW2ZXIyIiIiLZlcKXk7hiK0F807WQvw7EXYHlj8He8eBwmF1atmezwYQJxuOpU2HLFnPrEREREZHsSeHLmXj4Q5O/oHgPowPilgGw/gVIiDG7smyvfn3o0sXIsn37KtOKiIiIyL1T+HI2NneoPQ2qjQOLFQ5Pg2VN4NoZsyvL9j78EDw9YfVqmDXL7GpEREREJLvJEuHr888/Jzg4GA8PD2rXrs2GDRvuuP9PP/1ESEgIHh4eVKxYkQULFiS9FhcXx+DBg6lYsSJeXl4UKlSIbt26cerUqWTHCA4OxmKxJBtjxozJkO+X6SwWCBkAjRaAqy+cWw2LasKlbWZXlq0VLgxDhxqP33gDoqLMrUdEREREshfTw9fs2bMZOHAgw4cPZ8uWLVSuXJkWLVpw9uzZVPdfs2YNXbp0oVevXmzdupV27drRrl07du7cCUB0dDRbtmzh7bffZsuWLfz666/s27ePJ554IsWxRo0axenTp5PGq6++mqHfNdMVagEt1oN3aYg+DovrQdgvZleVrb32GhQrBidPwujRZlcjIiIiItmJ6eFr3LhxvPjii/Ts2ZNy5coxefJkPD09mTZtWqr7f/rpp7Rs2ZI33niDsmXL8s4771CtWjUmTpwIgK+vL6GhoXTq1IkyZcrw8MMPM3HiRDZv3kxYWFiyY3l7exMQEJA0vLy8Mvz7ZjqfMtBiHQQ0h4RoWPUUbB9hrAmTe+bhAePGGY8//hgOHza3HhERERHJPlzM/PDY2Fg2b97MkCFDkrZZrVaaNm3K2rVrU33P2rVrGThwYLJtLVq0YO7cubf9nCtXrmCxWPDz80u2fcyYMbzzzjsUKVKEZ555hgEDBuDikvqPJCYmhpiYG40rIiIiAOMyx7i4uDt9zQyX+Pm3rcOSG+rNxbp9CLYDn8LOkdgvbSeh1jRwccLAmcFatYImTWwsXWpl4EA7P/2UkO6fcdc5lWxJ8+p8NKfOSfPqfDSnzikrzWtaazA1fJ0/f56EhAT8/f2Tbff392fv3r2pvic8PDzV/cPDw1Pd//r16wwePJguXbrg4+OTtL1v375Uq1aNvHnzsmbNGoYMGcLp06cZl3ha4xajR49m5MiRKbYvXrwYT0/PO37PzBIaGnqXPR6hiFsClWMnYz05h6u/bWW9+1CuWQtmSn3OpF07b/76qzG//WZl9Oh1VK6cMXdfvvucSnakeXU+mlPnpHl1PppT55QV5jU6OjpN+5kavjJaXFwcnTp1wuFwMGnSpGSv3Xz2rFKlSri5ufHyyy8zevRo3N3dUxxryJAhyd4TERFBUFAQzZs3TxbqzBAXF0doaCjNmjXD1dX1Lnu3wn7+KSxrOuEbc5Rm9jdJePhHHPnrZUqtzmTfPgcTJ8KsWXV4/fV47vqjvwf3NqeSXWhenY/m1DlpXp2P5tQ5ZaV5Tbwq7m5MDV/58+fHZrNx5kzyNuhnzpwhICAg1fcEBASkaf/E4HXs2DGWLVt214BUu3Zt4uPjOXr0KGXKlEnxuru7e6qhzNXV1fTJTpTmWgIbQcuN8HdbLJe24bKiOdScBCV6ZXyRTmTUKKPl/J49Fr780pW+fdP/M7LS75ekH82r89GcOifNq/PRnDqnrDCvaf38+2q4cfz4cU6cOJH0fMOGDfTv358pU6bc03Hc3NyoXr06S5cuTdpmt9tZunQpderUSfU9derUSbY/GKcab94/MXgdOHCAJUuWkC9fvrvWsm3bNqxWKwUL5pBL8LyKQLNVEPQU2OOMmzFv7g/2eLMryzby5IH33jMeDxsG5zLmykMRERERcRL3Fb6eeeYZ/vrrL8BYg9WsWTM2bNjAm2++yahRo+7pWAMHDmTq1Kl8/fXX7Nmzh1deeYWoqCh69uwJQLdu3ZI15OjXrx8LFy5k7Nix7N27lxEjRrBp0yb69OkDGMHrqaeeYtOmTXz//fckJCQQHh5OeHg4sbGxgNG0Y/z48fzzzz8cPnyY77//ngEDBvDss8+SJ0+e+/mRZE8uXlB/NlQcYTzf9yksbwWxl0wtKzvp1QuqVoUrV+Ctt8yuRkRERESysvsKXzt37qRWrVoA/Pjjj1SoUIE1a9bw/fffM2PGjHs6VufOnfn4448ZNmwYVapUYdu2bSxcuDCpqUZYWBinT59O2r9u3brMnDmTKVOmULlyZX7++Wfmzp1LhQoVADh58iTz5s3jxIkTVKlShcDAwKSxZs0awLiEcNasWTRq1Ijy5cvz3nvvMWDAgHs+c+cULFaoOBzq/ww2TwgPhUW14UrqDU8kOZsNJkwwHk+dClu3mluPiIiIiGRd97XmKy4uLmn905IlS5JuYBwSEpIsKKVVnz59ks5c3Wr58uUptnXs2JGOHTumun9wcDAOh+OOn1etWjXWrVt3z3U6tSIdwLsErGgLVw/A4oeh3iwo1NLsyrK8+vWhSxf44Qfo2xf+/hssFrOrEhEREZGs5r7OfJUvX57JkyezcuVKQkNDadnS+Av6qVOn0rS+SrKoPFWMRhwF6kHcFVjRGvaMg7uEWYEPPwRPT1i1ymjCISIiIiJyq/sKXx988AH/+9//aNy4MV26dKFy5coAzJs3L+lyRMmmPArCo0uNzocOO2x9DdY/Dwkxd39vDla4MCQuTXzjDYiKMrceEREREcl67uuyw8aNG3P+/HkiIiKSNah46aWXsswNh+UB2Nyh1lTwqwRbBsDhGRCxDxr8CrlSvwWAwOuvw7RpcOQIjBkD77xjdkUiIiIikpXc15mva9euERMTkxS8jh07xvjx49m3b1/OadXu7CwWKNMXGi8EVz84vxYW1YSLW8yuLMvy8ICxY43HH30Ehw+bW4+IiIiIZC33Fb7atm3LN998A8Dly5epXbs2Y8eOpV27dkyaNCldCxSTBTaDFuvBpwxEn4DQ+nDsR7OryrLatYMmTSAmxjgTJiIiIiKS6L7C15YtW2jQoAEAP//8M/7+/hw7doxvvvmGCYl9t8V5+JSG5ushsCUkXIPVnWH7MGNNmCRjscCnnxot6OfMgSVLzK5IRERERLKK+wpf0dHReHt7A7B48WKefPJJrFYrDz/8MMeOHUvXAiWLcPOFRvMh5DXj+c53YOVTEBdpbl1ZUPny0Lu38bhfP4iLM7ceEREREcka7it8lSxZkrlz53L8+HEWLVpE8+bNATh79iw+Pj7pWqBkIVYbVPsYHp4BVjc4MQdC60LkUbMry3JGjIB8+WD3btCVuCIiIiIC9xm+hg0bxuuvv05wcDC1atWiTp06gHEWrGrVqulaoGRBxbtDk+Xg4Q+XdxiNOM7+bXZVWUqePPD++8bj4cPh3Dlz6xERERER891X+HrqqacICwtj06ZNLFq0KGl7kyZN+OSTT9KtOMnCCtSBFhshTzWIOQ9Lm8DBqWZXlaX06gVVq8Lly/D222ZXIyIiIiJmu6/wBRAQEEDVqlU5deoUJ06cAKBWrVqEhISkW3GSxXkFQbOVUKQTOOJhw0uw6VWwx5tdWZZgsxnNNwCmTIGtW82tR0RERETMdV/hy263M2rUKHx9fSlatChFixbFz8+Pd955B7tdHfByFBdPqDcLKv17R+H9E+GvlhBz0dy6sogGDeDpp8HhgL59jT9FREREJGe6r/D15ptvMnHiRMaMGcPWrVvZunUr77//Pp999hlv6/qqnMdigQpvQYNfwcULziyFRbXhyh6zK8sSPvwQPD1h1SqYPdvsakRERETELPcVvr7++mu+/PJLXnnlFSpVqkSlSpX4z3/+w9SpU5kxY0Y6lyjZRlB7aLYGvIpC5EEjgJ1cYHZVpgsKgiFDjMevvw5RUebWIyIiIiLmuK/wdfHixVTXdoWEhHDxoi43y9HyVDIacRRsCPFXYcXjsPujHH+93WuvQXAwnDwJY8aYXY2IiIiImOG+wlflypWZOHFiiu0TJ06kUqVKD1yUZHMeBeCRUCj5EuCAbYNgbXdIuG52ZabJlQvGjTMef/QRHDlibj0iIiIikvlc7udNH374Ia1bt2bJkiVJ9/hau3Ytx48fZ8ECXWYmgM0Nak4G34qwpT8c/Rau7oeGcyBXoNnVmaJdO2jSBJYuNS4//OUXsysSERERkcx0X2e+GjVqxP79+2nfvj2XL1/m8uXLPPnkk+zatYtvv/02vWuU7MpigTJ94JFF4JYHLqyHhTXhwiazKzOFxWK0nrfZ4NdfjRAmIiIiIjnHfd/nq1ChQrz33nv88ssv/PLLL7z77rtcunSJr776Kj3rE2cQ0ARabACfsnDtJCxpAEdnmV2VKcqXh//8x3jcrx/E65ZoIiIiIjnGfYcvkXviXRKar4VCrYy1X2u6wD9vgiPn3Rdu5EjIlw927YJJk8yuRkREREQyi8KXZB43X2g4D8oOMp7veh/+bg9xV82tK5PlyQPvvWc8HjYMzp0ztx4RERERyRwKX5K5rDao+gHU+Qas7nByHiyuC5E5q/3fCy9AlSpw+TLovuQiIiIiOcM9dTt88skn7/j65cuXH6QWyUmKPQfepeHvdnBlJyyqCfV/Bv/GZleWKWw2mDABGjaEKVPg5ZehalWzqxIRERGRjHRPZ758fX3vOIoWLUq3bt0yqlZxNvlrQ8uNkLc6xFyAZc3gwGSzq8o0DRrA008b95/u2zfH34daRERExOnd05mv6dOnZ1QdklN5FoamK2H983BsFmx8BS7vgOrjwepqdnUZ7sMP4bffYNUqmD3bCGMiIiIi4py05kvM55IL6s6Eyu8DFjjwBfzVwjgb5uSCgmDoUOPxG29AVJS59YiIiIhIxlH4kqzBYoHyQ6DhXHDJDWf+gkW14PIusyvLcK+9BsHBcOIEfPCB2dWIiIiISEZR+JKspfATxv3AvIpB5GFYXAdOzje7qgyVKxeMHWs8/vBDOJKzGj+KiIiI5BgKX5L1+FWAFhugYGOIvwornoDdHzh1R4r27eHRRyEmBl5/3exqRERERCQjKHxJ1uSRHx5dDCX/D3DAtv/C2ucg/prZlWUIiwU+/dRoQf/rr7BsmcXskkREREQknSl8SdZldYVak6DmF2CxwdHvYUkjiD5ldmUZokIF+M9/jMcDB9pISFAAExEREXEmCl+S9ZV6BR4NBbe8cHGjcUPmCxvNripDjBwJ+fLB7t0W/vwz2OxyRERERCQdKXxJ9uD/iLEOzLccXDsFoQ3gyPdmV5Xu8uSB994zHv/wQwjHjplbj4iIiIikH4UvyT68SxidEB9qA/YYWPussRbMnmB2ZenqhRegcmUHUVFulCvnwvPPw549ZlclIiIiIg9K4UuyF1cfaDAHyv3XeL77A/i7HcRFmFpWerLZ4Lvv4ilX7jxxcRamT4dy5aBdO1i71uzqREREROR+KXxJ9mO1QZXRUOc7sLrDqfnG/cCuHjK7snRTpgy8//5q/v47nrZtjW2//QZ160LDhrBggVN33hcRERFxSgpfkn0V6wrNVkKuQLiyGxbVgvBlZleVrh5+2MHcubB7N/TsCa6usHIltG4NlSvDd99BXJzZVYqIiIhIWih8SfaWrya02AR5a0LsRfirOez/wuyq0l3ZsjBtGhw+DK+9Brlzw44d8NxzULIkTJgAUVFmVykiIiIid6LwJdmfZyFougKCu4IjATb1hg2vgN35TgkVLgwffwxhYUZXxIIFjcf9+kHRojBiBJw/b3aVIiIiIpIahS9xDi65oM63UOUDwAIHJ8OyZnDdOZNInjwwdCgcPQpffAHFi8OFC8Z9wooUgb59UZt6ERERkSxG4Uuch8UC5QZBo3ng4g1nVxjrwC7vNLuyDJMrF7zyCuzfD7NnQ7VqcO0afPYZlCgBzz4L27ebXaWIiIiIgMKXOKOHHjfuB5a7OEQdMTohnvjN7KoylM0GnTrBpk0QGgpNmkBCAnz/vdGYo1UrWLFCHRJFREREzKTwJc7Jrzy02AD+j0B8JPzdHna97/Tpw2KBpk1hyRIjiHXsCFYr/PknNG4MderAnDlgt5tdqYiIiEjOo/Alzss9HzyyCEr1Bhzwz5uwpivEXzO7skxRvTr8+CPs2wcvvwzu7rB+PTz5pHHT5q++gpgYs6sUERERyTkUvsS5WV2h5kSoORksLnDsB1jSAKJPml1ZpilZEiZPNppzDBkCvr5GIHvhBaNRx0cfQUSE2VWKiIiIOD+FL8kZSr0Mjy4xzoZd3AwLa8D59WZXlakCAuD9943W9B99BIUKwalTMGiQ0SFxyBAIDze7ShERERHnpfAlOYd/I2ixEXwrwPVwWNIIjnxrdlWZzscHXn/duGHzV19BmTJw5QqMGQPBwcYligcPml2liIiIiPNR+JKcJXcxaL4GCrcFewys7QZbB4E9wezKMp27Ozz/POzebTThePhhYw3YlClQurTRrGPTJrOrFBEREXEeCl+S87h6Q4NfofybxvM9H8HfT0DsFXPrMonVCu3awZo1Rjv6Vq2MppA//ww1axpt6xcvdvpGkSIiIiIZTuFLciaLFSq/C3V/AJsHnFpg3A/sas693s5igYYN4Y8/jBszP/uscf+wZcugRQuje+Ls2RAfb3alIiIiItmTwpfkbMFPQ9OVkOshiNgDi2pB+FKzqzJdxYrw7bdw6BD07QuenrB1Kzz9tLFG7Isv4FrO6NgvIiIikm4UvkTy1YCWGyFfbYi9BH+1gH2f6To7oGhR+PRTo0PiiBGQL5/RqKN3b+O1996DS5fMrlJEREQke1D4EgHIFQhNl0OxbuBIgM19YcPLkBBrdmVZQr58MHw4HDsGEyYYwevcOXjrLaNN/WuvwYkTZlcpIiIikrUpfIkksnnAwzOg6keABQ5NhWVN4fo5syvLMry84NVX4cAB+O474/LEyEgYN864YXPPnrBnj9lVioiIiGRNCl8iN7NYoOzr0Gg+uPrAuZWwqCZc2m52ZVmKqyt07Qr//AMLFkCjRhAXBzNmQLly0Lat0T1RRERERG5Q+BJJzUOtoPk6yF0Soo5BaF04PsfsqrIciwUeewyWL4d166B9e2PbvHlQrx40aADz54PdbnalIiIiIuZT+BK5Hd+y0GI9BDSF+ChY+STsfFeNOG6jdm349Vfjps3PP2+cHVu1Ctq0gUqV4JtvjLNjIiIiIjmVwpfInbjnhcZ/QulXjefb34bVT0N8tLl1ZWEhIfDVV3D0KLzxBnh7w65d0L07lCgB48cb68REREREchqFL5G7sbpAjQlQawpYXSHsRwhtAFHHza4sSytUCD780GhTP3o0+PvD8eMwYIDRIXHYMKNjooiIiEhOofAlklYlX4RHl4J7fri0xWjEcW6t2VVleX5+8N//GmfCJk+GkiWNe4O9847Rsr5PHzhyxOwqRURERDKewpfIvSjYAFpsBL9KcP0MLG0Mh2eYXVW24OEBL78Me/fCjz9C9epw7Rp8/jmUKgXPPGN0TxQRERFxVgpfIvcqdzA0Ww2F24M9Ftb1hC2vgT3B7MqyBZsNOnaEjRthyRJo1gwSEuCHH6BKFWjZEv76S31NRERExPkofIncD9fc0OBnqDDMeL53HKx4HGIvm1pWdmKxQJMmsHgxbN4MnTuD1QqLFsGjj97onpigTCsiIiJOQuFL5H5ZrFBpJNT/EWy54PRCWPwwROw3u7Jsp1o1mDUL9u+HV14xLlHcuBE6dDBu2vzllxATY3aVIiIiIg9G4UvkQRXpCM1WgWdhiNgHi2rD6cVmV5UtlSgBX3wBx47Bm28azTr274cXX4TgYPjgA7hyxewqRURERO6PwpdIeshbDVpsgvx1IO4yLH8M9n6qhUv3qWBBePddo0392LHw0EMQHm50TSxSxPjz9GmzqxQRERG5NwpfIukllz80+QuK9wCHHbb0hw0vQoKul7tf3t4wcCAcPgzTp0PZshARYZwBCw6Gl14yzoyJiIiIZAdZInx9/vnnBAcH4+HhQe3atdmwYcMd9//pp58ICQnBw8ODihUrsmDBgqTX4uLiGDx4MBUrVsTLy4tChQrRrVs3Tp06lewYFy9epGvXrvj4+ODn50evXr2IjIzMkO8nOYjNHWpPg2rjjDVhh76CZU3g+lmzK8vW3NygRw/YuRN++w3q1oXYWJg6FUJC4KmnjDViIiIiIlmZ6eFr9uzZDBw4kOHDh7NlyxYqV65MixYtOHs29b+srlmzhi5dutCrVy+2bt1Ku3btaNeuHTt37gQgOjqaLVu28Pbbb7NlyxZ+/fVX9u3bxxNPPJHsOF27dmXXrl2EhoYyf/58/v77b1566aUM/76SA1gsEDIAGv0Brr5wbjUsrAmXtpldWbZntcITT8Dq1bByJTz+uHFl5y+/QK1aRpfERYt0taeIiIhkTaaHr3HjxvHiiy/Ss2dPypUrx+TJk/H09GTatGmp7v/pp5/SsmVL3njjDcqWLcs777xDtWrVmDhxIgC+vr6EhobSqVMnypQpw8MPP8zEiRPZvHkzYWFhAOzZs4eFCxfy5ZdfUrt2berXr89nn33GrFmzUpwhE7lvhVpCi/XgXQqiw2BxPQj7xeyqnEb9+vD777BjB3TrBi4uxv3BWrY0uif+8APEx5tdpYiIiMgNLmZ+eGxsLJs3b2bIkCFJ26xWK02bNmXt2rWpvmft2rUMHDgw2bYWLVowd+7c237OlStXsFgs+Pn5JR3Dz8+PGjVqJO3TtGlTrFYr69evp3379imOERMTQ8xNva4jIiIA4zLHuLi4u37XjJT4+WbXIanIVRweXYVtXVesZ5bAqqdIKPc29nJvGpcl3obmNO3KlDFa0Q8bBhMmWPnqKyvbtll45hl4800H/fvb6d7djqen2ZVqXp2R5tQ5aV6dj+bUOWWleU1rDaaGr/Pnz5OQkIC/v3+y7f7+/uzduzfV94SHh6e6f3h4eKr7X79+ncGDB9OlSxd8fHySjlGwYMFk+7m4uJA3b97bHmf06NGMHDkyxfbFixfjmRX+VgeEhoaaXYLchsXxCuVdclEi/ndsu98hfN9Strr3JcHiccf3aU7vzaOPQo0arvz5ZzH++KM4R46406+fjbffjqd168O0anUEb2/z/wWteXU+mlPnpHl1PppT55QV5jU6OjpN+5kavjJaXFwcnTp1wuFwMGnSpAc61pAhQ5KdcYuIiCAoKIjmzZsnhTqzxMXFERoaSrNmzXB1dTW1FrmTNsQfmYFtc28eSlhDIbco4uv9Ap5FUuypOX0wTz8N0dHw9dcJfPKJlaNH3fnhh7LMmxdCr152+vWzExSU+XVpXp2P5tQ5aV6dj+bUOWWleU28Ku5uTA1f+fPnx2azcebMmWTbz5w5Q0BAQKrvCQgISNP+icHr2LFjLFu2LFlACggISNHQIz4+nosXL972c93d3XF3d0+x3dXV1fTJTpSVapHbKP0i+JWFlU9iufwPrkvqQMM5UKBeqrtrTu+fry/07Qv/+Q/89JPRnv6ffyxMmGDjiy9sPPMMDBoE5ctnfm2aV+ejOXVOmlfnozl1TllhXtP6+aY23HBzc6N69eosXbo0aZvdbmfp0qXUqVMn1ffUqVMn2f5gnGq8ef/E4HXgwAGWLFlCvnz5Uhzj8uXLbN68OWnbsmXLsNvt1K5dOz2+msjtFawPLTeBX2WIOQdLH4FDqTeYkQfn4gJdusDWrfDnn/DII0Yjjm++gQoVoE0bWLXK7CpFREQkJzC92+HAgQOZOnUqX3/9NXv27OGVV14hKiqKnj17AtCtW7dkDTn69evHwoULGTt2LHv37mXEiBFs2rSJPn36AEbweuqpp9i0aRPff/89CQkJhIeHEx4eTmxsLABly5alZcuWvPjii2zYsIHVq1fTp08fnn76aQoVKpT5PwTJebyKQPPVENQB7HGwvhdsHgB2tefLKBaL0Qlx2TJYvx6efNLYNn8+NGgA9erBvHlgt5tdqYiIiDgr08NX586d+fjjjxk2bBhVqlRh27ZtLFy4MKmpRlhYGKdPn07av27dusycOZMpU6ZQuXJlfv75Z+bOnUuFChUAOHnyJPPmzePEiRNUqVKFwMDApLFmzZqk43z//feEhITQpEkTWrVqRf369ZkyZUrmfnnJ2Vy8oP6PUHGE8XzfeFjeGmIvmVlVjlCrlnFvsD174IUXjJs4r1kDbdtCxYrw9dfGTZxFRERE0lOWaLjRp0+fpDNXt1q+fHmKbR07dqRjx46p7h8cHIwjDXdYzZs3LzNnzrynOkXSncUKFYeDbwVY2w3CF8Oih6Ge7geWGcqUgalTYdQoGD8eJk+G3buhRw946y0YOBBefBFy5za7UhEREXEGpp/5EhGgSAfjMkTPInB1Py5L61MgfqvZVeUYgYFGQ46wMBgzBgIC4MQJI3wVKQJvvw239OgRERERuWcKXyJZRZ4q0HIjFKiHJe4KdWLewbamM5xeDA4tRMoMvr4weDAcOQJTpkCpUnDpErz7LhQtCr17w+HDZlcpIiIi2ZXCl0hW4lEQHl2KvdjzWLBjPTkH/moB80rAzvcg+pTZFeYIHh7G5YZ79sDPP0PNmnD9OnzxhRHIErsnioiIiNwLhS+RrMbmTkKNySzLNZ6Ekr3B1Q+ijsL2t+C3IvB3ezi5AOwJZlfq9Gw26NDB6I64bBm0aGF0Q5w1C6pVM54vWwZpWGYqIiIiovAlklVdtQZjr/oJtD8Fdb6BAvXBkQAn5sKK1jCvGOwYBdEnzC7V6Vksxv3BFi40znh16QJWKyxeDE2aGN0Tf/4ZEpSHRURE5A4UvkSyOpdcUOw5aLYSWu+CMv3BLS9EH4cdw+G3orC8DZz4XfcJywRVqsDMmXDwoLEGzMMDNm2Cjh2hbFljrdj162ZXKSIiIlmRwpdIduJbDqp/Au1PQt3voWAjoxnHqfnw9xPwWzBsHw5RYWZX6vSKFYOJE40OiW+/DXnywIED8PLLxmtjxsCVK2ZXKSIiIlmJwpdIdmTzgOBnoOlyeHwvhLwG7vnh2knYOcoIYX+1guNzwR5ncrHOrUAB4z5hYWHwyScQFATh4TBkiPF40CA4pT4pIiIigsKXSPbnUwaqfQztTkC9WeD/KOCA03/CyvbGZYn/vAmRR8yu1Knlzg39+8OhQ/D111C+PFy9Ch99ZJwJe+EF2LfP7CpFRETETApfIs7C5g5FO0OTpdDmAJQbbLSuv3Yadr1vtKtf1gLCftHZsAzk6grdusH27fD771C/PsTGwldfQaVKLgwfXofPPrNy4IDZlYqIiEhmU/gScUbeJaHKGGh7HOr/DAHNAQeEL4ZVT8HcwrDtv3D1oNmVOi2rFR5/HFauhFWr4IknwOGw8M8/BXntNRulS0Pp0jBgACxZAjExZlcsIiIiGU3hS8SZ2dygSAd4dBE8cQjKDwWPALh+FnZ/AL+XgqVN4NhsSNDf/jNKvXrw22+we3ccPXvu5JFH7Li4GA06xo+HZs0gf35o3x6+/BJOnjS7YhEREckICl8iOUXu4lD5PWgXBg3mQOBjgAXOLIPVTxtnw7a+ARH7za7UaZUsCW3bHmLRogQuXIBffoHnn4eAAIiMhLlz4cUXoXBhqFoV3noL1q7V/cNERESchcKXSE5jdYWgdvDIAmh7BCq8DbkegpjzsOdjmF8GljSGozMhQTesyig+PvDkk8ZasJMnYfNmo2ti7drGTZ23bYP33oO6dcHfH559Fn74AS5eNLtyERERuV8KXyI5mVdRqDQK2h6FhvOg0ONgscLZFbCmK8x5CDYPgCu7za7UqVmtUK2acb+wdevgzBn45hvo3Bn8/ODCBfj+e3jmGaO1ff36MHq00dTD4TC7ehEREUkrhS8RAasLFG4DjX+Htseg4kjwDILYi7BvPPxRHkIbwJFvIf6a2dU6vQIF4LnnYNYsOHcO/v4bBg+GChXAbofVq2HoUKhcGYoUMW7sPG8eREWZXbmIiIjcicKXiCTnWRgqDoMnjkCjP6BwW7DY4NwqWNsN5hSCTX3h8g6zK80RXFygQQMYMwZ27IBjx2DSJKOTYq5ccOIETJkCbdtC3rzQogVMmGDcb0xERESyFoUvEUmd1QYPtYKGc6FtGFR617hMMe4y7P8MFlSCRXXg0HSI1ymXzFKkCPzf/xn3ELtwAf78E/r0MW7kHBsLixdDv35Gc48yZWDgQFi61HhNREREzKXwJSJ351kIKrwJTxyGRxZBUAewuMCFdbD+eeNs2MbecGmb2ZXmKLlyQcuW8NlnxpmuPXvg44/hkUeMM2b798Mnn0DTppAv340GH6dOmV25iIhIzuRidgEiko1YrBDY3BjXwuHwDDg0FSIPw4EvjJG3JpR8CYo+Da65za44x7BYICTEGK+9BleuGDdv/uMPWLDAaOIxZ44xwGhl37q1MWrWBJvN3PpFRERyAp35EpH7kysAyv8X2hyAR5dAkU5GG/uLG2HDizAnEDb8H1zcbHalOZKvL3ToANOmGWe6Nm6EkSOhVi0jqG3dCu++C3XqGPcZS2zwcemS2ZWLiIg4L4UvEXkwFisENIH6s6HdCaj6EXiXgvhIOPg/WFgD/qwOB/4HcRFmV5sjWa1QowYMGwbr10N4OHz9NXTqZIS08+fhu++gSxfInz95gw+1shcREUk/Cl8ikn48CkLZ1+HxfdDkLyjaBaxucGkLbPw/Y23Y+hfg/Ab9rd5EBQtCt24we7bRyn7FChg0CMqXN1rZr1oFQ4ZApUpQtOiNBh9qZS8iIvJgFL5EJP1ZLODfGOrNhHYnodo48AkxuiIe+goW14Y/q8D+zyH2ssnF5myurtCwIXzwAezcCUePwhdfGGvBcuWC48fhf/+DJ54wmnYkNvg4fNjsykVERLIfhS8RyVge+SFkALTeDU1XQvBzYHWHy9thUx/jbNi6nnBurc6GZQFFi8Irr8D8+UYr+wULoHdvCA6GmBhYtAj69oUSJW4091i2TK3sRURE0kLhS0Qyh8UCBetD3W+g/Smo/in4loeEa0bXxNC6sKAi7JsAser6kBXkygWPPQYTJxpnunbtgo8+gsaNjVb2+/bBuHHQpImxViyxwcfp02ZXLiIikjUpfIlI5nPPC2X6Qqsd0GwNFO8BtlxwZRds7mecDVvTDc6u1NmwLMJigXLl4PXX4a+/jCYdP/4IPXoYa8iuXoVff4VevaBQIahe/UaDD7vd7OpFRESyBoUvETGPxQIF6sDD042zYTUmgl8lSLgOR7+FJQ3hj3Kw9xOIuWB2tXITX1/o2BGmTzfOdG3YACNGGPcMA9iyBd55Bx5+2Ghln9jg4/JlM6sWERExl8KXiGQNbn5Qujc8tg2ar4cSvcDmCRF7YctA42zY6mfgzHKdDctirFYjdA0fboSw8HCYMcMIZz4+RkfFb7+Fp582Lk+8ucGHplJERHIShS8RyVosFshfC2p/CU+ehpqTIU9VsMfCsR9g6SMwvwzs/giunzW7WkmFvz90725clnj+PCxfDm+8YVy2mJAAK1fCf/8LFSsajTwSG3xER5tduYiISMZS+BKRrMvVB0q9DI9tgZaboORL4JIbrh6AbYNgbmFY1RnCl4JDC4uyIldXaNQIPvzQaNhx5Ah8/jm0agUeHhAWBpMnQ5s2kDfvjQYfR46YXbmIiEj6U/gSkewhb3Wo9T9ofxpqTYW8NcEeB2E/wrKm8Hsp2DUGroWbXancQXAw/Oc/8McfRiv7+fON50WLGq3sFy6EV1+F4sWhbNkbDT7i4syuXERE5MEpfIlI9uKaG0q+AC03wGNbodR/jDNkkYfhnyEwNwhWPgWnFulsWBbn6WnczPnzz40zXTt3GmvBGjUCmw327oWxY+HRR421Yk89ZTT4CFe+FhGRbErhS0SyrzxVoObnRqfE2tMgfx1wxMPxX2B5S5hXAna+B9GnzK5U7sJigfLlYdAgY43Y+fNGd8Tu3Y1W9hER8Msv8PzzEBiYvMGHWtmLiEh2ofAlItmfixeU6AnN10Cr7VD6VXD1g6ijsP0t+K0I/N0OTi4Ae4LJxUpa+PlBp05G18TTp437hQ0fDjVqGK9v2gSjRkHt2kYr+8QGH2plLyIiWZnCl4g4F7+KUGOCcTaszjdQoD44EuDEb7CiNcwrBjtGQtRxsyuVNLJaoVYt4z5iGzcaYWz6dOMyxMRW9t98A507G5cnNm58o8GHWtmLiEhWovAlIs7JJRcUew6arYTWu6BMf3DLC9HHYccImBcMy9vAid/BHm9ysXIvAgKgRw/46Sfj8sRly4zGHGXLGq3sV6yAwYOhQgUoVuxGgw+1shcREbMpfImI8/MtB9U/gfYnoe73ULCR0Yzj1Hz4+wn4rShsHwZRx8yuVO6Rqys88gh89BHs3g2HD8Nnnxkt693d4dgxmDQJHn8c8uUzWtx//jkcPWp25SIikhMpfIlIzmHzgOBnoOlyeHwvlH0d3PPDtVOw8x34rRj81QqOzzHa2Eu2U6wY9OkDCxbAxYvw++/GTZyLFIHr1+HPP43XixUzGny88YbR4EOt7EVEJDMofIlIzuRTBqp+BO1OQL1Z4N8EcMDpP2HlkzC3CPzzJkTqbr/Zlaenccbriy+MM107dsCYMdCwodHKfvdu+Phj48xZgQI3GnycOWN25SIi4qwUvkQkZ7O5Q9HO0GQJtDkA5QaDR0G4Hg673od5xWFZcwj7GRJiza5W7pPFYqwBGzzYWBN27hzMmgXduhnB68oVYw1Zz57GmrKbG3yolb2IiKQXhS8RkUTeJaHKGGh7HOr/DAHNje3hobCqI/wWBFsHw9WD5tYpDyxPHqM74tdfGzdtXrcOhg2D6tWN1zduhJEjjRBWqJARyn76yQhpIiIi90vhS0TkVjY3KNIBHl0ETxyC8kPBIwCun4U9H8LvpWBpEzg2GxJizK5WHpDVatwvbORI4/5hp07BV19Bhw7g7W1chjhjhnFZYv78yRt8qJW9iIjcC4UvEZE7yV0cKr8H7cKgwRwIfAywwJllsPppmFsYtrwOEfvMrlTSSWAgPP88/Pyz0cp+6VIYOBBCQiA+3mjQMWiQ0bCjTBkXJk+uxPTpFrZsgRhlcRERuQMXswsQEckWrK4Q1M4YUcfg0DQ49BVcOwl7xxqjYCMo+RIEPWl0VpRsz80NHn3UGGPHGq3s//jD6Kb4119w9KiFo0eLsXChsb+rK5QrB1Wr3hiVKxs3gxYREVH4EhG5V15FodJIqPA2nPoTDk6B0wvg7ApjuOWFYt2g5IvGPcbEaRQvDq++aoyoKFi8OJ6vvz5KRERxtm2zcukS/POPMWbMuPG+kiWTB7KqVcHf37SvISIiJlH4EhG5X1YXKNzGGNEn/j0b9iVEH4d9441RoB6UeAmKdET/ynUuXl7w+OMOrNZdtGpVFBcXK2FhsHVr8nHiBBw8aIyffrrx/sDAlIGsWDGjM6OIiDgn/U1ARCQ9eBaGisOg/JtwehEcmgonf4dzq42xuR/Wos+QNyEIEpoY16eJU7FYoGhRY7Rrd2P7+fMpA9n+/XD6tDEWLLixr68vVKkC1ardCGQhIeCi/1qLiDgF/etcRCQ9WW3wUCtjRJ+Cw9ONIBZ1DNvBL2gAOOaOgHy1oED9f0ddcPMzuXDJKPnzQ7NmxkgUGQnbtycPZDt3Gq3sV6wwRiIPD6hYMfkZsooVjZtIi4hI9qLwJSKSUTwLQYU3ofwQCF+C/eCXxB1fjLv9CpxbaQwALOBX8aYwVh+8gkwtXTJW7txQt64xEsXGwp49yQPZtm1w9apx37GNG2/sa7UaZ8RuvWwxT55M/yoiInIPFL5ERDKaxQqBzUnI/wgLL/xBq4alcL20Ds6tgrOrIPIgXN5ujANfGO/xKpo8jPmWM44jTsvNzeiMWLky9OhhbLPbjQ6Lt162eOaMcZ+x3bvh++9vHKNo0ZSB7KGHtI5MRCSrUPgSEclMFgt4l4a85aFEL2PbtfB/14atNALZpa1GO/uoY3D0379Zu+WB/PWg4L9hLG8NsLmb9z0kU1itRqfEkiWhY8cb20+fvhHEtmwx/jxyBI4dM8bcuTf2zZ8/ZSArVco4toiIZC6FLxERs+UKgCIdjAEQdxUurDfOip1bCefXQewlODXfGABWd60by8ECA43RqtWNbZcvG5cp3nyGbM8eo+FHaKgxEnl5GWfYbg5k5cuDu/K8iEiGUvgSEclqXL0hoKkxAOxxcGnbv5cp/nt2LOZcKuvGKkCBBlo3lkP5+UHjxsZIdO2a0cjj5kC2fbtxj7I1a4yRKLUbRFepAt7emfs9REScmcKXiEhWZ3WFfDWNETIAHA64esAIYYnj6gG4vMMYievGPIsYIaxgA60by6Fy5YKaNY2RKD7eaHV/6zqyO90g+ubW91WrQsGCmf5VREScgsKXiEh2Y7GAT2ljlHje2Ja0bmzVjXVj0WFwbKYxAFz9jJs+JwYyrRvLkVxcjDNc5cpB167GNoeDu94g+scfbxyjUKGU68iCg9XYQ0TkbhS+REScwR3Xja2C82sh7jKc+sMY8O+6sZr/XqbYQOvGcrDb3SD63LmU68j274dTp4zxxx839vXzMy5TvDmQ6QbRIiLJ6V+JIiLO6E7rxhLH9bM3HjOGG+vGbr7fWBETv4SYrUCBtN8g+vJlWL7cGIl0g2gRkeQUvkREcoJU140dvNHePsW6sUnG+5LWjSXeb6y81o3lcHe6QXRi2/vEG0RHRuoG0SIiN1P4EhHJiSwW8ClljKR1Y2fg/OobHRXvtm6sQH3IVwNsHqZ9Dckabr5BdM+exja7HQ4dSrmO7OxZ3SBaRHIuhS8RETHk8oegJ40BEBdprBtLbHGf6roxt1TuN6ZTGGKc4SpVyhidOhnbHI7kN4hOHLe7QXSBAinXkekG0SKSnSl8iYhI6lxzQ0ATY8C/68b++fcyxZWprBsDrRuTO7FYjE6JhQpB69Y3tt/uBtHnzqV+g+hbA1n58sbZNxGRrE7hS0RE0sbqalxmmK8GhPS/ad3YqhuBLNV1Y0FGN0WtG5PbuNcbRK9ebYxErq5GALs5kFWurBtEi0jWo/AlIiL3J9m6sX8X+iStG0u839gWiD6eyrqxuv+2t9e6MUldWm8QvWXLjTNn27bB9OnGvhaLcYPoW9eR6QbRImImhS8REUk/d1o3lux+YwuMAf+uG7v1fmNaNyYp3e4G0ceOpVxHdvIkHDhgDN0gWkSyCoUvERHJOCnWjcXfcr+xlf+uG1ttDD4w9vP9d91YwQZaNyZ3ZLEY4Sk4GNq3v7H93LmUgezAgbTdILpCBYiPVxoTkfRn+kX3n3/+OcHBwXh4eFC7dm02bNhwx/1/+uknQkJC8PDwoGLFiixYsCDZ67/++ivNmzcnX758WCwWtm3bluIYjRs3xmKxJBv/93//l55fS0REUmN1ubFmrMHP0D4c2hyA2tOg+PPgXdrY78pOODgZ1nSF34rC3CKw+hnY/4WxnsxhN/VrSNZXoAA0bw6DB8OsWbBvH0REwKpV8Nln8PzzRtBydb1xg+hPPoFu3aBaNVeefvpxqlRxoVMnGDECfvoJdu0y7mkmInK/TD3zNXv2bAYOHMjkyZOpXbs248ePp0WLFuzbt4+CqVyUvWbNGrp06cLo0aN5/PHHmTlzJu3atWPLli1UqFABgKioKOrXr0+nTp148cUXb/vZL774IqNGjUp67unpmf5fUERE7sxiAe+SxkhcN5bYQTHFurEfjAHg6nvL/cZqat2Y3FXu3FCvnjESxcYa9xy7+QzZtm0OIiOtSfcju5nNZrS7L1/+xiWQ5ctD6dLg7p6530dEsh9Tw9e4ceN48cUX6fnvHRknT57MH3/8wbRp0/jvf/+bYv9PP/2Uli1b8sYbbwDwzjvvEBoaysSJE5k8eTIAzz33HABHjx6942d7enoSEBCQjt9GRETShUfB5OvG4qPg/Pob7e3Pr4W4K3dYN1Yf8tcF97zmfQfJNtzcjEsOq1S5cYPomJh4vv32L/z9H2X/fpekELZrF1y9Cnv3GuOXX24cx2aDEiVShrIyZcBD/19ARP5lWviKjY1l8+bNDBkyJGmb1WqladOmrF27NtX3rF27loEDBybb1qJFC+befEfGNPr+++/57rvvCAgIoE2bNrz99tt3PPsVExNDTExM0vOIiAgA4uLiiIuLu+fPT0+Jn292HZJ+NKfOSfN6v9wgXwNjhGCsG7uyHev51VjOrcJyfg2WmDMp1o05fMpjz18PR/66OPLXA6+i6V6Z5tQ5JSTEUaDANZo0iaVlS0fSdofDaOSxZ4+F3bst7NljYc8e2L3bwpUrFvbvN7oxzplz41hWq4PixaFsWUfSKFfOQZkyoItuMo/+WXVOWWle01qDaeHr/PnzJCQk4O/vn2y7v78/e/fuTfU94eHhqe4fHh5+T5/9zDPPULRoUQoVKsT27dsZPHgw+/bt49dff73te0aPHs3IkSNTbF+8eHGWuWQx9Oa7UIpT0Jw6J81reilhDFs3vHKFkzdhN/nse8iXsJvcjlNYInZhi9gFh6cAEG3Jz0VrWS7YynLRVo4ISxBYbOlSiebUOd1pXkuVMsYTTxih7NIlD44f9yYszJvjx2+MyEg3Dh6Egwct/P77jfdbLA4KFowmKOgqRYpcJSjIGIULX8XDIyETvl3OpH9WnVNWmNfo6Og07Zcjux2+9NJLSY8rVqxIYGAgTZo04dChQ5QoUSLV9wwZMiTZWbeIiAiCgoJo3rw5Pj4+GV7zncTFxREaGkqzZs1wdXU1tRZJH5pT56R5zTxx189iubDGOCt2bhWWy1vxdJzHM2ElhRNWAuBw9cWRrw6O/PWMkffe7zemOXVO6TWvDgecORP37xkyC7t33zhrduGChTNnvDhzxotNm5IvgwgOTn6WrGxZCAlx6KbRD0D/rDqnrDSviVfF3Y1p4St//vzYbDbOnDmTbPuZM2duuxYrICDgnvZPq9q1awNw8ODB24Yvd3d33FNZSevq6mr6ZCfKSrVI+tCcOifNayZwfQi8O0JwR+N50rqxG/cbs8RdwRK+EMIXGvtY3SBvjRvt7e9h3Zjm1Dmlx7wGBRmjefPk28+eJdlassTHZ8/C0aMWjh618Oefyd9TpEjy9WTlykHZsuDr+0Al5ij6Z9U5ZYV5Tevnmxa+3NzcqF69OkuXLqVdu3YA2O12li5dSp8+fVJ9T506dVi6dCn9+/dP2hYaGkqdOnUeqJbEdvSBgYEPdBwREcmiXLwg4FFjgLFu7PI/NzoqnlsJ18/A+TXGSLrfWPkbN38uWB88i+huvJIuChY0RuPGybefP38jiN0czMLDISzMGAsXJn9P4cIpQ1m5csb9y0QkazH1ssOBAwfSvXt3atSoQa1atRg/fjxRUVFJ3Q+7devGQw89xOjRowHo168fjRo1YuzYsbRu3ZpZs2axadMmpkyZknTMixcvEhYWxqlTpwDYt28fYJw1CwgI4NChQ8ycOZNWrVqRL18+tm/fzoABA2jYsCGVKlXK5J+AiIiYwuoCeasbI6SfcX1Y5KGbbv68CiL2wZVdxjj4P+N9noVvhLEC9cGrtLnfQ5xO/vzQsKExbnbxYuqh7NQpOHHCGIsXJ39PYGDK7ovlykFeNQIVMY2p4atz586cO3eOYcOGER4eTpUqVVi4cGFSU42wsDCs1hv3ga5bty4zZ87krbfeYujQoZQqVYq5c+cm3eMLYN68eUnhDeDpp58GYPjw4YwYMQI3NzeWLFmSFPSCgoLo0KEDb731ViZ9axERyXJuvt9Y8R7Gtutn/+2g+G8Yu7gFok/AsVnGAFxcfamTEIx183zIHQxeRYyzY15FINdDYHMz7SuJc8mbF+rXN8bNLl+GPXuSX7q4a5cRxk6fNsaSJcnf4++feijLnz/Tvo5IjmV6w40+ffrc9jLD5cuXp9jWsWNHOnbseNvj9ejRgx49etz29aCgIFasWHGvZYqISE7jURCC2hsDjHVjFzbA2ZXJ1o0V5B84/E8qB7BArkDwDEoeym7+0z2fLmOUB+LnB3XqGONmERGph7KwMDhzxhjLliV/T4ECKS9dLF/e2K5fU5H0YXr4EhERyRZcvMD/EWMA2OOJO7+FnX9/S6WSftiun4SoMIgOM/60x8C1U8a4sD71Y9py3T6YeRUxLnO8xw6MIgA+PlC7tjFulniT6JtD2e7dcOQInDsHK1YY42b58qUeyvz9FcpE7pXCl4iIyP2wukCeqoS5nqZC+VbYbu505XBAzLmbwtjxG6Es8c/r4ZBwzVhbFrHv9p/j4Z9KKLvpbJpHQf0NWNLM2xtq1jTGzaKijFB2a/fFw4fhwgVYudIYN8uTJ/VGH4UK6VdS5HYUvkRERNKbxWKEIo+CkK9G6vskxBhryBLD2M3BLPHPhGijC+P1M3BxY+rHsbrfCGOpnj0LAhfPjPuu4hS8vKB6dWPcLDoa9u1LGcoOHYJLl2D1amPczNc39VBWuLBCmYjCl4iIiBls7uBdwhipcTgg9mLqoSwqDKKPG5c02mMg8qAxbsc9f8pQdvNjD3+wWG//fsmxPD2halVj3Oz69Ruh7OZgdvAgXLkCa9ca42be3jeC2M3BLCgIrPr1kxxC4UtERCQrsliMhhzu+SBv1dT3SYg1Aliq4SwMoo5BfCTEnDfGpS2pH8fqCrkK3z6ceRYB19wZ910l2/HwgMqVjXGzmBjYvz9lW/wDB4z1ZuvXG+NmXl6ph7KiRRXKxPkofImIiGRXNjejxX3u4NRfdzgg7krqZ88S/7x2EuxxEHXEGLfjluf2jUG8ioBHIFhtGfEtJRtxd4eKFY1xs9hY46zYrd0X9+831ptt3GiMm3l6QtmyKYNZcDDY9Ksm2ZTCl4iIiLOyWMDNzxh5KqW+jz3eOHuWIpjd1CQk7jLEXjLG5dTa6gMWm9GdMVkwC0r+3M03g76oZHVubjcC1M3i4oz1Y7euKdu711hvtnmzMW7m4QEhISm7LxYvrlAmWZ/Cl4iISE5mdblx9up24iJS79iY9OcJcMQblzlGHYNztzmOq8+dz57lKmRcAik5hqurEaRCQuDJJ29sj483Oi2mFsquX4dt24xxM3d3KFMmZSgrcZtllSJmUPgSERGRO3P1Ab/yxkiNPcFonX+nyxtjLxoh7spOY6TGYjUC2J0CmqufWublAC4uULq0Mdq1u7E9IcG4J9mtjT727IFr12D7dmPczNUVSpd2wdu7JosWWSlUCAIDb4yAAChYUGfNJHMofImIiMiDsdrA8yFjUCf1feKj7nL27DjYY/9tv38Czq9J/TguXnc5e1bYWAsnTslmg5IljfHEEze22+1w9GjKULZ7t3H54q5dFqAQ69alflyr1QhgAQEpg9mtj3PlyoxvKs5K4UtEREQynosX+IYYIzUOO1w/e+ezZzHnjBAXsccYqbJAroDbBzTPIkYHSZ09cypWq7Hmq3hxePzxG9vtdggLg3/+iWfBgt3kzVues2dtnD4N4eFw+jScPWvsFx5ujFsvZ7yVr+/tg9nNj/Pk0a+ZpKTwJSIiIuazWI3QlCsAqJX6PvHXjDNkqd6Y+t/tCdfh2mljXFif+nFsuVLeiDpZY5CADPuakrmsVqM74kMPOYAjtGpVFlfX5NcXJiTAuXNGEEscicHs1sfXrxv3MbtyxVh/difu7kYQu11IS3zu729cZik5g6ZaREREsgeXXOBT2hipcTiM+5mlGs7+/fN6OCRcg4h9xkiFK/AYXrj8WQhy+YNHQXAv+O+fBYw/E4d7QXDPq5tUZ2M2242QdOvNpG/mcEBERNpC2qVLxj3Pjh0zxp1YLFCgQNouefTySt/vLplP4UtEREScg8UCHgWMkbd66vskxPy7ruwOAS0hGjeiIPKAMe76uVZwz38joCWFtQLJg1vicPHW9WjZkMViXHLo62t0Z7yT69fhzJnUg9nNz8+cMc68nT1rjFubhdzK2zttIS2frqzNshS+REREJOewuYN3CWOkxuEgLuoMf4f+TKPaZXGJv2isRbt+1lhzlvT43z9jL91Yr3b9LFxJQw1Wt5Sh7OYzardud1GHh+zGwwOKFjXGnSQkwIULaTubFh0NV68a48Bd/p+Aq+udL3lMfOzvb9yDTTKPwpeIiIhIIosF3PMRaQ3CUaCh8bfYO7HHGZc6JoavpGB27kZAuzm8xUcm7+qYFi65bwllBVKeTUs80+aeX/dKy0ZsNqPLYsGCULny7fdzOIzQdbtgdvPjCxeMm1cfP26Mu8mf/+7r0gIDjbNu8uAUvkRERETul9UVcgUaIy3io5OfQbvdGbXE7fZYI7BFRkLk4bR9hlvelGfUUoS1f7e75dF6tWzAYgEfH2OUvs2Sx0SxsWm75DE83LiZ9fnzxth5m9vvJfLyStslj/nzG41OJHUKXyIiIiKZxcUTXIqC112uRwPjdEdcRPJQliK43bQ95rxxCWTsRWNE3KUdH4DFdlNAS6WZyK3bXXJrMVEW5+YGQUHGuBO7HS5eTNslj5GREBUFhw4Z405sNuNyxruFtIAAoyNkTqPwJSIiIpIVWSzg5msMSt19f3uCEbpuvvQxxdm0m7bHXQZHgtEB8np42mqyedx0ieNtLn28+bHN40F+ApKBrFbjLFX+/FCx4p33jYy8fTC7+fm5c8Y6tlOnjHE3efPefV1aYKBxxs9ZMr/Cl4iIiIgzsNpudHuk/N33T4i9cSbtTpc+Xj8L188YLfoTrhtdIaPD0laTq8+dm4kka9mfD6z6q2lWlDs3lCxpjDuJizO6NqblksfYWOPM28WLsHv3nY+bK1fqwaxgQQsREX7p9j0zg37DRURERHIimxt4PmSMtIiP+jeIpdZMJJXtjnjjssm4CIi8y7VqAFiMe6alaNl/mzNtrn7OczrESbi6wkMPGeNOHA7jXmhpueQxIgKuXYMjR4yRnAtNmgTTt29GfaP0p/AlIiIiInfn4gW5ixnjbhwO47LG24a1Wy6JjLkAOIw/Yy5AxJ67f4bFJWUou9391Wx+Rk2SJVgsxiWHefNC+bucpI2OvtMlj3aKFLkMFMqMstOFwpeIiIiIpC+Lxeik6JYHfMrcfX97/L/BK5XLH1NrMhIXYZxZu3baGHfhCrTBBcscT+O+ababRtJzz1ue326/xOeed95PLf/ThacnFC9ujFvFxSWwYMFRoFxml3XfFL5ERERExFxWF8jlb4y0SIi5TefH21wSmXAdK/EQH2GMzGCxpT2opdjueff9km3zNMKeLsPM8hS+RERERCR7sbmDZ2Fj3I3DQdz1yyxb+AuPNqqDqyX+3+Yh1yD+3z8Tom95fstIbXt8dCr7Xr/pcxOMe7TFR0JMxv0oklisqQe5+zlrd6cwmHRmz11h7z4ofImIiIiI87JYwCU3160FwLu00RUiozgcRgBLNbxF3znMpbY91YB3y778u5bNYTeaosRHZdz3S8Zi3EogRXhLJajd7axdmvbzcIobgit8iYiIiIikB4vFCAwuuTLn8xwOsMfePqzdNeTd5YxfiteijZBnfPiN7ZnF6p7sLJyL1YPSsZWAVplXwwNS+BIRERERyY4sFuMSTJs74Jfxn+dwgD0u7Zdm3hoI0xTybgmEjvgbn2+PgdgY4JLx9QEPlyIZ/73TkcKXiIiIiIjcncVi3B/O5gb4Zs5n2uNvG/LiY65yZOMB0rDyL8tQ+BIRERERkazJ6gJWb3D1TvGSIy6Oq9brqbwp68r+q9ZERERERESyAYUvERERERGRTKDwJSIiIiIikgkUvkRERERERDKBwpeIiIiIiEgmUPgSERERERHJBApfIiIiIiIimUDhS0REREREJBMofImIiIiIiGQChS8REREREZFMoPAlIiIiIiKSCRS+REREREREMoHCl4iIiIiISCZQ+BIREREREckELmYXkF05HA4AIiIiTK4E4uLiiI6OJiIiAldXV7PLkXSgOXVOmlfnozl1TppX56M5dU5ZaV4TM0FiRrgdha/7dPXqVQCCgoJMrkRERERERLKCq1ev4uvre9vXLY67xTNJld1u59SpU3h7e2OxWEytJSIigqCgII4fP46Pj4+ptUj60Jw6J82r89GcOifNq/PRnDqnrDSvDoeDq1evUqhQIazW26/s0pmv+2S1WilcuLDZZSTj4+Nj+i+epC/NqXPSvDofzalz0rw6H82pc8oq83qnM16J1HBDREREREQkEyh8iYiIiIiIZAKFLyfg7u7O8OHDcXd3N7sUSSeaU+ekeXU+mlPnpHl1PppT55Qd51UNN0RERERERDKBznyJiIiIiIhkAoUvERERERGRTKDwJSIiIiIikgkUvkRERERERDKBwlc29vfff9OmTRsKFSqExWJh7ty5ZpckD2j06NHUrFkTb29vChYsSLt27di3b5/ZZckDmjRpEpUqVUq6CWSdOnX4888/zS5L0tGYMWOwWCz079/f7FLkPo0YMQKLxZJshISEmF2WpIOTJ0/y7LPPki9fPnLlykXFihXZtGmT2WXJfQoODk7xz6rFYqF3795ml5YmCl/ZWFRUFJUrV+bzzz83uxRJJytWrKB3796sW7eO0NBQ4uLiaN68OVFRUWaXJg+gcOHCjBkzhs2bN7Np0yYeffRR2rZty65du8wuTdLBxo0b+d///kelSpXMLkUeUPny5Tl9+nTSWLVqldklyQO6dOkS9erVw9XVlT///JPdu3czduxY8uTJY3Zpcp82btyY7J/T0NBQADp27GhyZWnjYnYBcv8ee+wxHnvsMbPLkHS0cOHCZM9nzJhBwYIF2bx5Mw0bNjSpKnlQbdq0Sfb8vffeY9KkSaxbt47y5cubVJWkh8jISLp27crUqVN59913zS5HHpCLiwsBAQFmlyHp6IMPPiAoKIjp06cnbStWrJiJFcmDKlCgQLLnY8aMoUSJEjRq1Mikiu6NznyJZGFXrlwBIG/evCZXIuklISGBWbNmERUVRZ06dcwuRx5Q7969ad26NU2bNjW7FEkHBw4coFChQhQvXpyuXbsSFhZmdknygObNm0eNGjXo2LEjBQsWpGrVqkydOtXssiSdxMbG8t133/H8889jsVjMLidNdOZLJIuy2+3079+fevXqUaFCBbPLkQe0Y8cO6tSpw/Xr18mdOzdz5syhXLlyZpclD2DWrFls2bKFjRs3ml2KpIPatWszY8YMypQpw+nTpxk5ciQNGjRg586deHt7m12e3KfDhw8zadIkBg4cyNChQ9m4cSN9+/bFzc2N7t27m12ePKC5c+dy+fJlevToYXYpaabwJZJF9e7dm507d2rNgZMoU6YM27Zt48qVK/z88890796dFStWKIBlU8ePH6dfv36Ehobi4eFhdjmSDm6+jL9SpUrUrl2bokWL8uOPP9KrVy8TK5MHYbfbqVGjBu+//z4AVatWZefOnUyePFnhywl89dVXPPbYYxQqVMjsUtJMlx2KZEF9+vRh/vz5/PXXXxQuXNjsciQduLm5UbJkSapXr87o0aOpXLkyn376qdllyX3avHkzZ8+epVq1ari4uODi4sKKFSuYMGECLi4uJCQkmF2iPCA/Pz9Kly7NwYMHzS5FHkBgYGCK/8lVtmxZXVLqBI4dO8aSJUt44YUXzC7lnujMl0gW4nA4ePXVV5kzZw7Lly/XomAnZrfbiYmJMbsMuU9NmjRhx44dybb17NmTkJAQBg8ejM1mM6kySS+RkZEcOnSI5557zuxS5AHUq1cvxS1b9u/fT9GiRU2qSNLL9OnTKViwIK1btza7lHui8JWNRUZGJvs/ckeOHGHbtm3kzZuXIkWKmFiZ3K/evXszc+ZMfvvtN7y9vQkPDwfA19eXXLlymVyd3K8hQ4bw2GOPUaRIEa5evcrMmTNZvnw5ixYtMrs0uU/e3t4p1mJ6eXmRL18+rdHMpl5//XXatGlD0aJFOXXqFMOHD8dms9GlSxezS5MHMGDAAOrWrcv7779Pp06d2LBhA1OmTGHKlClmlyYPwG63M336dLp3746LS/aKM9mrWklm06ZNPPLII0nPBw4cCED37t2ZMWOGSVXJg5g0aRIAjRs3TrZ9+vTp2WoxqSR39uxZunXrxunTp/H19aVSpUosWrSIZs2amV2aiPzrxIkTdOnShQsXLlCgQAHq16/PunXrUrS1luylZs2azJkzhyFDhjBq1CiKFSvG+PHj6dq1q9mlyQNYsmQJYWFhPP/882aXcs8sDofDYXYRIiIiIiIizk4NN0RERERERDKBwpeIiIiIiEgmUPgSERERERHJBApfIiIiIiIimUDhS0REREREJBMofImIiIiIiGQChS8REREREZFMoPAlIiIiIiKSCRS+REREMpnFYmHu3LlmlyEiIplM4UtERHKUHj16YLFYUoyWLVuaXZqIiDg5F7MLEBERyWwtW7Zk+vTpyba5u7ubVI2IiOQUOvMlIiI5jru7OwEBAclGnjx5AOOSwEmTJvHYY4+RK1cuihcvzs8//5zs/Tt27ODRRx8lV65c5MuXj5deeonIyMhk+0ybNo3y5cvj7u5OYGAgffr0Sfb6+fPnad++PZ6enpQqVYp58+Zl7JcWERHTKXyJiIjc4u2336ZDhw78888/dO3alaeffpo9e/YAEBUVRYsWLciTJw8bN278/3buHqSRIAzj+DOioFm1kGAINhZCiIWCKBi0CVYKgqDYBIk2EpRgIwhBMKK1dqYQu4hCCsHCD9AyIFZ+FGotBFGwEUGb5AohuOdxHMc55sz/V83OLLvvlA+z7yqTyejo6MgVrlKplKanpzU5OanLy0vt7u6qpaXF9Y7FxUWNjo7q4uJCAwMDikQienx8tLpPAIBdplAoFL66CAAAbBkfH1c6nVZ1dbVrPpFIKJFIyBijWCymVCpVXOvu7lZHR4fW1ta0vr6uubk53d7eynEcSdLe3p4GBweVy+Xk8/nU1NSkiYkJLS8v/7IGY4zm5+e1tLQk6S3Q1dbWan9/n94zAPjG6PkCAJSdcDjsCleS1NDQUByHQiHXWigU0tnZmSTp6upK7e3txeAlST09Pcrn87q5uZExRrlcTn19fb+toa2trTh2HEf19fW6v7//2y0BAP4DhC8AQNlxHOfDZ4D/Sk1NzR/dV1VV5bo2xiifz39GSQCAEkHPFwAAPzk5OflwHQwGJUnBYFDn5+d6fn4urmezWVVUVCgQCKiurk7Nzc06Pj62WjMAoPRx8gUAKDuvr6+6u7tzzVVWVsrr9UqSMpmMOjs71dvbq83NTZ2enmpjY0OSFIlEtLCwoGg0qmQyqYeHB8XjcY2Njcnn80mSksmkYrGYGhsb1d/fr6enJ2WzWcXjcbsbBQCUFMIXAKDsHBwcyO/3u+YCgYCur68lvf2JcHt7W1NTU/L7/dra2lJra6skyePx6PDwUDMzM+rq6pLH49Hw8LBWVlaKz4pGo3p5edHq6qpmZ2fl9Xo1MjJib4MAgJLE3w4BAHjHGKOdnR0NDQ19dSkAgG+Gni8AAAAAsIDwBQAAAAAW0PMFAMA7fI0PAPgsnHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALPgBuGBT/6/XncYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_dir_name = \"../models/fld0_sfzn1_hd_hl512_hghcnf08_prb02//\"\n",
    "i = 0\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# loss„Çí„Éó„É≠„ÉÉ„Éà\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\n",
      "ÊúÄÂ§ßË™§Â∑Æ: 0.0\n",
      "Âπ≥ÂùáË™§Â∑Æ: 0.0\n",
      "Ê®ôÊ∫ñÂÅèÂ∑Æ: 0.0\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´Âá∫Âäõ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "\n",
    "# „É¢„Éá„É´„Éë„Çπ\n",
    "# ÊØîËºÉÂÖÉ\n",
    "model_1_path = \"../models/sfzn1_hd_hl512//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_safezone1000_head_hoplength512/model_fold0.pth\"\n",
    "\n",
    "# ÂÖ±ÈÄöË®≠ÂÆöÔºà„Åì„ÅÆcfg_inf„ÅØÂøÖÈ†àÔºâ\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÈñ¢Êï∞\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# Êé®Ë´ñÔºàÂá∫Âäõ„Å´ sigmoid „ÅåÂøÖË¶Å„Å™Â†¥Âêà„ÅØ model „Å´Âê´„Åæ„Çå„Å¶„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶ÈÅ©ÂÆúËøΩÂä†Ôºâ\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# Â∑ÆÂàÜË®àÁÆó\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\")\n",
    "print(f\"ÊúÄÂ§ßË™§Â∑Æ: {np.max(abs_diff)}\")\n",
    "print(f\"Âπ≥ÂùáË™§Â∑Æ: {np.mean(abs_diff)}\")\n",
    "print(f\"Ê®ôÊ∫ñÂÅèÂ∑Æ: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„Éù„ÉÉ„ÇØ1„Åß„Éá„Éê„ÉÉ„Ç∞„Åß„Åç„Çã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
