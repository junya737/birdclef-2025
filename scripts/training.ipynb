{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'module.config_lib' from '/root/program/birdclef-2025/scripts/module/config_lib.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import librosa\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import timm\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from module import preprocess_lib, datasets_lib, utils_lib, models_lib, learning_lib, config_lib\n",
    "reload(config_lib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            self.train_csv = '/kaggle/input/birdclef-2025/train.csv'\n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.spectrogram_npy = '/kaggle/input/birdclef25-mel-spectrograms/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330'\n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # 全modelの保存先\n",
    "            self.model_path = self.models_dir # 各モデルの保存先．学習時に動的に変更．\n",
    "            \n",
    "            self.train_csv = '../data/processed/mel_CropAugment/train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_CropAugment/birdclef2025_melspec_5sec_256_256.npy'\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensemble_7sec_pseudoth0.5/pseudo_label.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/train_soundscapes_0407/train_soundscapes_melspecs.npy\"\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = 'efficientnet_b0'\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.WINDOW_SIZE = 5.0 # 推論時のウィンドウサイズ\n",
    "        self.TARGET_DURATION = 5.0 # データセット作成時のウィンドウサイズ\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        self.N_FFT = 1024\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.N_MELS = 128\n",
    "        self.FMIN = 50\n",
    "        self.FMAX = 14000        \n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 8\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0]\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "\n",
    "            self.aug_prob = 0.5\n",
    "            self.mixup_alpha_real = 0.5\n",
    "            self.mixup_alpha_pseudo = 0.5\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            self.use_pseudo_mixup = False  # pseudo lableでmixupするかどうか\n",
    "            self.pseudo_mix_prob = 0.4  # mixupでpseudo lableを使う確率\n",
    "            self.pseudo_conf_threshold = 0.5\n",
    "            \n",
    "            self.full_train = True\n",
    "            \n",
    "\n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._load_taxonomy()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.jsonを保存\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _load_taxonomy(self):\n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # labelとindexの対応\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"📥 Loading pseudo label CSV and melspecs...\")\n",
    "\n",
    "        # row_id を index にして読み込む（← ここがポイント！）\n",
    "        self.pseudo_df = pd.read_csv(self.cfg.pseudo_label_csv, index_col=\"row_id\")\n",
    "\n",
    "        # 信頼度フィルタリング（例: 最大値が 0.5 未満の行を除く）\n",
    "        confidence_threshold = self.cfg.pseudo_conf_threshold\n",
    "        max_probs = self.pseudo_df.max(axis=1)\n",
    "        self.pseudo_df = self.pseudo_df[max_probs > confidence_threshold]\n",
    "        self.pseudo_df = self.pseudo_df.reset_index(drop=False)\n",
    "        print(f\"✅ Filtered pseudo labels: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # melspec は key が row_id の dict を想定\n",
    "        self.pseudo_melspecs = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True)\n",
    "        print(f\"✅ Loaded pseudo mel-spectrograms: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            print(\"🔀 Using BirdCLEFDatasetWithPseudo (with pseudo label mixup)\")\n",
    "            return self.datasets_lib.BirdCLEFDatasetWithPseudo(\n",
    "                train_df=train_df,\n",
    "                pseudo_df=self.pseudo_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                pseudo_melspecs=self.pseudo_melspecs,\n",
    "                mode='train'\n",
    "            )\n",
    "        else:\n",
    "            print(\"📦 Using BirdCLEFDatasetFromNPY (no pseudo mixup)\")\n",
    "            return self.datasets_lib.BirdCLEFDatasetFromNPY(\n",
    "                train_df, self.cfg, self.spectrograms, mode='train'\n",
    "            )   \n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # 👇 ROC AUC はバイナリラベルを必要とするので、soft labelを2値化\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # バイナリ化（連続値でもintでも安全）\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # エラー出たときも安心\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # ラベルをバイナリ化（soft label対応）\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csvのfoldを使う．\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['kfold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['kfold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = self.datasets_lib.BirdCLEFDatasetFromNPY(\n",
    "                val_df, self.cfg, self.spectrograms, mode='valid'\n",
    "            )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "\n",
    "            model = self.models_lib.BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # スコア取得\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwiseスコアを除外した val_metrics のログ\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # ログ用スコアの更新（classwiseは除外）\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "           \n",
    "                \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_20250412_2219\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_CropAugment/birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 31913 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Use full train data for training.\n",
      "Training set: 31913 samples\n",
      "Validation set: 6495 samples\n",
      "📦 Using BirdCLEFDatasetFromNPY (no pseudo mixup)\n",
      "Found 31913 matching spectrograms for train dataset out of 31913 samples\n",
      "Found 6495 matching spectrograms for valid dataset out of 6495 samples\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2c522c82f34c1686ac87dd6e7bfe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BirdCLEFTrainer(cfg, train_df, datasets_lib, models_lib, learning_lib)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 304\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    302\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(model, val_loader, criterion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# スコア取得\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 209\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.train_one_epoch\u001b[0;34m(self, model, loader, optimizer, criterion, device, scheduler)\u001b[0m\n\u001b[1;32m    205\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_outputs)\n\u001b[1;32m    206\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_targets)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(losses),\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_auc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_outputs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_map\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_map(all_targets, all_outputs),   \n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_classwise_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_classwise_auc(all_targets, all_outputs),\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_classwise_ap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_classwise_ap(all_targets, all_outputs),  \n\u001b[1;32m    213\u001b[0m }\n",
      "Cell \u001b[0;32mIn[5], line 109\u001b[0m, in \u001b[0;36mBirdCLEFTrainer._calculate_auc\u001b[0;34m(self, targets, outputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# 👇 ROC AUC はバイナリラベルを必要とするので、soft labelを2値化\u001b[39;00m\n\u001b[1;32m    107\u001b[0m targets_bin \u001b[38;5;241m=\u001b[39m (targets \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m aucs \u001b[38;5;241m=\u001b[39m [roc_auc_score(targets_bin[:, i], probs[:, i]) \n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(targets_bin[:, i]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(aucs) \u001b[38;5;28;01mif\u001b[39;00m aucs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# 👇 ROC AUC はバイナリラベルを必要とするので、soft labelを2値化\u001b[39;00m\n\u001b[1;32m    107\u001b[0m targets_bin \u001b[38;5;241m=\u001b[39m (targets \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m aucs \u001b[38;5;241m=\u001b[39m [\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets_bin\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(targets_bin[:, i]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(aucs) \u001b[38;5;28;01mif\u001b[39;00m aucs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    571\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1017\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1015\u001b[0m tps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m0\u001b[39m, tps]\n\u001b[1;32m   1016\u001b[0m fps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m0\u001b[39m, fps]\n\u001b[0;32m-> 1017\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1020\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo negative samples in y_true, false positive value should be meaningless\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1022\u001b[0m         UndefinedMetricWarning,\n\u001b[1;32m   1023\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/index_tricks.py:326\u001b[0m, in \u001b[0;36mAxisConcatenator.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrans1d \u001b[38;5;241m=\u001b[39m trans1d\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndmin \u001b[38;5;241m=\u001b[39m ndmin\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# handle matrix builder syntax\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    329\u001b[0m         frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)  # これはtrainer内部でまた読み込むので optional\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
