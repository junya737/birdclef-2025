{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cuda:0\n",
      "['sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        \n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n",
    "\n",
    "\n",
    "\n",
    "class BirdCLEFDatasetWithPseudoMixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, pseudo_df=None, pseudo_melspecs=None,\n",
    "                 mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.pseudo_df = pseudo_df.reset_index(drop=True) if pseudo_df is not None else None\n",
    "        self.pseudo_melspecs = pseudo_melspecs\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx2label = idx2label\n",
    "        self.species_ids = list(label2idx.keys()) if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df['filename'].map(\n",
    "                lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        rand_val = random.random()\n",
    "\n",
    "        # === real √ó real mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and rand_val < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === real √ó pseudo mixup ===\n",
    "        if (self.mode == \"train\" and self.cfg.use_pseudo_mixup and\n",
    "            self.pseudo_df is not None and\n",
    "            rand_val < (self.cfg.mixup_prob + self.cfg.pseudo_mixup_prob)):\n",
    "            \n",
    "            idx2 = random.randint(0, len(self.pseudo_df) - 1)\n",
    "            row2 = self.pseudo_df.iloc[idx2]\n",
    "            spec2 = self._get_spec_pseudo(row2['samplename'])\n",
    "            label2 = self._get_label_pseudo(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === no mixup ===\n",
    "        return {\n",
    "            'melspec': spec1,\n",
    "            'target': torch.tensor(label1, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_spec_pseudo(self, samplename):\n",
    "        if self.pseudo_melspecs and samplename in self.pseudo_melspecs:\n",
    "            spec = self.pseudo_melspecs[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Pseudo spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        return spec  # No augmentation\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def _get_label_pseudo(self, row):\n",
    "        values = row[self.species_ids].values.astype(np.float32)\n",
    "        values = np.nan_to_num(values, nan=0.0)\n",
    "        return values\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), \n",
    "                            (x.size(-2), x.size(-1))).pow(1. / self.p)\n",
    "\n",
    "# Â∑Æ„ÅóÊõø„Åà\n",
    "\n",
    "\n",
    "class BirdCLEFModelForTrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.pooling = GeM()\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        # self.dropout = nn.Dropout(0.3)\n",
    "        # self.activation = nn.Mish()  # „Åæ„Åü„ÅØ Swish, GELU\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(backbone_out, backbone_out // 2),\n",
    "        #     nn.BatchNorm1d(backbone_out // 2),\n",
    "        #     self.activation,\n",
    "        #     self.dropout,\n",
    "        #     nn.Linear(backbone_out // 2, cfg.num_classes)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        # Ê¥ªÊÄßÂåñÈñ¢Êï∞‰∏çÂú®Ôºé\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "class BirdCLEFModelForTrain_Coat(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # CoaTÂ∞ÇÁî®: drop_path_rate„Çí0„Å´„Åô„Çã\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.0  # <= „Åì„Åì„Çí0.0„Å´ÔºÅ\n",
    "        )\n",
    "        \n",
    "        # CoaT„ÅØ reset_classifier „ÅåÂøÖË¶Å\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')  # <= global_pool='avg'\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BirdCLEFModelForTrain_Swin(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        backbone_out = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)  # 2D„Éó„Éº„É™„É≥„Ç∞„Å´Â§âÊõ¥ÔºÅÔºÅ\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if features.ndim == 4:\n",
    "            # CNNÁ≥ª (B, C, H, W)\n",
    "            features = self.pooling(features)\n",
    "            features = features.flatten(1)\n",
    "        elif features.ndim == 3:\n",
    "            # TransformerÁ≥ª (B, N, C)\n",
    "            features = features.mean(dim=1)\n",
    "        elif features.ndim == 2:\n",
    "            # „ÇÇ„ÅÜ (B, C) „Å´„Å™„Å£„Å¶„ÇãÔºà‰æã„Åà„Å∞ SwinTinyÔºâ\n",
    "            pass  # ‰Ωï„ÇÇÂä†Â∑•„Åó„Å™„ÅÑ\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n",
    "\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = None\n",
    "            self.spectrogram_npy = None\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = None\n",
    "            self.pseudo_melspec_npy = None\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # ÂÖ®model„ÅÆ‰øùÂ≠òÂÖà\n",
    "            self.model_path = self.models_dir # ÂêÑ„É¢„Éá„É´„ÅÆ‰øùÂ≠òÂÖàÔºéÂ≠¶ÁøíÊôÇ„Å´ÂãïÁöÑ„Å´Â§âÊõ¥Ôºé\n",
    "            \n",
    "            \n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„Çã\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = '../data/processed/mel_sfzn3_hd_hl16/train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_sfzn3_hd_hl16//birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensmbl_0850//pseudo_labels.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/mel_prtl_trn_sndscps_hl16_0850/mel_train_soundscapes.npy\"\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = \"efficientnet_b0\" # tf_efficientnetv2_b3    seresnext26t_32x4d eca_nfnet_l0\n",
    "\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainerÂÜÖÈÉ®„ÅßÊ±∫„Åæ„Çã„ÅÆ„Åß„Åì„Åì„Åß„ÅØÊåáÂÆö„Åó„Å™„ÅÑÔºé\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0, 1, 2, 3, 4] # fold„ÅÆÈÅ∏Êäû\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # „É¨„Ç¢Á®Æ„ÅØÂÖ®ÈÉ®train fold„Å´„Åô„Çã\n",
    "            self.aug_prob = 0.5 # spec augment„ÅÆÁ¢∫Áéá\n",
    "            \n",
    "            # real √ó real„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha =  0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labels„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            \n",
    "            \n",
    "            \n",
    "            # real √ó pseudo„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_pseudo_mixup = True # Pseudo mixup„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            self.pseudo_no_call_threshold = 0.06  # no call„ÅÆÈñæÂÄ§Ôºé‰Ωé„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.08„Åå‰∏äÈôê\n",
    "            self.pseudo_high_conf_threshold = 0.9 # Pseudo Label„ÅÆÈ´ò‰ø°È†ºÂ∫¶„ÅÆÈñæÂÄ§ÔºéÈ´ò„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.7„Åå‰∏ãÈôêÔºé\n",
    "            self.pseudo_mixup_prob = 0.1 # Pseudo mixup „Çí‰Ωø„ÅÜÁ¢∫ÁéáÔºéreal √ó real mixup„Å®ÂêåÊôÇ„Å´‰Ωø„Çè„Çå„Çã„Åì„Å®„ÅØ„Å™„ÅÑÔºé\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=False)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train„ÅÆÂá¶ÁêÜ„Çí„ÇØ„É©„Çπ„ÅßÂÆüË°åÔºé\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # label„Å®index„ÅÆÂØæÂøú\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"üì• Loading pseudo label CSV and melspecs from: \", self.cfg.pseudo_label_csv)\n",
    "\n",
    "        # 1. „É©„Éô„É´CSVË™≠„ÅøËæº„Åø\n",
    "        df = pd.read_csv(self.cfg.pseudo_label_csv)\n",
    "        species_cols = df.columns.drop(\"row_id\")\n",
    "        \n",
    "        # 2. soft label ÂâçÂá¶ÁêÜ: „Åó„Åç„ÅÑÂÄ§‰ª•‰∏ã„Çí„Çº„É≠„Å´\n",
    "        df[species_cols] = df[species_cols].where(df[species_cols] >= self.cfg.pseudo_no_call_threshold, 0.0)\n",
    "\n",
    "        # 3. no_call „Å® high_conf „Å´ÂàÜÈ°û\n",
    "        no_call_df = df[df[species_cols].max(axis=1) == 0.0].copy()\n",
    "        no_call_df[\"primary_label\"] = \"no_call\"\n",
    "        no_call_df[\"pseudo_source\"] = \"no_call\"\n",
    "        no_call_df[\"samplename\"] = no_call_df[\"row_id\"]\n",
    "\n",
    "        high_conf_df = df[df[species_cols].max(axis=1) >= self.cfg.pseudo_high_conf_threshold].copy()\n",
    "        high_conf_df[\"primary_label\"] = high_conf_df[species_cols].idxmax(axis=1)\n",
    "        high_conf_df[\"pseudo_source\"] = \"high_conf\"\n",
    "        high_conf_df[\"samplename\"] = high_conf_df[\"row_id\"]\n",
    "\n",
    "        # 4. Áµ±Âêà\n",
    "        self.pseudo_df = pd.concat([no_call_df, high_conf_df], axis=0).reset_index(drop=True)\n",
    "        print(f\"‚úÖ no_call: {len(no_call_df)}, high_conf: {len(high_conf_df)}, total: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # 5. ÂøÖË¶Å„Å™ row_id „Å†„ÅëÊäΩÂá∫\n",
    "        used_ids = set(self.pseudo_df[\"row_id\"])\n",
    "\n",
    "        # 6. ËæûÊõ∏ÂΩ¢Âºè„ÅÆ .npy „ÇíË™≠„ÅøËæº„ÇÄ\n",
    "        print(\"üì¶ Loading full pseudo mel spectrograms from:\", self.cfg.pseudo_melspec_npy)\n",
    "        full_mels = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True).item()\n",
    "        \n",
    "        print(f\"üì¶ All pseudo mel specs loaded: {len(full_mels)}\")\n",
    "\n",
    "        # 7. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        self.pseudo_melspecs = {\n",
    "            row_id: full_mels[row_id]\n",
    "            for row_id in used_ids\n",
    "            if row_id in full_mels\n",
    "        }\n",
    "        \n",
    "        del full_mels  # „É°„É¢„É™ÁØÄÁ¥Ñ„ÅÆ„Åü„ÇÅ„Å´ÂâäÈô§\n",
    "        gc.collect()  # „Ç¨„Éº„Éô„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„ÇíÂÆüË°å\n",
    "\n",
    "        print(f\"‚úÖ Filtered mel specs loaded: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            \n",
    "            print(\"Using BirdCLEFDatasetWithPseudoMixup for training...\")\n",
    "            return BirdCLEFDatasetWithPseudoMixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                pseudo_df=self.pseudo_df,\n",
    "                pseudo_melspecs=self.pseudo_melspecs,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "        else:\n",
    "            print(\"Using BirdCLEFDatasetFromNPY_Mixup for training...\")\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # üëá ROC AUC „ÅØ„Éê„Ç§„Éä„É™„É©„Éô„É´„ÇíÂøÖË¶Å„Å®„Åô„Çã„ÅÆ„Åß„ÄÅsoft label„Çí2ÂÄ§Âåñ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „Éê„Ç§„Éä„É™ÂåñÔºàÈÄ£Á∂öÂÄ§„Åß„ÇÇint„Åß„ÇÇÂÆâÂÖ®Ôºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # „Ç®„É©„ÉºÂá∫„Åü„Å®„Åç„ÇÇÂÆâÂøÉ\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „É©„Éô„É´„Çí„Éê„Ç§„Éä„É™ÂåñÔºàsoft labelÂØæÂøúÔºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csv„ÅÆfold„Çí‰Ωø„ÅÜÔºé\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "            # coat„ÅåÊñáÂ≠óÂàó„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞\n",
    "            if 'coat' in self.cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Coat(self.cfg).to(self.cfg.device)\n",
    "            \n",
    "            elif 'swin' in self.cfg.model_name:\n",
    "                print(\"Using Swin model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Swin(self.cfg).to(self.cfg.device)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "                \n",
    "                \n",
    "                \n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # „Çπ„Ç≥„Ç¢ÂèñÂæó\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwise„Çπ„Ç≥„Ç¢„ÇíÈô§Â§ñ„Åó„Åü val_metrics „ÅÆ„É≠„Ç∞\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # „É≠„Ç∞Áî®„Çπ„Ç≥„Ç¢„ÅÆÊõ¥Êñ∞Ôºàclasswise„ÅØÈô§Â§ñÔºâ\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É¨„Ç¢Á®Æ„ÅØfold=-1„Å´„Åô„ÇãÔºé\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # ÂêÑ„É©„Éô„É´„ÅÆÂá∫ÁèæÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„ÅÆ„Éá„Éº„Çø„Å†„Åë fold = -1 „Å´‰∏äÊõ∏„Åç\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_20250605_1346\n",
      "{0: '1139490', 1: '1192948', 2: '1194042', 3: '126247', 4: '1346504', 5: '134933', 6: '135045', 7: '1462711', 8: '1462737', 9: '1564122', 10: '21038', 11: '21116', 12: '21211', 13: '22333', 14: '22973', 15: '22976', 16: '24272', 17: '24292', 18: '24322', 19: '41663', 20: '41778', 21: '41970', 22: '42007', 23: '42087', 24: '42113', 25: '46010', 26: '47067', 27: '476537', 28: '476538', 29: '48124', 30: '50186', 31: '517119', 32: '523060', 33: '528041', 34: '52884', 35: '548639', 36: '555086', 37: '555142', 38: '566513', 39: '64862', 40: '65336', 41: '65344', 42: '65349', 43: '65373', 44: '65419', 45: '65448', 46: '65547', 47: '65962', 48: '66016', 49: '66531', 50: '66578', 51: '66893', 52: '67082', 53: '67252', 54: '714022', 55: '715170', 56: '787625', 57: '81930', 58: '868458', 59: '963335', 60: 'amakin1', 61: 'amekes', 62: 'ampkin1', 63: 'anhing', 64: 'babwar', 65: 'bafibi1', 66: 'banana', 67: 'baymac', 68: 'bbwduc', 69: 'bicwre1', 70: 'bkcdon', 71: 'bkmtou1', 72: 'blbgra1', 73: 'blbwre1', 74: 'blcant4', 75: 'blchaw1', 76: 'blcjay1', 77: 'blctit1', 78: 'blhpar1', 79: 'blkvul', 80: 'bobfly1', 81: 'bobher1', 82: 'brtpar1', 83: 'bubcur1', 84: 'bubwre1', 85: 'bucmot3', 86: 'bugtan', 87: 'butsal1', 88: 'cargra1', 89: 'cattyr', 90: 'chbant1', 91: 'chfmac1', 92: 'cinbec1', 93: 'cocher1', 94: 'cocwoo1', 95: 'colara1', 96: 'colcha1', 97: 'compau', 98: 'compot1', 99: 'cotfly1', 100: 'crbtan1', 101: 'crcwoo1', 102: 'crebob1', 103: 'cregua1', 104: 'creoro1', 105: 'eardov1', 106: 'fotfly', 107: 'gohman1', 108: 'grasal4', 109: 'grbhaw1', 110: 'greani1', 111: 'greegr', 112: 'greibi1', 113: 'grekis', 114: 'grepot1', 115: 'gretin1', 116: 'grnkin', 117: 'grysee1', 118: 'gybmar', 119: 'gycwor1', 120: 'labter1', 121: 'laufal1', 122: 'leagre', 123: 'linwoo1', 124: 'littin1', 125: 'mastit1', 126: 'neocor', 127: 'norscr1', 128: 'olipic1', 129: 'orcpar', 130: 'palhor2', 131: 'paltan1', 132: 'pavpig2', 133: 'piepuf1', 134: 'pirfly1', 135: 'piwtyr1', 136: 'plbwoo1', 137: 'plctan1', 138: 'plukit1', 139: 'purgal2', 140: 'ragmac1', 141: 'rebbla1', 142: 'recwoo1', 143: 'rinkin1', 144: 'roahaw', 145: 'rosspo1', 146: 'royfly1', 147: 'rtlhum', 148: 'rubsee1', 149: 'rufmot1', 150: 'rugdov', 151: 'rumfly1', 152: 'ruther1', 153: 'rutjac1', 154: 'rutpuf1', 155: 'saffin', 156: 'sahpar1', 157: 'savhaw1', 158: 'secfly1', 159: 'shghum1', 160: 'shtfly1', 161: 'smbani', 162: 'snoegr', 163: 'sobtyr1', 164: 'socfly1', 165: 'solsan', 166: 'soulap1', 167: 'spbwoo1', 168: 'speowl1', 169: 'spepar1', 170: 'srwswa1', 171: 'stbwoo2', 172: 'strcuc1', 173: 'strfly1', 174: 'strher', 175: 'strowl1', 176: 'tbsfin1', 177: 'thbeup1', 178: 'thlsch3', 179: 'trokin', 180: 'tropar', 181: 'trsowl', 182: 'turvul', 183: 'verfly', 184: 'watjac1', 185: 'wbwwre1', 186: 'whbant1', 187: 'whbman1', 188: 'whfant1', 189: 'whmtyr1', 190: 'whtdov', 191: 'whttro1', 192: 'whwswa1', 193: 'woosto', 194: 'y00678', 195: 'yebela1', 196: 'yebfly1', 197: 'yebsee1', 198: 'yecspi2', 199: 'yectyr1', 200: 'yehbla2', 201: 'yehcar1', 202: 'yelori1', 203: 'yeofly1', 204: 'yercac1', 205: 'ywcpar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_sfzn3_hd_hl16//birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 28546 pre-computed mel spectrograms\n",
      "üì• Loading pseudo label CSV and melspecs from:  ../data/processed/pseudo_labels/ensmbl_0850//pseudo_labels.csv\n",
      "‚úÖ no_call: 1433, high_conf: 1345, total: 2778\n",
      "üì¶ Loading full pseudo mel spectrograms from: ../data/processed/mel_prtl_trn_sndscps_hl16_0850/mel_train_soundscapes.npy\n",
      "üì¶ All pseudo mel specs loaded: 10449\n",
      "‚úÖ Filtered mel specs loaded: 2778\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 22836 samples\n",
      "Validation set: 5710 samples\n",
      "Using BirdCLEFDatasetWithPseudoMixup for training...\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a508004f8ea54125a2d91d2c3ee27a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 365\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    363\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(model, val_loader, criterion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# „Çπ„Ç≥„Ç¢ÂèñÂæó\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 229\u001b[0m, in \u001b[0;36mBirdCLEFTrainer.train_one_epoch\u001b[0;34m(self, model, loader, optimizer, criterion, device, scheduler)\u001b[0m\n\u001b[1;32m    227\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m criterion(outputs, targets)\n\u001b[1;32m    228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs\n\u001b[0;32m--> 229\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    231\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´„ÅØmodels_{current_time}„Å´‰øùÂ≠ò„Åï„Çå„ÇãÔºé\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    # taxonomy„ÅØ„É©„Éô„É´„Å®index„ÅÆÂØæÂøú„ÇíÂèñ„Çã„Åü„ÇÅ„Å´ÂøÖË¶ÅÔºé\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 7, val_auc: 0.969, train_auc: 0.988\n",
      "Missing log for fold 1: ../models/fld0_sfzn1_hd_hl512_nfnt//log_fold1.csv\n",
      "Missing log for fold 2: ../models/fld0_sfzn1_hd_hl512_nfnt//log_fold2.csv\n",
      "Missing log for fold 3: ../models/fld0_sfzn1_hd_hl512_nfnt//log_fold3.csv\n",
      "Missing log for fold 4: ../models/fld0_sfzn1_hd_hl512_nfnt//log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.969 | 0.988 | 0.641 | 0.731 | 0.011 | 0.010 | 7.00 | eca_nfnet_l0 | 32 | 7 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.032708</td>\n",
       "      <td>0.557915</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.756709</td>\n",
       "      <td>0.081041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.022330</td>\n",
       "      <td>0.825638</td>\n",
       "      <td>0.134066</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.327418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.918832</td>\n",
       "      <td>0.286971</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.946985</td>\n",
       "      <td>0.453268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.955231</td>\n",
       "      <td>0.417025</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>0.956168</td>\n",
       "      <td>0.547657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.975903</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.962901</td>\n",
       "      <td>0.590015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.011127</td>\n",
       "      <td>0.981176</td>\n",
       "      <td>0.657853</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.967887</td>\n",
       "      <td>0.620179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.988318</td>\n",
       "      <td>0.731436</td>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.969426</td>\n",
       "      <td>0.640912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000475            2.12    0.032708   0.557915   0.010418   \n",
       "1      2  0.000406            2.13    0.022330   0.825638   0.134066   \n",
       "2      3  0.000306            1.97    0.017375   0.918832   0.286971   \n",
       "3      4  0.000195            2.00    0.014762   0.955231   0.417025   \n",
       "4      5  0.000095            2.15    0.012691   0.975903   0.555336   \n",
       "5      6  0.000026            2.12    0.011127   0.981176   0.657853   \n",
       "6      7  0.000001            2.15    0.010207   0.988318   0.731436   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.027725  0.756709  0.081041  \n",
       "1  0.017998  0.924667  0.327418  \n",
       "2  0.015240  0.946985  0.453268  \n",
       "3  0.013373  0.956168  0.547657  \n",
       "4  0.012267  0.962901  0.590015  \n",
       "5  0.011535  0.967887  0.620179  \n",
       "6  0.011181  0.969426  0.640912  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir = \"../models/fld0_sfzn1_hd_hl512_nfnt//\"\n",
    "\n",
    "# „Çπ„Ç≥„Ç¢Ê†ºÁ¥çËæûÊõ∏Ôºàfold„Åî„Å®„ÅÆË®òÈå≤Ôºâ\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# ÂêÑfold„ÅÆ„Éô„Çπ„Éà„Çπ„Ç≥„Ç¢ÂèéÈõÜ\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# Âπ≥Âùá„Çπ„Ç≥„Ç¢„ÇíÊï¥ÂΩ¢Ôºà.3f„ÅßË°®Á§∫„ÄÅepoch„Å†„Åë.2fÔºâ\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv Ë™≠„ÅøËæº„Åø\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# configÊÉÖÂ†±„ÅÆÁµ±Âêà\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# MarkdownÂá∫Âäõ\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAHWCAYAAAACSaoRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWlUlEQVR4nOzde3zO9f/H8ce1s5nZDJvDMuc5zDCHyKmMySklp3xzSPwSpVbyVTlXiohQOpG+kUMkSRgSRc7nnE9zmjPD2PH6/fFp11yZY9s+27Xn/XZ733bt83l/Pp/Xdb2HvbxPFqvVakVERERERERM52R2ACIiIiIiImJQgiYiIiIiIpJNKEETERERERHJJpSgiYiIiIiIZBNK0ERERERERLIJJWgiIiIiIiLZhBI0ERERERGRbEIJmoiIiIiISDahBE1ERERERCSbUIImIiIid9WtWze8vLzMDkNExOEpQRMREVN9/fXXWCwWNm7caHYopurWrRsWiyXd4uHhYXZ4IiKSRVzMDkBEREQM7u7ufPnll7ccd3Z2NiEaERExgxI0ERGRbMLFxYX//Oc/ZochIiIm0hBHERHJEbZs2cLjjz+Ot7c3Xl5eNG7cmD///NOuTmJiIsOGDaNs2bJ4eHjg5+dHvXr1iIqKstWJiYmhe/fuFC9eHHd3d4oUKcITTzzBkSNHbvvsDz/8EIvFwtGjR285N3DgQNzc3Lh48SIA+/fvp23btgQEBODh4UHx4sXp2LEjly9fzpDPIXVI6KpVq/i///s//Pz88Pb2pkuXLrYYbvbJJ59QqVIl3N3dKVq0KH369OHSpUu31Fu3bh3NmzfH19eXvHnzUqVKFcaPH39LvRMnTtCmTRu8vLwoVKgQr7/+OsnJyRny3kRERD1oIiKSA+zatYv69evj7e3NG2+8gaurK5999hmNGjXit99+o3bt2gAMHTqUkSNH8vzzz1OrVi1iY2PZuHEjmzdvpkmTJgC0bduWXbt28dJLLxEUFMSZM2eIiooiOjqaoKCgdJ/fvn173njjDWbPnk3//v3tzs2ePZumTZvi6+tLQkICERERxMfH89JLLxEQEMCJEydYuHAhly5dIn/+/Hd9r+fOnbvlmJubG97e3nbH+vbti4+PD0OHDmXv3r18+umnHD16lJUrV2KxWGyfx7BhwwgPD6d37962ehs2bOCPP/7A1dUVgKioKFq2bEmRIkXo168fAQEB7N69m4ULF9KvXz/bM5OTk4mIiKB27dp8+OGHLFu2jDFjxlC6dGl69+591/cmIiL3wCoiImKiqVOnWgHrhg0bblunTZs2Vjc3N+vBgwdtx06ePGnNly+ftUGDBrZjoaGh1hYtWtz2PhcvXrQC1tGjR993nHXq1LGGhYXZHVu/fr0VsH7zzTdWq9Vq3bJlixWwzpkz577v37VrVyuQbomIiLDVS/28wsLCrAkJCbbjo0aNsgLWH3/80Wq1Wq1nzpyxurm5WZs2bWpNTk621Zs4caIVsE6ZMsVqtVqtSUlJ1pIlS1pLlChhvXjxol1MKSkpt8Q3fPhwuzrVqlW75XMREZEHpyGOIiKSrSUnJ7N06VLatGlDqVKlbMeLFCnCM888w++//05sbCwAPj4+7Nq1i/3796d7rzx58uDm5sbKlSvTHQ54Jx06dGDTpk0cPHjQdmzWrFm4u7vzxBNPANh6yJYsWUJcXNx93R/Aw8ODqKioW8r7779/S91evXrZesAAevfujYuLC4sWLQJg2bJlJCQk8Morr+DklPbPfc+ePfH29ubnn38GjKGjhw8f5pVXXsHHx8fuGak9cTd74YUX7L6vX78+hw4duu/3KiIi6VOCJiIi2drZs2eJi4ujfPnyt5yrUKECKSkpHDt2DIDhw4dz6dIlypUrR0hICP3792f79u22+u7u7nzwwQf88ssv+Pv706BBA0aNGkVMTMxd42jXrh1OTk7MmjULAKvVypw5c2zz4gBKlixJZGQkX375JQULFiQiIoJJkybd8/wzZ2dnwsPDbylVq1a9pW7ZsmXtvvfy8qJIkSK2uXSp8+X++bm5ublRqlQp2/nUhLNy5cp3jc/Dw4NChQrZHfP19b3vZFdERG5PCZqIiDiMBg0acPDgQaZMmULlypX58ssvqV69ut3S9a+88gr79u1j5MiReHh4MGjQICpUqMCWLVvueO+iRYtSv359Zs+eDcCff/5JdHQ0HTp0sKs3ZswYtm/fzptvvsn169d5+eWXqVSpEsePH8/4N5zFtNy/iEjmU4ImIiLZWqFChfD09GTv3r23nNuzZw9OTk4EBgbajhUoUIDu3bvz3XffcezYMapUqcLQoUPtritdujSvvfYaS5cuZefOnSQkJDBmzJi7xtKhQwe2bdvG3r17mTVrFp6enrRq1eqWeiEhIbz99tusWrWK1atXc+LECSZPnnz/b/4O/jmM8+rVq5w6dcq20EmJEiUAbvncEhISOHz4sO186dKlAdi5c2eGxiciIg9GCZqIiGRrzs7ONG3alB9//NFuKfzTp08zY8YM6tWrZxtieP78ebtrvby8KFOmDPHx8QDExcVx48YNuzqlS5cmX758tjp30rZtW5ydnfnuu++YM2cOLVu2JG/evLbzsbGxJCUl2V0TEhKCk5PTPd3/fnz++eckJibavv/0009JSkri8ccfByA8PBw3Nzc+/vhjrFarrd5XX33F5cuXadGiBQDVq1enZMmSjBs37pbl92++TkREsoaW2RcRkWxhypQpLF68+Jbj/fr145133iEqKop69erx4osv4uLiwmeffUZ8fDyjRo2y1a1YsSKNGjUiLCyMAgUKsHHjRr7//nv69u0LwL59+2jcuDHt27enYsWKuLi48MMPP3D69Gk6dux41xgLFy7Mo48+ytixY7ly5cotwxtXrFhB3759adeuHeXKlSMpKYn//e9/ODs707Zt27vePykpiW+//Tbdc08++aRdMpiQkGB7L3v37uWTTz6hXr16tG7dGjB6HgcOHMiwYcNo1qwZrVu3ttWrWbOmbUNsJycnPv30U1q1akXVqlXp3r07RYoUYc+ePezatYslS5bcNW4REclAJq8iKSIiuVzqsvG3K8eOHbNarVbr5s2brREREVYvLy+rp6en9dFHH7WuWbPG7l7vvPOOtVatWlYfHx9rnjx5rMHBwdZ3333Xthz9uXPnrH369LEGBwdb8+bNa82fP7+1du3a1tmzZ99zvF988YUVsObLl896/fp1u3OHDh2yPvfcc9bSpUtbPTw8rAUKFLA++uij1mXLlt31vndaZh+wHj582O7z+u2336y9evWy+vr6Wr28vKydO3e2nj9//pb7Tpw40RocHGx1dXW1+vv7W3v37n3LcvpWq9X6+++/W5s0aWLNly+fNW/evNYqVapYJ0yYYBdf3rx5b7luyJAhVv06ISKScSxWq8YviIiI5BRff/013bt3Z8OGDdSoUcPscEREJINpDpqIiIiIiEg2oQRNREREREQkm1CCJiIiIiIikk1oDpqIiIiIiEg2oR40ERERERGRbEIJmoiIiIiISDahjaozUUpKCidPniRfvnxYLBazwxEREREREZNYrVauXLlC0aJFcXK6fT+ZErRMdPLkSQIDA80OQ0REREREsoljx45RvHjx255XgpaJ8uXLBxiN4O3tbWosiYmJLF26lKZNm+Lq6mpqLJIx1KaOSe3qeNSmjkdt6pjUro4nu7VpbGwsgYGBthzhdpSgZaLUYY3e3t7ZIkHz9PTE29s7W/yAyr+nNnVMalfHozZ1PGpTx6R2dTzZtU3vNvVJi4SIiIiIiIhkE0rQREREREREsgklaCIiIiIiItmE5qCJiIiISK5htVpJSkoiOTnZ7nhiYiIuLi7cuHHjlnOSM2V1mzo7O+Pi4vKvt9dSgiYiIiIiuUJCQgKnTp0iLi7ulnNWq5WAgACOHTum/WsdhBlt6unpSZEiRXBzc3vgeyhBExERERGHl5KSwuHDh3F2dqZo0aK4ubnZ/dKekpLC1atX8fLyuuMmwpJzZGWbWq1WEhISOHv2LIcPH6Zs2bIP/EwlaCIiIiLi8BISEkhJSSEwMBBPT89bzqekpJCQkICHh4cSNAeR1W2aJ08eXF1dOXr0qO25D0I/fSIiIiKSayj5ksyUET9f+gkVERERERHJJpSgiYiIiIiIZBNK0EREREREcpmgoCDGjRtndhiSDiVoIiIiIiLZlMViuWMZOnToA913w4YN9OrV61/F1qhRI1555ZV/dQ+5lVZxzCUSEyE+Xvm4iIiISE5y6tQp2+tZs2YxePBg9u7dazvm5eVle221WklOTsbF5e6/4hcqVChjA5UMo9/Yc4E1a6BmTRdmzgw2OxQRERGRbMNqhWvXsr5YrfceY0BAgK3kz58fi8Vi+37Pnj3ky5ePX375hbCwMNzd3fn99985ePAgTzzxBP7+/nh5eVGzZk2WLVtmd99/DnG0WCx8+eWXPPnkk3h6elK2bFkWLFjwrz7fuXPnUqlSJdzd3QkKCmLMmDF25z/55BPKli2Lh4cH/v7+PP3007Zz33//PSEhIeTJkwc/Pz/Cw8O5du3av4onp1APWi5w4QL89ZeFvXtL89dfyYSGmh2RiIiIiPni4iCtA8oJ8MmS5169CnnzZtz9/vvf//Lhhx9SqlQpfH19OXbsGM2bN+fdd9/F3d2db775hlatWrF3714eeuih295n2LBhjBo1itGjRzNhwgQ6d+7M0aNHKVCgwH3HtGnTJtq3b8/QoUPp0KEDa9as4cUXX8TPz49u3bqxceNGXn75Zf73v/9Rt25dLly4wOrVqwGj17BTp06MGjWKJ598kitXrrB69Wqs95PZ5mBK0HKBli2hZcsUFi504pVXYMUKsFjMjkpEREREMsLw4cNp0qSJ7fsCBQoQetP/yI8YMYIffviBBQsW0Ldv39vep1u3bnTq1AmA9957j48//pj169fTrFmz+45p7NixNG7cmEGDBgFQrlw5/vrrL0aPHk23bt2Ijo4mb968tGzZknz58lGiRAmqVasGGAlaUlISTz31FCVKlAAgJCTkvmPIqTTEMZcYMyYZN7dkVq50YuZMs6MRERERMZ+np9GbdfUqxMamcPz4JWJjU2zHMqt4embs+6hRo4bd91evXuX111+nQoUK+Pj44OXlxe7du4mOjr7jfapUqWJ7nTdvXry9vTlz5swDxbR7924eeeQRu2OPPPII+/fvJzk5mSZNmlCiRAlKlSrFs88+y/Tp04mLiwMgNDSUxo0bExISQrt27fjiiy+4ePHiA8WREylByyVKloSnn94HwGuvQWysyQGJiIiImMxiMYYaZnXJ6JFMef8xXvL111/nhx9+4L333mP16tVs3bqVkJAQEhIS7ngfV1fXf3w+FlJSUjI22L/ly5ePzZs3891331GkSBEGDx5MaGgoly5dwtnZmaioKH755RcqVqzIhAkTKF++PIcPH86UWLIbJWi5SJs2ByhTxsqpU/CAK7KKiIiISDb3xx9/0K1bN5588klCQkIICAjgyJEjWRpDhQoV+OOPP26Jq1y5cjg7OwPg4uJCeHg4o0aNYvv27Rw5coQVK1YARnL4yCOPMGzYMLZs2YKbmxs//PBDlr4Hs2gOWi7i5pbCuHHJtGzpwscfQ/fukIuG84qIiIjkCmXLlmXevHm0atUKi8XCoEGDMq0n7OzZs2zdutXuWJEiRXjttdeoWbMmI0aMoEOHDqxdu5aJEyfyySefALBw4UIOHTpEgwYN8PX1ZdGiRaSkpFC+fHnWrVvH8uXLadq0KYULF2bdunWcPXuWChUqZMp7yG7Ug5bLNG1qpW1bSE6GF1+8v2VeRURERCT7Gzt2LL6+vtStW5dWrVoRERFB9erVM+VZM2bMoFq1anbliy++oHr16syePZuZM2dSuXJlBg8ezPDhw+nWrRsAPj4+zJs3j8cee4wKFSowefJkvvvuOypVqoS3tzerVq2iefPmlCtXjrfffpsxY8bw+OOPZ8p7yG7Ug5YLffQR/PIL/P47/O9/0KWL2RGJiIiIyN1069bNluAANGrUKN2l54OCgmxDBVP16dPH7vt/DnlM7z6XLl26YzwrV6684/m2bdvStm3bdM/Vq1fvttdXqFCBxYsX3/Hejkw9aLlQYCAMHmy87t8f7vJnT0REREREsogStFzq1VchOBjOnIG/t6cQERERERGTKUHLpdzcYNIk4/Unn8DmzebGIyIiIiIiStBytcceg44dISUF+vQxvoqIiIiIiHmUoOVyH34IXl7w558wdarZ0YiIiIiI5G7ZIkGbNGkSQUFBeHh4ULt2bdavX3/H+nPmzCE4OBgPDw9CQkJYtGiR3fmhQ4cSHBxM3rx58fX1JTw8nHXr1tnVuXDhAp07d8bb2xsfHx969OjB1atX7eps376d+vXr4+HhQWBgIKNGjcqYN5yNFCsGw4YZrwcMgAsXzI1HRERERCQ3Mz1BmzVrFpGRkQwZMoTNmzcTGhpKREQEZ86cSbf+mjVr6NSpEz169GDLli20adOGNm3asHPnTludcuXKMXHiRHbs2MHvv/9OUFAQTZs25ezZs7Y6nTt3ZteuXURFRbFw4UJWrVpFr169bOdjY2Np2rQpJUqUYNOmTYwePZqhQ4fy+eefZ96HYZKXXoJKleD8eXjzTbOjERERERHJvUxP0MaOHUvPnj3p3r07FStWZPLkyXh6ejJlypR0648fP55mzZrRv39/KlSowIgRI6hevToTJ0601XnmmWcIDw+nVKlSVKpUibFjxxIbG8v27dsB2L17N4sXL+bLL7+kdu3a1KtXjwkTJjBz5kxOnjwJwPTp00lISGDKlClUqlSJjh078vLLLzN27NjM/1CymKursVAIwOefw4YN5sYjIiIiIpJbmbpRdUJCAps2bWLgwIG2Y05OToSHh7N27dp0r1m7di2RkZF2xyIiIpg/f/5tn/H555+TP39+QkNDbffw8fGhRo0atnrh4eE4OTmxbt06nnzySdauXUuDBg1wc3Oze84HH3zAxYsX8fX1veVZ8fHxxMfH276PjY0FIDExkcTExLt8Gpkr9fm3i6NOHejc2Znp053o3TuF339Pxtk5KyOU+3W3NpWcSe3qeNSmjkdtmjMlJiZitVpJSUkhJZ2V0VI3ak6tIzmfGW2akpKC1WolMTER53/8Mn2vf2eYmqCdO3eO5ORk/P397Y77+/uzZ8+edK+JiYlJt35MTIzdsYULF9KxY0fi4uIoUqQIUVFRFCxY0HaPwoUL29V3cXGhQIECtvvExMRQsmTJW56Tei69BG3kyJEMS53QdZOlS5fi6emZ7vvJalFRUbc9Fx7uzg8/NGbTJldefXUHzZodybrA5IHdqU0l51K7Oh61qeNRm+YsLi4uBAQEcPXqVRISEm5b78qVK1kYVdZp2bIlISEhjBw5EoAqVarQu3dvevfufdtrfH19+fbbb2nRosW/enZG3edBZWWbJiQkcP36dVatWkVSUpLdubi4uHu6h6kJWmZ69NFH2bp1K+fOneOLL76gffv2rFu37pbELCMNHDjQrncvNjaWwMBAmjZtire3d6Y9914kJiYSFRVFkyZNcHV1vW29S5ecePVVmDWrCoMGVaRQoSwMUu7Lvbap5CxqV8ejNnU8atOc6caNGxw7dgwvLy88PDxuOW+1Wrly5Qr58uXDYrGYEGH6WrduTWJiIr/88sst51avXk2jRo3YsmULVapUueN9XFxccHNzs/1OumHDBvLmzXvXToQ8efLc8++xw4YN48cff2TzPzbYPXHiBL6+vri7u9/TfR7E119/TWRkJBduWvHOjDa9ceMGefLkoUGDBrf8nKWOrrsbUxO0ggUL4uzszOnTp+2Onz59moCAgHSvCQgIuKf6efPmpUyZMpQpU4aHH36YsmXL8tVXXzFw4EACAgJuWYQkKSmJCxcu2O5zu+eknkuPu7t7uj94rq6u2eYv8LvF0rcvTJsGW7daGDTIla++ysLg5IFkp58vyThqV8ejNnU8atOcJTk5GYvFgpOTE05Oty7DkDoELrVOdvH888/Ttm1bTp48SfHixe3OTZs2jRo1alC1atV7utfN7+2fI9Ju53af1+3un3rNzYoWLXpP1/8bqc+8+dlmtKmTkxMWiyXdvx/u9e8LU3/63NzcCAsLY/ny5bZjKSkpLF++nDp16qR7TZ06dezqgzHE4Hb1b75v6vywOnXqcOnSJTZt2mQ7v2LFClJSUqhdu7atzqpVq+zGikZFRVG+fPl0hzc6CheXtAVDpkyB20wFFBEREcn5rFZIupb15e+5UfeiZcuWFCpUiK+//tru+NWrV5kzZw49evTg/PnzdOrUiWLFiuHp6UlISAjffffdHe8bFBTEuHHjbN/v37/f1utTsWLFdIfwDhgwgHLlyuHp6UmpUqUYNGiQ7Xflr7/+mmHDhrFt2zYsFgsWi8UWs8VisVsvYseOHTz22GPkyZMHPz8/evXqZbfdVbdu3WjTpg0ffvghRYoUwc/Pjz59+vyreZ/R0dE88cQTeHl54e3tTfv27e06Y7Zt28ajjz5Kvnz58Pb2JiwsjI0bNwJw9OhRWrVqha+vL3nz5qVSpUq3bPOVkUwf4hgZGUnXrl2pUaMGtWrVYty4cVy7do3u3bsD0KVLF4oVK2YbL9uvXz8aNmzImDFjaNGiBTNnzmTjxo225e+vXbvGu+++S+vWrSlSpAjnzp1j0qRJnDhxgnbt2gFQoUIFmjVrRs+ePZk8eTKJiYn07duXjh072jL8Z555hmHDhtGjRw8GDBjAzp07GT9+PB999JEJn1LWqlMHnnvOSNBefNFY1dHF9J8UERERkQyWHAezvQCj18Inq57b/iq45L2nqi4uLnTp0oWvv/6at956y9ZLNWfOHJKTk+nUqRNXr14lLCyMAQMG4O3tzc8//8yzzz5L6dKlqVWr1l2fkZKSwlNPPYW/vz/r1q3j8uXLvPLKK7fUy5cvH19//TVFixZlx44d9OzZk3z58vHGG2/QoUMHdu7cyeLFi1m2bBkA+fPnv+Ue165dIyIigjp16rBhwwbOnDnD888/T9++fe2S0F9//ZUiRYrw66+/cuDAATp06EDVqlXp2bPnPX1u/3x/qcnZb7/9RlJSEn369KFDhw6sXLkSMLbgqlatGp9++inOzs5s3brV1uPVp08fEhISWLVqFXnz5uWvv/7Cy8vrvuO4V6b/2t2hQwfOnj3L4MGDiYmJoWrVqixevNjW7RodHW3XJVm3bl1mzJjB22+/zZtvvknZsmWZP38+lStXBsDZ2Zk9e/Ywbdo0zp07h5+fHzVr1mT16tVUqlTJdp/p06fTt29fGjdujJOTE23btuXjjz+2nc+fPz9Lly6lT58+hIWFUbBgQQYPHmy3V5oje/99+OEH2LoVPv3U2CtNRERERLLec889x+jRo/ntt99o1KgRAFOnTqVt27bkz5+f/Pnz8/rrr9vqv/TSSyxZsoTZs2ffU4K2bNky9uzZw5IlS2ydFe+99x6PP/64Xb23337b9jooKIjXX3+dmTNn8sYbb5AnTx68vLxsi7HczowZM7hx4wbffPMNefMaSerEiRNp1aoVH3zwgS0H8PX1ZeLEiTg7OxMcHEyLFi1Yvnz5AyVoy5cvZ8eOHRw+fJjAwEAAvvnmGypVqsSGDRuoWbMm0dHR9O/fn+DgYADKli1ruz46Opq2bdsSEhICQKlSpe47hvtheoIG0LdvX/r27ZvuudSs9mbt2rWz9Yb9k4eHB/PmzbvrMwsUKMCMGTPuWKdKlSqsXr36rvdyRIUKwXvvQe/e8Pbb0L493ONQZREREZGcwdnT6M3C6GWJjY3F29s78+crOd/f6t7BwcHUrVuXKVOm0KhRIw4cOMDq1asZPnw4YMyve++995g9ezYnTpwgISGB+Pj4e15FfPfu3QQGBtrNFUtv+tCsWbP4+OOPOXjwIFevXiUpKem+F8LbvXs3oaGhtuQM4JFHHiElJYW9e/faErRKlSrZLVNfpEgRduzYcV/PSrVnzx4CAwNtyRlAxYoV8fHxYffu3dSsWZPIyEief/55/ve//xEeHk67du0oXbo0AC+//DK9e/dm6dKlhIeH07Zt27suyvJvZJ8ZkJLt9OwJNWpAbCz07292NCIiIiIZzGIxhhpmdXmAFQV79OjB3LlzuXLlClOnTqV06dI0bNgQgNGjRzN+/HgGDBjAr7/+ytatW4mIiLjjdgL3a+3atXTu3JnmzZuzcOFCtmzZwltvvZWhz7jZPxfUsFgsmbqX2dChQ9m1axctWrRgxYoVVKxYkR9++AEwFmo5dOgQzz77LDt27KBGjRpMmDAh02JRgia35exsLBhiscD//gerVpkdkYiIiEju1L59e5ycnJgxYwbffPMNzz33nG0+2h9//METTzzBf/7zH0JDQylVqhT79u2753tXqFCBY8eOcerUKduxP//8067OmjVrKFGiBG+99RY1atSgbNmyHD161K6Om5sbycnJd33Wtm3buHbtmu3YH3/8gZOTE+XLl7/nmO9HcHAwx44d49ixY7Zjf/31F5cuXaJixYq2Y+XKlePVV19l6dKlPPXUU0ydOtV2LjAwkBdeeIF58+bx2muv8cUXX2RKrKAETe6iZk2jJw2gTx/4F4vniIiIiMgD8vLyokOHDgwcOJBTp07RrVs327myZcsSFRXFmjVr2L17N//3f/93y3ZRdxIeHk65cuXo2rUr27ZtY/Xq1bz11lt2dcqWLUt0dDQzZ87k4MGDfPzxx7YeplRBQUEcPnzYthdx6grqN+vcuTMeHh507dqVnTt38uuvv/LSSy/x7LPP3vPS/7eTnJzM1q1b7crevXsJDw8nJCSEzp07s3nzZtavX0+XLl1o2LAhNWrU4Pr16/Tt25eVK1dy9OhR/vjjDzZs2ECFChUAeOWVV1iyZAmHDx9m8+bN/Prrr7ZzmUEJmtzVe++Bnx/s3AmZ2JsrIiIiInfQo0cPLl68SEREhN18sbfffpvq1asTERFBo0aNCAgIoE2bNvd8XycnJ3744QeuX79OrVq1eP7553n33Xft6rRu3ZpXX32Vvn37UrVqVdasWcOgQYPs6rRt25ZmzZrx6KOPUqhQoXSX+vf09GTJkiVcuHCBmjVr8vTTT9O4cWMmTpx4fx9GOq5evUq1atVsJSwsjE6dOmGxWPjxxx/x9fWlQYMGhIeHU6pUKWbNmgUYiwyeP3+eLl26UK5cOdq3b8/jjz/OsGHDACPx69Onj20l+HLlyvFJ6r5UmcBitd7HRgxyX2JjY8mfPz+XL1++7wmUGS0xMZFFixbRvHnzB9pU86uv4PnnwcsL9u6FLNhvUO7i37apZE9qV8ejNnU8atOc6caNGxw+fJiSJUvi4eFxy/ksXSREsoQZbXqnn7N7zQ300yf3pHt3ePhhuHoVXnvN7GhERERERByTEjS5J05OMGmS8XXmTFixwuyIREREREQcjxI0uWfVqxv7ooGxYEgmraoqIiIiIpJrKUGT+/LOO1C4MOzZAx99ZHY0IiIiIiKORQma3BcfHxg92ng9fDjctJ2EiIiISLan9fEkM2XEz5cSNLlvzz4L9epBXBy8+qrZ0YiIiIjcXeqKm3FxcSZHIo4s9efr36zw6pJRwUjuYbEYC4ZUrw5z58KSJRARYXZUIiIiIrfn7OyMj48PZ86cAYz9uCwWi+18SkoKCQkJ3LhxQ8vsO4isbFOr1UpcXBxnzpzBx8cHZ2fnB76XEjR5IFWqwEsvwbhxxtcdO8Dd3eyoRERERG4vICAAwJak3cxqtXL9+nXy5Mljl7hJzmVGm/r4+Nh+zh6UEjR5YMOGwaxZsH8/fPghvPWW2RGJiIiI3J7FYqFIkSIULlyYxMREu3OJiYmsWrWKBg0aaANyB5HVberq6vqves5SKUGTB+btDWPGwDPPwLvvQufOEBRkdlQiIiIid+bs7HzLL9LOzs4kJSXh4eGhBM1B5NQ21QBb+Vc6doRHH4Xr16FfP7OjERERERHJ2ZSgyb9iscDEieDiAgsWwMKFZkckIiIiIpJzKUGTf61ixbTl9l9+2ehNExERERGR+6cETTLE4MFQvDgcPgwffGB2NCIiIiIiOZMSNMkQXl7w0UfG6/ffh4MHzY1HRERERCQnUoImGaZtW2jSBOLjjb3RrFazIxIRERERyVmUoEmGSV0wxNUVfvkFfvzR7IhERERERHIWJWiSocqVg/79jdf9+sG1a+bGIyIiIiKSkyhBkwz31ltQogRER8N775kdjYiIiIhIzqEETTKcpyeMH2+8Hj0a9u41Nx4RERERkZxCCZpkitatoXlzSEyEvn21YIiIiIiIyL1QgiaZwmKBjz8Gd3dYtgy+/97siEREREREsj8laJJpSpeG//7XeP3qq3DlirnxiIiIiIhkd0rQJFMNGAClSsGJEzBihNnRiIiIiIhkb0rQJFPlyWMMdQT46CPYtcvceEREREREsjMlaJLpWrSAJ56ApCQtGCIiIiIicidK0CRLjBtn9KatXAnffWd2NCIiIiIi2ZMSNMkSQUHGBtYAr70Gly+bGo6IiIiISLaULRK0SZMmERQUhIeHB7Vr12b9+vV3rD9nzhyCg4Px8PAgJCSERYsW2c4lJiYyYMAAQkJCyJs3L0WLFqVLly6cPHnSVmflypVYLJZ0y4YNGwA4cuRIuuf//PPPzPkQcoHXX4eyZSEmBoYONTsaEREREZHsx/QEbdasWURGRjJkyBA2b95MaGgoERERnDlzJt36a9asoVOnTvTo0YMtW7bQpk0b2rRpw86dOwGIi4tj8+bNDBo0iM2bNzNv3jz27t1L69atbfeoW7cup06dsivPP/88JUuWpEaNGnbPW7ZsmV29sLCwzPswHJy7O0ycaLyeMAG2bzc3HhERERGR7Mb0BG3s2LH07NmT7t27U7FiRSZPnoynpydTpkxJt/748eNp1qwZ/fv3p0KFCowYMYLq1asz8e/f/PPnz09UVBTt27enfPnyPPzww0ycOJFNmzYRHR0NgJubGwEBAbbi5+fHjz/+SPfu3bFYLHbP8/Pzs6vr6uqauR+Ig2vaFJ5+GpKT4cUXtWCIiIiIiMjNXMx8eEJCAps2bWLgwIG2Y05OToSHh7N27dp0r1m7di2RkZF2xyIiIpg/f/5tn3P58mUsFgs+Pj7pnl+wYAHnz5+ne/fut5xr3bo1N27coFy5crzxxht2PXH/FB8fT3x8vO372NhYwBh2mZiYeNvrskLq882OA2DUKPjlFxf++MPClClJdOmiLO1BZKc2lYyjdnU8alPHozZ1TGpXx5Pd2vRe4zA1QTt37hzJycn4+/vbHff392fPnj3pXhMTE5Nu/ZiYmHTr37hxgwEDBtCpUye8vb3TrfPVV18RERFB8eLFbce8vLwYM2YMjzzyCE5OTsydO5c2bdowf/782yZpI0eOZNiwYbccX7p0KZ6enulek9WioqLMDgGAtm3L8M03lXjttWQ8PJbj5ZU9/uDkRNmlTSVjqV0dj9rU8ahNHZPa1fFklzaNi4u7p3qmJmiZLTExkfbt22O1Wvn000/TrXP8+HGWLFnC7Nmz7Y4XLFjQrqeuZs2anDx5ktGjR982QRs4cKDdNbGxsQQGBtK0adPbJodZJTExkaioKJo0aZIthmmGh8P69Vb27HHnjz8iGD8+xeyQcpzs1qaSMdSujkdt6njUpo5J7ep4slubpo6uuxtTE7SCBQvi7OzM6dOn7Y6fPn2agICAdK8JCAi4p/qpydnRo0dZsWLFbROkqVOn4ufnd8ehi6lq1659xwzc3d0dd3f3W467urpmix8KyD6xuLrCJ5/AY4/BZ5858/zzzlSvbnZUOVN2aVPJWGpXx6M2dTxqU8ekdnU82aVN7zUGUxcJcXNzIywsjOXLl9uOpaSksHz5curUqZPuNXXq1LGrD0a35c31U5Oz/fv3s2zZMvz8/NK9l9VqZerUqXTp0uWePrCtW7dSpEiRe3lrcg8efRQ6dYKUFGPBkBR1oomIiIhILmf6EMfIyEi6du1KjRo1qFWrFuPGjePatWu2BTu6dOlCsWLFGDlyJAD9+vWjYcOGjBkzhhYtWjBz5kw2btzI559/DhjJ2dNPP83mzZtZuHAhycnJtvlpBQoUwM3NzfbsFStWcPjwYZ5//vlb4po2bRpubm5Uq1YNgHnz5jFlyhS+/PLLTP08cpsPP4SFC2HdOpgyBdJpChERERGRXMP0BK1Dhw6cPXuWwYMHExMTQ9WqVVm8eLFtIZDo6GicnNI6+urWrcuMGTN4++23efPNNylbtizz58+ncuXKAJw4cYIFCxYAULVqVbtn/frrrzRq1Mj2/VdffUXdunUJDg5ON7YRI0Zw9OhRXFxcCA4OZtasWTz99NMZ+O6laFEYNgwiI+G//4Unn4TbdHiKiIiIiDg80xM0gL59+9K3b990z61cufKWY+3ataNdu3bp1g8KCsJ6j5trzZgx47bnunbtSteuXe/pPvLvvPQSTJ0KO3bAm2/CZ5+ZHZGIiIiIiDlM36haxMUFJk0yXn/xBaxfb248IiIiIiJmUYIm2UL9+tClC1itxoIhyclmRyQiIiIikvWUoEm2MWoU5M8PmzbB32u+iIiIiIjkKkrQJNvw94d33jFev/kmnD1rbjwiIiIiIllNCZpkK717Q7VqcOkSDBhgdjQiIiIiIllLCZpkK87OaQuGTJ0Kf/xhbjwiIiIiIllJCZpkO3XqQI8exus+fSApydx4RERERESyihI0yZbefx98fWHbNvjkE7OjERERERHJGkrQJFsqWBBGjjReDxoEMTHmxiMiIiIikhWUoEm29fzzULMmxMZC//5mRyMiIiIikvmUoEm25exsDG+0WODbb+G338yOSEREREQkcylBk2ytRg34v/8zXvfpA4mJ5sYjIiIiIpKZlKBJtvfuu8actF274OOPzY5GRERERCTzKEGTbK9AAfjgA+P10KFw4oSp4YiIiIiIZBolaJIjdOtm7I929Sq89prZ0YiIiIiIZA4laJIjODkZC4Y4OcGsWbB8udkRiYiIiIhkPCVokmNUrWosFALG14QEU8MREREREclwStAkRxk+HPz9Ye9eGDvW7GhERERERDKWEjTJUXx8YPRo4/WIERAdbWo4IiIiIiIZSgma5Dj/+Q/Urw9xcfDqq2ZHIyIiIiKScZSgSY5jscCkSeDsDPPmweLFZkckIiIiIpIxlKBJjhQSAv36Ga9feglu3DA3HhERERGRjKAETXKsoUOhaFE4cCBtXpqIiIiISE6mBE1yrHz5YMwY4/V778Hhw+bGIyIiIiLybylBkxytQwd47DFjiGPqkEcRERERkZxKCZrkaBYLTJwIrq7w009GERERERHJqZSgSY5XoQJERhqv+/WD69fNjUdERERE5EEpQROH8PbbULy4MQ9t5EizoxEREREReTBK0MQheHnBuHHG6w8+MFZ2FBERERHJaZSgicN46imIiICEBGNvNKvV7IhERERERO6PEjRxGBYLTJgAbm6weDHMn292RCIiIiIi90cJmjiUsmXhjTeM1/36wbVr5sYjIiIiInI/lKCJwxk4EEqUgGPH4J13zI5GREREROTeZYsEbdKkSQQFBeHh4UHt2rVZv379HevPmTOH4OBgPDw8CAkJYdGiRbZziYmJDBgwgJCQEPLmzUvRokXp0qULJ0+etLtHUFAQFovFrrz//vt2dbZv3079+vXx8PAgMDCQUaNGZdyblkzj6Qkff2y8HjMG9uwxNx4RERERkXtleoI2a9YsIiMjGTJkCJs3byY0NJSIiAjOnDmTbv01a9bQqVMnevTowZYtW2jTpg1t2rRh586dAMTFxbF582YGDRrE5s2bmTdvHnv37qV169a33Gv48OGcOnXKVl566SXbudjYWJo2bUqJEiXYtGkTo0ePZujQoXz++eeZ80FIhmrdGlq2hMRE6NtXC4aIiIiISM5geoI2duxYevbsSffu3alYsSKTJ0/G09OTKVOmpFt//PjxNGvWjP79+1OhQgVGjBhB9erVmThxIgD58+cnKiqK9u3bU758eR5++GEmTpzIpk2biI6OtrtXvnz5CAgIsJW8efPazk2fPp2EhASmTJlCpUqV6NixIy+//DJjx47NvA9DMtT48eDhAcuXw5w5ZkcjIiIiInJ3LmY+PCEhgU2bNjFw4EDbMScnJ8LDw1m7dm2616xdu5bIyEi7YxEREcy/w5J9ly9fxmKx4OPjY3f8/fffZ8SIETz00EM888wzvPrqq7i4uNie06BBA9zc3Oye88EHH3Dx4kV8fX1veU58fDzx8fG272NjYwFj2GViYuJt48sKqc83O46sFBgIb7zhxPDhzrz6qpXw8CTy5TM7qoyTG9s0N1C7Oh61qeNRmzomtavjyW5teq9xmJqgnTt3juTkZPz9/e2O+/v7s+c2E4diYmLSrR8TE5Nu/Rs3bjBgwAA6deqEt7e37fjLL79M9erVKVCgAGvWrGHgwIGcOnXK1kMWExNDyZIlb3lO6rn0ErSRI0cybNiwW44vXboUT0/PdOPLalFRUWaHkKUqV3YiIOBRTp70okePI3Tr9pfZIWW43NamuYXa1fGoTR2P2tQxqV0dT3Zp07i4uHuqZ2qCltkSExNp3749VquVTz/91O7czb1wVapUwc3Njf/7v/9j5MiRuLu7P9DzBg4caHff2NhYAgMDadq0qV1yaIbExESioqJo0qQJrq6upsaS1Tw8LLRuDQsXlmHIkCAqVTI7ooyRm9vUkaldHY/a1PGoTR2T2tXxZLc2TR1ddzemJmgFCxbE2dmZ06dP2x0/ffo0AQEB6V4TEBBwT/VTk7OjR4+yYsWKuyZItWvXJikpiSNHjlC+fPnbPic1hvS4u7unm9y5urpmix8KyF6xZJVWreDJJ+GHHyz06+fKypXGptaOIje2aW6gdnU8alPHozZ1TGpXx5Nd2vReYzB1kRA3NzfCwsJYvny57VhKSgrLly+nTp066V5Tp04du/pgdFveXD81Odu/fz/Lli3Dz8/vrrFs3boVJycnChcubHvOqlWr7MaKRkVFUb58+XSHN0r29tFHkCcPrFoFM2aYHY2IiIiISPpMX8UxMjKSL774gmnTprF792569+7NtWvX6N69OwBdunSxW0SkX79+LF68mDFjxrBnzx6GDh3Kxo0b6du3L2AkZ08//TQbN25k+vTpJCcnExMTQ0xMDAkJCYCxAMi4cePYtm0bhw4dYvr06bz66qv85z//sSVfzzzzDG5ubvTo0YNdu3Yxa9Ysxo8ff8sCJZIzlCgBgwYZr197DS5fNjceEREREZH0mD4HrUOHDpw9e5bBgwcTExND1apVWbx4sW1BjujoaJyc0vLIunXrMmPGDN5++23efPNNypYty/z586lcuTIAJ06cYMGCBQBUrVrV7lm//vorjRo1wt3dnZkzZzJ06FDi4+MpWbIkr776ql3ylT9/fpYuXUqfPn0ICwujYMGCDB48mF69emXyJyKZJTISvv4a9u2DIUNg3DizIxIRERERsWd6ggbQt29fWw/YP61cufKWY+3ataNdu3bp1g8KCsJ6l12Jq1evzp9//nnXuKpUqcLq1avvWk9yBnd3mDQJmjSBCROge3cIDTU7KhERERGRNKYPcRTJSuHh0L49pKTAiy8aX0VEREREsgslaJLrjBkDefPCmjXwzTdmRyMiIiIikkYJmuQ6xYvD0KHG6zfegIsXTQ1HRERERMRGCZrkSv36QcWKcPYsvP222dGIiIiIiBiUoEmu5OpqLBgC8OmnsGmTufGIiIiIiIASNMnFGjWCzp3BatWCISIiIiKSPShBk1xt9Gjw9ob16+Grr8yORkRERERyOyVokqsVKQLDhxuv//tfOHfO3HhEREREJHdTgia5Xp8+UKUKXLgAb75pdjQiIiIikpspQZNcz8UFPvnEeP3ll7BunbnxiIiIiEjupQRNBHjkEejWLW3BkORksyMSERERkdxICZrI3z74AHx8YPNm+Owzs6MRERERkdxICZrI3woXhnffNV6/9RacOWNuPCIiIiKS+yhBE7nJ//0fVK8Oly7BgAFmRyMiIiIiuY0SNJGbODunLRjy9dfwxx+mhiMiIiIiuYwSNJF/qF0bnn/eeP3ii5CUZG48IiIiIpJ7KEETScfIkVCgAGzfDpMmmR2NiIiIiOQWStBE0lGwILz/vvF60CA4dcrceEREREQkd1CCJnIbPXpArVpw5Qr07292NCIiIiKSGyhBE7kNJydjwRCLBaZPh5UrzY5IRERERBydEjSROwgLgxdeMF736QOJiebGIyIiIiKOTQmayF28+y4UKgR//QXjx5sdjYiIiIg4MiVoInfh6wujRhmvhw6F48dNDUdEREREHJgSNJF70KUL1K0L167Ba6+ZHY2IiIiIOColaCL3IHXBECcnmD0bli0zOyIRERERcURK0ETuUWgo9O1rvO7TB+LjzY1HRERERByPEjSR+zB8OAQEwL59MHas2dGIiIiIiKNRgiZyH/Lnhw8/NF6PGAHR0ebGIyIiIiKORQmayH165hlo2BCuX4dXXjE7GhERERFxJErQRO6TxQKTJoGzM/zwA/zyi9kRiYiIiIijUIIm8gAqVUrrPXvpJbhxw9RwRERERMRBKEETeUBDhkDRonDwYNpG1iIiIiIi/4YSNJEHlC8ffPSR8XrkSDh0yNx4RERERCTnyxYJ2qRJkwgKCsLDw4PatWuzfv36O9afM2cOwcHBeHh4EBISwqJFi2znEhMTGTBgACEhIeTNm5eiRYvSpUsXTp48aatz5MgRevToQcmSJcmTJw+lS5dmyJAhJCQk2NWxWCy3lD///DPjPwDJsdq1g/BwY4hjv35mRyMiIiIiOZ3pCdqsWbOIjIxkyJAhbN68mdDQUCIiIjhz5ky69desWUOnTp3o0aMHW7ZsoU2bNrRp04adO3cCEBcXx+bNmxk0aBCbN29m3rx57N27l9atW9vusWfPHlJSUvjss8/YtWsXH330EZMnT+bNN9+85XnLli3j1KlTthIWFpY5H4TkSBYLTJgArq6wcCEsWGB2RCIiIiKSk5meoI0dO5aePXvSvXt3KlasyOTJk/H09GTKlCnp1h8/fjzNmjWjf//+VKhQgREjRlC9enUmTpwIQP78+YmKiqJ9+/aUL1+ehx9+mIkTJ7Jp0yai/960qlmzZkydOpWmTZtSqlQpWrduzeuvv868efNueZ6fnx8BAQG24urqmnkfhuRIwcHw2mvG65dfhrg4c+MRERERkZzLxcyHJyQksGnTJgYOHGg75uTkRHh4OGvXrk33mrVr1xIZGWl3LCIigvnz59/2OZcvX8ZiseDj43PHOgUKFLjleOvWrblx4wblypXjjTfesOuJ+6f4+Hji4+Nt38fGxgLGsMvExMTbXpcVUp9vdhyOasAAmDHDhaNHLbzzTjLDhqVk+jPVpo5J7ep41KaOR23qmNSujie7tem9xmFqgnbu3DmSk5Px9/e3O+7v78+ePXvSvSYmJibd+jExMenWv3HjBgMGDKBTp054e3unW+fAgQNMmDCBDz/80HbMy8uLMWPG8Mgjj+Dk5MTcuXNp06YN8+fPv22SNnLkSIYNG3bL8aVLl+Lp6ZnuNVktKirK7BAc1jPPFOH992sxejQEBv5G0aLXsuS5alPHpHZ1PGpTx6M2dUxqV8eTXdo07h6HWZmaoGW2xMRE2rdvj9Vq5dNPP023zokTJ2jWrBnt2rWjZ8+etuMFCxa066mrWbMmJ0+eZPTo0bdN0AYOHGh3TWxsLIGBgTRt2vS2yWFWSUxMJCoqiiZNmmiYZiZ5/HHYsiWFJUucmT//MX76KRmLJfOepzZ1TGpXx6M2dTxqU8ekdnU82a1NU0fX3Y2pCVrBggVxdnbm9OnTdsdPnz5NQEBAutcEBATcU/3U5Ozo0aOsWLEi3QTp5MmTPProo9StW5fPP//8rvHWrl37jhm4u7s77u7utxx3dXXNFj8UkL1icUQTJxqbWC9d6sRPPznRtm3mP1Nt6pjUro5Hbep41KaOSe3qeLJLm95rDKYuEuLm5kZYWBjLly+3HUtJSWH58uXUqVMn3Wvq1KljVx+Mbsub66cmZ/v372fZsmX4+fndcp8TJ07QqFEjwsLCmDp1Kk5Od/8otm7dSpEiRe717UkuVKaMMR8N4JVX4FrWjHIUEREREQdh+hDHyMhIunbtSo0aNahVqxbjxo3j2rVrdO/eHYAuXbpQrFgxRo4cCUC/fv1o2LAhY8aMoUWLFsycOZONGzfaesASExN5+umn2bx5MwsXLiQ5Odk2P61AgQK4ubnZkrMSJUrw4YcfcvbsWVs8qT1x06ZNw83NjWrVqgEwb948pkyZwpdffplln43kTAMHwrffwuHDMGIEvP++2RGJiIiISE5heoLWoUMHzp49y+DBg4mJiaFq1aosXrzYthBIdHS0Xe9W3bp1mTFjBm+//TZvvvkmZcuWZf78+VSuXBkwesYW/L0ZVdWqVe2e9euvv9KoUSOioqI4cOAABw4coHjx4nZ1rFar7fWIESM4evQoLi4uBAcHM2vWLJ5++unM+BjEgeTJAx9/DK1awZgx0LUrVKhgdlQiIiIikhOYnqAB9O3bl759+6Z7buXKlbcca9euHe3atUu3flBQkF2SlZ5u3brRrVu3O9bp2rUrXbt2vWMdkdtp2dJI0H76Cfr2hWXLyNQFQ0RERETEMZi+UbWIoxo/Hjw8YMUKmD3b7GhEREREJCdQgiaSSUqWhDffNF5HRsKVK+bGIyIiIiLZnxI0kUzUv7+xsuPJkzB0qNnRiIiIiEh2pwRNJBN5eMCECcbr8eNh505z4xERERGR7E0Jmkgma9YMnnoKkpOhTx+4yxo2IiIiIpKLKUETyQIffQSenrBqFUyfbnY0IiIiIpJdKUETyQIPPQSDBhmvX38dLl0yNRwRERERyaaUoIlkkchIKF8eTp+GwYPNjkZEREREsqMHStCOHTvG8ePHbd+vX7+eV155hc8//zzDAhNxNG5uMGmS8XrSJNi61dRwRERERCQbeqAE7ZlnnuHXX38FICYmhiZNmrB+/Xreeusthg8fnqEBijiSxo2hQwdISYEXXzS+ioiIiIikeqAEbefOndSqVQuA2bNnU7lyZdasWcP06dP5+uuvMzI+EYczZgx4ecHatTBtmtnRiIiIiEh28kAJWmJiIu7u7gAsW7aM1q1bAxAcHMypU6cyLjoRB1SsWNqm1W+8ARcumBqOiIiIiGQjD5SgVapUicmTJ7N69WqioqJo1qwZACdPnsTPzy9DAxRxRC+/DJUqwblz8NZbZkcjIiIiItnFAyVoH3zwAZ999hmNGjWiU6dOhIaGArBgwQLb0EcRuT1X17QFQz77DDZuNDceEREREckeXB7kokaNGnHu3DliY2Px9fW1He/Vqxeenp4ZFpyII2vYEP7zH/j2W2PBkLVrwdnZ7KhERERExEwP1IN2/fp14uPjbcnZ0aNHGTduHHv37qVw4cIZGqCIIxs9Gry9YcMG+Oors6MREREREbM9UIL2xBNP8M033wBw6dIlateuzZgxY2jTpg2ffvpphgYo4sgCAmDECOP1wIHGnDQRERERyb0eKEHbvHkz9evXB+D777/H39+fo0eP8s033/Dxxx9naIAiju7FFyE01FjNceBAs6MRERERETM9UIIWFxdHvnz5AFi6dClPPfUUTk5OPPzwwxw9ejRDAxRxdC4u8Mknxusvv4Q//zQ3HhERERExzwMlaGXKlGH+/PkcO3aMJUuW0LRpUwDOnDmDt7d3hgYokhvUrQvduxuvX3wRkpPNjUdEREREzPFACdrgwYN5/fXXCQoKolatWtSpUwcwetOqVauWoQGK5BYffAA+PrBlC0yebHY0IiIiImKGB0rQnn76aaKjo9m4cSNLliyxHW/cuDEfffRRhgUnGcdyZiVY1S2TnRUqBO+9Z7x+6y04fdrceEREREQk6z1QggYQEBBAtWrVOHnyJMePHwegVq1aBAcHZ1hwkkHOb8Tlt6Y0uvGakahJttWrF4SFweXLMGCA2dGIiIiISFZ7oAQtJSWF4cOHkz9/fkqUKEGJEiXw8fFhxIgRpKSkZHSM8m/FHcPq6kv+lCO4/NYUVreFq4fMjkrS4exsLBhiscC0afD772ZHJCIiIiJZ6YEStLfeeouJEyfy/vvvs2XLFrZs2cJ7773HhAkTGDRoUEbHKP9W4JMkPf4Xh1yaY7U4w7F5sLACbH0TEq+YHZ38Q61a0LOn8frFFyEpydx4RERERCTrPFCCNm3aNL788kt69+5NlSpVqFKlCi+++CJffPEFX3/9dQaHKBnC3Y8d7r1IarIBAsIhJQH+Ggk/lYND08Cqns/s5L33wM8PduyAiRPNjkZEREREssoDJWgXLlxId65ZcHAwFy5c+NdBSSbKXxkeXQoNfgSv0nAjBv7sBksehrNrzY5O/ubnB++/b7wePBhOnjQ3HhERERHJGg+UoIWGhjIxnf/WnzhxIlWqVPnXQUkms1igeGtosQuqjgKXfHBhA0TVhT86Q9xxsyMU4LnnoHZtuHIF+vc3OxoRERERyQouD3LRqFGjaNGiBcuWLbPtgbZ27VqOHTvGokWLMjRAyUTO7lCxP5TsAtvfgoNT4OgMOD4fKg6ACq+Di6fZUeZaTk7GgiE1a8KMGfD88/Doo2ZHJSIiIiKZ6YF60Bo2bMi+fft48sknuXTpEpcuXeKpp55i165d/O9//8voGCWz5fGH2l9Cs41QqB4kx8GOIcZCIkdngdVqdoS5VvXq0Lu38bpPH0hIMDceEREREclcD7wPWtGiRXn33XeZO3cuc+fO5Z133uHixYt89dVXGRmfZKUC1SF8FTwyEzwfgrho+KMjLGsAFzaZHV2u9c47xibWu3fD+PFmRyMiIiIimemBEzRxUBYLlOgALfdAyHBwzgNnf4fFNWHd83D9tNkR5jo+PjB6tPF62DA4rimCIiIiIg5LCZqkzyUPhAyCVvsgqDNghYNfwU9l4a9RkBxvdoS5SpcuUK8eXLsGkZFmRyMiIiIimSVbJGiTJk0iKCgIDw8Pateuzfr16+9Yf86cOQQHB+Ph4UFISIjdwiSJiYkMGDCAkJAQ8ubNS9GiRenSpQsn/7FO+YULF+jcuTPe3t74+PjQo0cPrl69aldn+/bt1K9fHw8PDwIDAxk1alTGvemcwrM41P0WmqyBAjUh6QpsHQA/V4LjP2p+WhaxWGDSJHB2hjlzYOlSsyMSERERkcxwX6s4PvXUU3c8f+nSpfsOYNasWURGRjJ58mRq167NuHHjiIiIYO/evRQuXPiW+mvWrKFTp06MHDmSli1bMmPGDNq0acPmzZupXLkycXFxbN68mUGDBhEaGsrFixfp168frVu3ZuPGjbb7dO7cmVOnThEVFUViYiLdu3enV69ezJgxA4DY2FiaNm1KeHg4kydPZseOHTz33HP4+PjQq1ev+36fOV6hOhDxJxz+H2z9L1w9CKvaGJteV/8IfCqbHaHDq1IFXnoJxo0zvm7StEARERERh3NfPWj58+e/YylRogRdunS5rwDGjh1Lz5496d69OxUrVmTy5Ml4enoyZcqUdOuPHz+eZs2a0b9/fypUqMCIESOoXr26bV+2/PnzExUVRfv27SlfvjwPP/wwEydOZNOmTURHRwOwe/duFi9ezJdffknt2rWpV68eEyZMYObMmbaetunTp5OQkMCUKVOoVKkSHTt25OWXX2bs2LH39f4cisUJSnU1hj1WHAhO7hCzDH4JhQ19If682RE6vGHDICAA9u2Djz7KFh3gIiIiIpKB7qsHberUqRn68ISEBDZt2sTAgQNtx5ycnAgPD2ft2rXpXrN27Voi/zEJJyIigvnz59/2OZcvX8ZiseDj42O7h4+PDzVq1LDVCQ8Px8nJiXXr1vHkk0+ydu1aGjRogJubm91zPvjgAy5evIivr+8tz4mPjyc+Pm1uVmxsLGAMu0xMTLz9B5EFUp+fMXF4QKVhUKIrztv/i9OJ+bB/EtYjM0ipNJiU0r3AyTUDniP/lCcPfPCBha5dXRg50olx4/KY/rMlGStj/6xKdqA2dTxqU8ekdnU82a1N7zWOB9qoOqOcO3eO5ORk/P397Y77+/uzZ8+edK+JiYlJt35MTEy69W/cuMGAAQPo1KkT3t7etnv8c/iki4sLBQoUsN0nJiaGkiVL3vKc1HPpJWgjR45k2LBhtxxfunQpnp7ZY8PnqKioDL5jNwp6hFE54SvyJx7BeeurxG0bww63Hpx1qZbBzxIAb2+oXLkuO3cW4ssvQ/DzW4aLi+YCOpqM/7MqZlObOh61qWNSuzqe7NKmcXFx91TP1AQtsyUmJtK+fXusViuffvpppj9v4MCBdr17sbGxBAYG0rRpU1tyaJbExESioqJo0qQJrq4Z3bvVHKyvk3xoCk47h5Av4Th144eRUqA5yaGjIF+5DH6elCwJNWpY2bChCH37tqR7dys9eqTw0ENmRyb/Vub+WRUzqE0dj9rUMaldHU92a9PU0XV3Y2qCVrBgQZydnTl92n5vrdOnTxMQEJDuNQEBAfdUPzU5O3r0KCtWrLBLkAICAjhz5oxd/aSkJC5cuGC7z+2ek3ouPe7u7ri7u99y3NXVNVv8UEBmxuIKwS9CqWdgx3DYNwGnU4twOh0F5V6GyoPALX8mPDd3Cg2FyZOTeO21JGJiPBg5Ej74wJnHH4cXXoDHHzdWfJScKzv9vSEZQ23qeNSmjknt6niyS5veawymrjLg5uZGWFgYy5cvtx1LSUlh+fLl1KlTJ91r6tSpY1cfjG7Lm+unJmf79+9n2bJl+Pn53XKPS5cusemmZfBWrFhBSkoKtWvXttVZtWqV3VjRqKgoypcvn+7wRvmbmw+EjYXmO6Boc0hJhD1jjP3TDnwBKclmR+gwunSx8uWXS5kxI4nHHoOUFPj5Z2jVyuhhGzEC/rG7hIiIiIhkc6YvAxcZGckXX3zBtGnT2L17N7179+batWt0794dgC5dutgtItKvXz8WL17MmDFj2LNnD0OHDmXjxo307dsXMJKzp59+mo0bNzJ9+nSSk5OJiYkhJiaGhIQEACpUqECzZs3o2bMn69ev548//qBv37507NiRokWLAvDMM8/g5uZGjx492LVrF7NmzWL8+PG3LFAit5E/GBr9DI0WgXd5iD8L63vBkhpwZpXZ0TkMV1crTz9tZfly2LsXXnsN/Pzg2DEYPBgeegieegqWLDESOBERERHJ3kxP0Dp06MCHH37I4MGDqVq1Klu3bmXx4sW2BTmio6M5deqUrX7dunWZMWMGn3/+OaGhoXz//ffMnz+fypWNfbhOnDjBggULOH78OFWrVqVIkSK2smbNGtt9pk+fTnBwMI0bN6Z58+bUq1ePzz//3HY+f/78LF26lMOHDxMWFsZrr73G4MGDc+ceaP9G0ceN3rTq48DVBy5uhWUNYXU7uHrE3NgcTLly8OGHcPw4fPst1K8Pycnwww/QrBmULQvvvw//GLkrIiIiItlItlgkpG/fvrYesH9auXLlLcfatWtHu3bt0q0fFBSE1Xr3Fe0KFChg25T6dqpUqcLq1avvei+5CydXCO4HQZ1hx2A48Bkc+x5O/AQVXoeK/wVXL7OjdBgeHtC5s1F27YLPP4dp0+DQIRg40OhZe/JJY65ao0ZgsZgdsYiIiIikMr0HTXIRj4JQ8xNotgX8H4WUeNj1LiwsD4f/B1aNwctolSrB+PHGXLSpU6F2bUhMhNmz4bHHIDgYxo6F89pjXERERCRbUIImWc+3Cjy2HOrPA69ScP0krO0CS+vCuXVmR+eQPD2hWzf480/YssXoPfPygn37jHlrxYrBs8/CH3/APXRAi4iIiEgmUYIm5rBYIPBJaLELQkeCixecXwdLH4Y1z0LcCbMjdFhVq8Knnxq9ap99BtWqQXy8MW+tXj0ICYGJE+HSJbMjFREREcl9lKCJuZw9oNJ/odU+KNXNOHbkW/ipHOx8B5KumxqeI8uXD3r1gk2bYP16eO45yJPHmLf20ktQtCj06GGcU6+aiIiISNZQgibZQ54i8PBUiNgABetCchxsHwQ/V4Do75UhZCKLBWrWhK++MnrVJkyAypXh+nWYMsWYtxYWZvS2XblidrQiIiIijk0JmmQvfjWgye9QdwZ4FodrR+H3drC8kbFEv2QqHx/o2xe2b4fffzfmpbm7p81bK1rU+Lp1q9mRioiIiDgmJWiS/VgsENQJWu6BykPAOY+xufUv1WFdL7hxxuwIHZ7FAo88At98AydOGCs9lisHV6+mzVurXdtYGTIuzuxoRURERByHEjTJvlzyQpWhRqJWoiNghYNfwE9lYfcYSE4wO8Jcwc8PXn0V9uyBX3+FDh3A1TVt3lrRovDyy8bcNRERERH5d5SgSfaX9yF45DsIXw0FwiAxFra8Dosqw4mFmp+WRSwWY2PrmTPh+HF4/30oWRIuX06bt1a/PkyfDjdumB2tiIiISM6kBE1yjsL1IGI91J4CHv5wZT/81gp+bQaX/zI7ulylcGEYMAAOHIAlS+DJJ8HZ2Zi39p//QPHi8Prrxj5rIiIiInLvlKBJzmJxgtLdjWX5Kw4AJzeIWQqLqsDGlyH+gtkR5ipOTtC0KcybB9HRMHw4BAbC+fMwZgyULw+NG8Ps2ZCgEakiIiIid6UETXImV2+o+j60+AuKtwFrMuybYMxP2zcJUpLMjjDXKVoUBg2Cw4fhp5+gZUtjWOSKFca8tcBAGDjQOC8iIiIi6VOCJjlbvtLQ4Ad4bBnkrwwJF2BjX/ilKsQsMzu6XMnZ2UjOfvoJjhwxkrYiReDMGWPeWunS0KwZzJ8PScqjRUREROwoQRPHENAYHt8CNSaBux9c3gUrmsBvT8CVA2ZHl2s99JAx7PHoUWMYZNOmxpouqfPWSpSAIUPg2DGzIxURERHJHpSgieNwcoFyL0Kr/VC+H1ic4cQC+LkibBlgrP4opnB1NRKyJUuMhUUGDIBCheDkSSOBCwqC1q3h558hOdnsaEVERETMowRNHI+bL4SNg+bboUgEpCTC7lHwUzk4+BWkKAMwU+nSxlDHY8eMJfsbNYKUlLR5a6VKwTvvwKlTZkcqIiIikvWUoInjyl8RGv0CDRdCvnJw4zSsex6W1IIzv5sdXa7n7m4sHvLrr7B7t7EZtq+vsRrkoEHG8Mi2bSEqykjgRERERHIDJWji2CwWKNYCmu+AamOM1R8vboZl9eH3jnAt2uwIBQgOhrFj4cQJ+OYbeOQRYwGR1Hlr5crBqFFw9qzZkYqIiIhkLiVokjs4u0GFSGN+WplegAWiZ8HC8rB9CCRdMztCAfLkgWefNTa83rED+vYFb284eNCYt1asGHTqBL/9Ziw2IiIiIuJolKBJ7uJRGGp9Bo9vhsINIfkG7BwOP5WHIzP0W382UrkyTJhgLCTy1VdQsyYkJqbNW6tYEcaNgwvam1xEREQciBI0yZ18q0LjX6He95A3CK6fgDWdIeoROL/B7OjkJnnzwnPPwfr1sGkT9OplHNuzx5i3VqwYdO0Ka9YovxYREZGcTwma5F4WCzzUFlruhtB3wSUvnFtrLCKythtc1zKC2U316vDZZ0av2qefQmgo3LiRNm8tNBQmTYLLl82OVEREROTBKEETcfaASm9Cy31Qsotx7PA0Y1n+XSONYZCSrXh7wwsvwJYtsHYtdOsGHh5p89aKFoXnn4eNG82OVEREROT+KEETSeVZFOpMg6Z/gt/DkHQVtr0JCyvCsXkaP5cNWSzw8MMwdarRqzZ+PFSoAHFxafPWwsLgiy/g6lWzoxURERG5OyVoIv9UsDY0/QPqfAt5isK1w7C6LSx/DC5uMzs6uQ1fX3j5Zdi1C1atgmeeATc32LzZmLdWtCi8+CJsUxOKiIhINqYETSQ9Fico2Rla7oVKbxvDIM+shMXVYf0LcEMbcmVXFgvUrw/Tpxv7qo0eDWXKwJUrxry1qlWhTh2YNg2uXzc7WhERERF7StBE7sTVC0JHQIvd8FA7sKbAgc/gp7Kw5yNITjA7QrmDggXh9ddh715YtgzatQMXF/jzT2PeWtGi8MorsHu32ZGKiIiIGJSgidwLryCoNxvCfwPfapB4GTZHwi9V4MQis6OTu3BygsaNYfZsOHYM3nsPgoLg0iVj3lrFitCwIcyYAfHxZkcrIiIiuZkSNJH7UbgBRGyAWl8Ym17H7oXfWsCvzeHyHrOjk3sQEAADB8KBA7BoETzxhJHArVoFnTtD8eLQvz/s3292pCIiIpIbKUETuV9OzlDmeWNZ/gqvg5MrnPoFFoXAplcg4aLZEco9cHaGxx+H+fPh6FEYOtTY9PrcOfjwQyhXDsLD4fvvITHR7GhFREQkt1CCJvKg3PJDtdHQfBcUawXWJNg73piftn8ypCSZHaHco+LFYcgQOHIEfvzRSNwsFli+3Ji3FhgIb71lnBcRERHJTErQRP4t77LQcAE8ugTyV4T487Cht7HiY8wKs6OT++DiAq1bG0MfDx2CN98Ef384fdqYt1aqFDRvDgsWQJLybxEREckEStBEMkqRpvD4NgibAG6+cGkHrGgMq56Cq4fMjk7uU1AQvPuusajInDnGcEerFX75xZi3FhQEw4bB8eNmRyoiIiKOxPQEbdKkSQQFBeHh4UHt2rVZv379HevPmTOH4OBgPDw8CAkJYdEi+xX05s2bR9OmTfHz88NisbB161a780eOHMFisaRb5syZY6uX3vmZM2dm2PsWB+XkAuX7Qqv9UK4vWJzh+A+wsAJsHQiJV8yOUO6Tqys8/TRERcG+fcYCIn5+xh5rQ4dCiRLQpo2RuCUnmx2tiIiI5HSmJmizZs0iMjKSIUOGsHnzZkJDQ4mIiODMmTPp1l+zZg2dOnWiR48ebNmyhTZt2tCmTRt27txpq3Pt2jXq1avHBx98kO49AgMDOXXqlF0ZNmwYXl5ePP7443Z1p06dalevTZs2GfbexcG5+0GNCUaPWkATSEmAv96Hn8rBoa+N/dQkxylbFkaNMpKz6dOhQQNISTHmrTVvbmyI/d57EBNjdqQiIiKSU5maoI0dO5aePXvSvXt3KlasyOTJk/H09GTKlCnp1h8/fjzNmjWjf//+VKhQgREjRlC9enUmTpxoq/Pss88yePBgwsPD072Hs7MzAQEBduWHH36gffv2eHl52dX18fGxq+fh4ZFxb15yB59Kxty0Bj+CVxm4EQN/doclteHsGrOjkwfk7g7PPAO//Qa7dkG/fuDjYywi8tZbxqIi7doZi4ykKBcXERGR++Bi1oMTEhLYtGkTAwcOtB1zcnIiPDyctWvXpnvN2rVriYyMtDsWERHB/PnzHziOTZs2sXXrViZNmnTLuT59+vD8889TqlQpXnjhBbp3747FYrntveLj44m/aZfb2NhYABITE0k0eZ3u1OebHUeu5f84NH0MpwMTcfrrPSwXNkLUI6QEdiC5ynvgGXjft1SbZg9ly8Lo0cZ8tO+/t/DFF06sW+fE998bS/SXKWPl+edT6NIlhYIF734/tavjUZs6HrWpY1K7Op7s1qb3GodpCdq5c+dITk7G39/f7ri/vz979qS/4W9MTEy69WP+xXiir776igoVKlC3bl2748OHD+exxx7D09OTpUuX8uKLL3L16lVefvnl295r5MiRDBs27JbjS5cuxdPT84FjzEhRUVFmh5DLVcDdbQLBTKdE0jKcjs0i5dgPHHB9igOuT5Jscb/vO6pNs4+CBY1NsA8f9mbJkiB++604Bw648t//OvP221C37kkiIo5QseIF7vB/PYDa1RGpTR2P2tQxqV0dT3Zp07i4uHuqZ1qClh1cv36dGTNmMGjQoFvO3XysWrVqXLt2jdGjR98xQRs4cKBdD19sbCyBgYE0bdoUb2/vjA3+PiUmJhIVFUWTJk1wdXU1NRYBeIaki1tw3voaLud+JzhxJuVd/iA55D2sge2562/vqE2zuz594OpVmDUric8/d2bLFmdWrQpk1apAgoOt9OqVQufOKfj62l+ndnU8alPHozZ1TGpXx5Pd2jR1dN3dmJagFSxYEGdnZ06fPm13/PTp0wQEBKR7TUBAwH3Vv5vvv/+euLg4unTpcte6tWvXZsSIEcTHx+Punn4vh7u7e7rnXF1ds8UPBWSvWHK9wrWgySqIngNb+mOJi8Zl3bNwaDKEjYcCYfd0G7Vp9uXrCy+8YJSNG+Gzz2DGDNizx0JkpDNvvulMx47wf/8HtWvb5+VqV8ejNnU8alPHpHZ1PNmlTe81BtMWCXFzcyMsLIzly5fbjqWkpLB8+XLq1KmT7jV16tSxqw9Gl+Xt6t/NV199RevWrSlUqNBd627duhVfX9/bJmciD8RigRLtoeUeCBkOzp5w9g9YXBP+fA6uazlAR1GjBnzxBZw8CRMnQkgI3LgBX38NdepAtWrw6adwj/+5JiIiIg7K1CGOkZGRdO3alRo1alCrVi3GjRvHtWvX6N69OwBdunShWLFijBw5EoB+/frRsGFDxowZQ4sWLZg5cyYbN27k888/t93zwoULREdHc/LkSQD27t0LYFuJMdWBAwdYtWrVLfuoAfz000+cPn2ahx9+GA8PD6Kionjvvfd4/fXXM+2zkFzOJQ+EDILS3WHrf+HIdDg0FaK/h8pvQflXwFn/OeAI8uc3hj+++CKsXWv0qs2aBdu2Gcf693chLKw68fEWWraEbDJ9VURERLKIqcvsd+jQgQ8//JDBgwdTtWpVtm7dyuLFi20LgURHR3Pq1Clb/bp16zJjxgw+//xzQkND+f7775k/fz6VK1e21VmwYAHVqlWjRYsWAHTs2JFq1aoxefJku2dPmTKF4sWL07Rp01vicnV1ZdKkSdSpU4eqVavy2WefMXbsWIYMGZIZH4NIGs/iUPdbaLIGCtSEpCtGwvZzJTg2H6xWsyOUDGKxQN26MG2a0av20UdQvjxcu2Zh1apAOnRwoVAhY7n+mTPhivY4FxERyRUsVqt+48sssbGx5M+fn8uXL2eLRUIWLVpE8+bNs8UYXLkH1hQ4/C1s+y9c//s/KvwbQ9g48KmsNnVAViusXp3EmDFH2Lq1NNHRaZPS3N0hIgLatoVWrbhlcRHJvvRn1fGoTR2T2tXxZLc2vdfcwNQeNBG5A4sTlOoCLfdBpTfByR1OL4dfQmFDH4g/Z3aEksEsFqhTx8pzz+1i//4kNmyA//4XypSB+HhYsAC6doXCheHxx+HLL+HsWbOjFhERkYykBE0ku3P1gtB3oeVuCGxr9Kzt/wSXXypSJuEHiDtmdoSSCSwWY2GRkSNh3z5jjtrgwVCpEiQlweLF0LMnBATAY4/BJ5/ATSPCRUREJIdSgiaSU3iVhPrfQ+NfwacKlsRLVEqchuvPpWFRKGx9E86ugZRksyOVDGaxQJUqMGwY7NwJu3fDO+8YKz+mpMCvvxoLjxQrBvXqGfPZoqPNjlpEREQehBI0kZzGvxE020xS2GTOO1XAihNc2g5/jYSoR+AHf1jzLByZCQkXzY5WMkFwMLz1FmzeDAcPwqhRxj5qViv88QdERkKJElCrFnzwARw4YHbEIiIicq+UoInkRE7OWEs9x+95RpLU+gTU+RZKdARXH4g/D0e+hTWdYG4hWNYQ/hoFl//SKpAOqFQp6N8f/vzT6DUbPx4aNDB63VLnsJUtC1WrwogR8NdfZkcsIiIid6IETSSnc/eDkp3hke+g7VkIXwUV3oD8lcCaDGdWwdYBxlL9C0rBxpfg5GJIvmF25JLBAgPh5Zfht9+Mpfs//RTCw8HZ2X4OW4UKMGgQbN2qnF1ERCS7UYIm4kicXKBwfaj2AbTYCa0PQ42JUORxYxXIa0dg30RY+Th87we/PQEHPoe4E2ZHLhksIABeeAGiouD0afjqK2jeHFxdYc+etDlsZcrAgAGwfr2SNRERkexACZqII/MKgnJ94NFF8PR5aLAAyvwf5CkGyXFwYgGs/z+YXxx+qQbb3oZzf2qhEQfj5wfPPQc//wxnzsD//gdt2oCHBxw6lDaHrUQJeOUV+P13Y/ERERERyXpK0ERyC5e8ULwV1JoMbY7B41uhyjtQsA5ggYtbYde7sLQO/BAAa7vC0dmQcMncuCVD+fjAf/4DP/xg7KE2eza0bw9588KxY8Yctvr1jRUhX3wRli83lvUXERGRrOFidgAiYgKLBXxDjVL5LbhxFk4thhM/G1/jz8Hhb4xicYFC9aBYCyjaErzLG9dLjuflBe3aGeX6dVi6FObONTbEjokx5rB9+qnRA9emDbRtC40bg5ub2ZGLiIg4LiVoIgIehaDks0ZJSTT2Uzu50EjYYnfDmZVG2dIfvEpB0RZQrCUUbgjO7mZHLxkgTx544gmjJCQYPWdz58L8+XD+vDGH7auvIH9+aN3aSNaaNjWuExERkYyjIY4iYs/JFfwbQrXR0PIvaH0Qwj6GIhHg5AZXD8G+CfBrBMz1g1VPwoEvIe6k2ZFLBnFzg8cfhy+/NHrSli2D3r2NhUcuX06bw1aoEHTsCHPmwNWrZkctIiLiGJSgicideZWC8i/Bo4uh7XloMB9K94Q8RSHpGhyfD+t7wvxi8EsYbB8M59aDVatMOAIXF2NY4yefwPHjsHo19OtnLOl/7RrMmmXMYStUCJ58Er791kjiRERE5MFoiKOI3DtXLyj+hFGsVmNhkRML4eTPcH49XNxslJ0jwKOwsbx/sZZQpCm4epsdvfxLzs5Qr55RPvrI2Ah77lz4/ntjNcj5843i6gpNmhjDIJ94wpjDJiIiIvdGPWgi8mAsFihQDUIGQcSf8FQMPPw1PNTOSMZunIHD0+D3dsaea8sbw+6xELvP7MglA1gsUKsWfPABHDgAW7bA228bm2AnJsKiRdCjB/j7G8na5MnGfmwiIiJyZ0rQRCRjeBSGUl2h3mxoew4ar4DgSGPVR2sSnF4BW16DheVhQVnY9ArELIPkBLMjl3/JYoGqVWHECPjrL9i1C4YPh9BQSE5Om8NWpAg0bAgff2wMlxQREZFbKUETkYzn5Ar+j0L1MdByD7TaD9XHQUAT49zVA7B3PKxoYiw0srotHJwC12PMjlwyQMWKMGgQbN0K+/fD++9DzZrGqNhVq9LmsD38MHz4IRw+bHbEIiIi2YcSNBHJfPnKQHA/eGypsdBI/XlQ6jnwCICkq3BsHqzrAT8UgcU1YftQOL9BC404gDJlYMAAWL8ejh415q498ojR67ZuHfTvD6VKQfXq8O67sHev2RGLiIiYSwmaiGQt13wQ+CQ8/BU8eQKabYSQoVCgpnH+wkbYOQyW1IIfisKfzxkJXOIVU8OWf++hh+CVV+D33+HECZg0CR59FJyc0uawBQdD5cowZAjs2GH0uomIiOQmStBExDwWJygQBiFDoNl6ePIU1J4CgW3BxQtunIZDU40hkHP9YHk47BkHsfvNjlz+pSJF4MUXYcUKY6+1L76AZs2MFSBT57BVqQLly8PAgbBxo5I1ERHJHZSgiUj2kScASneH+t8bQyEfWwblX4F8ZSElEU4vh82vwsJy8FN52BQJMSu00EgOV6gQPP88/PKLsdLjtGnQujW4u9vPYStZEl57DdasgRSNfhUREQelBE1EsidnNwhoDGEfQat90HIvVB8L/o2NhUau7IO9H8GKxjC3IKx+Gg59Dde1lntO5usLXbrAjz/C2bMwcyY8/TR4ehpz2MaONeawBQbCSy/BypXGSpEiIiKOQhtVi0jO4F3OKMGvQmIsnIoyNsg++bOx59qxuUYB8KsFRVtAsRbgW80YSik5Tr580KGDUeLiYMkSY2PsBQvg5EmYONEohQpBmzZGIvfoo8YwSRERkZxKCZqI5Dyu3vBQW6NYU+DCJjix0EjWLmyC8+uNsmMI5CkCRZtD0ZYQEA6uXmZHLw/A0xOefNIo8fHG3mpz58L8+UZP2xdfGMXX1xge2batsUG2h4fZkYuIiNwf/beyiORsFifwqwlVhhkrQj55Emp/CcWfBJe8cP0UHPwKVj9pLDSyoins/RiuHDQ7cnlA7u7QogVMmWLMWVu6FP7v/6BwYbh4MW0OW+HC8MwzRiIXF2d21CIiIvdGCZqIOJY8RaB0D2gwz1ho5NGlUL4feJWGlASIiYJN/eCnMrCwAmx+HU7/aixCIjmOq6vRUzZ5sjHsceVKY25asWJw5Qp8950x9LFgQePrd99BbKzZUYuIiNyeEjQRcVzO7lCkCYSNg1b7oeUeqPYh+D8KFheI3QN7xsDyx4yFRn5vD4e+gRtnzY5cHoCzMzRsCB9/DNHRsHYtvP46BAXB9etGT9ozzxhz1lq3NnraLl40O2oRERF7moMmIrmDxQLe5Y1S4TVIuAwxS+HEz3ByEcSfheg5RsFiLDRSrKWx2IhvVeN6yTGcnODhh40yapSxEfbcufD997BvH/z0k1FcXOCxx4zetTZtjORNRETETOpBE5HcyS0/PNQO6nwNT8VA0z+h0tvGqo9Y4fw62D4IFleH+YGwrhcc/xGSrpkdudwniwWqV4d334U9e2DHDhg6FEJCICnJmMPWqxcEBBirQE6caAyXFBERMYMSNBERixMUrA2hI+DxzdDmONT6HIo/Ac6ecP0EHPwCVrWB7/3g12awdyJcPWx25HKfLBaoXBmGDIHt22HvXnjvPQgLMza/vnkO2yOPGPuuHT1qdtQiIpKbKEETEfknz2JQpic0mA9Pn4dGi6HcS5C3JKTEw6klsOklWFAKfq4EW96A079poZEcqFw5GDgQNm6EQ4fgww+hTh3j3Jo18Nprxhy2mjXh/fdh/35TwxURkVxACZqIyJ04e0DRCKjxMbQ+CC3+gqqjoHBDsDjD5b9g92hY3gjmFobfO8Lhb+HGObMjl/tUsqSRkK1ZA8ePw4QJ0KiRMZ9t40YjkStXDkJDYfhw2LULrFazoxYREUejRUJERO6VxQL5KxilYn9IuAin/l5o5NQiiD8P0bOMggUKPpy20IhPFS00koMUKwZ9+xrlzBljQ+y5c2HFCmNo5PbtxjDJ8uWNBUbatoWqVdXEIiLy75negzZp0iSCgoLw8PCgdu3arF+//o7158yZQ3BwMB4eHoSEhLBo0SK78/PmzaNp06b4+flhsVjYunXrLfdo1KgRFovFrrzwwgt2daKjo2nRogWenp4ULlyY/v37k5SU9K/fr4g4EDdfKNEB6n4DT56GJmug0pvgEwpY4dxa2PYW/FIVfnwI1r8Ax3+CJO2anJMULmwsIrJkibEx9tSp0LIluLkZc9jefddYhKR0aejfH/7805jPJiIi8iBMTdBmzZpFZGQkQ4YMYfPmzYSGhhIREcGZM2fSrb9mzRo6depEjx492LJlC23atKFNmzbs3LnTVufatWvUq1ePDz744I7P7tmzJ6dOnbKVUaNG2c4lJyfTokULEhISWLNmDdOmTePrr79m8ODBGfPGRcTxODlDoToQ+i403wpPREPNyVCsFTjngbjjcOAzWNUa5vrBr81h3yS4esTsyOU+FCgA3boZS/SfPQvTp8NTT0GePHD4cNocthIloF8/WLUKkpPNjlpERHISUxO0sWPH0rNnT7p3707FihWZPHkynp6eTJkyJd3648ePp1mzZvTv358KFSowYsQIqlevzsSJE211nn32WQYPHkx4ePgdn+3p6UlAQICteHt7284tXbqUv/76i2+//ZaqVavy+OOPM2LECCZNmkRCQkLGvHkRcWx5A6Hs/0HDBdD2PDRaBGVfhLwlIPkGnPoFNvaFBSXh58qw9b9wZjWkqKc+p/D2Nja+njvXSNa+/x46dgQvL2MO28cfGxtnBwW5MHFiVaZPt3DsmNlRi4hIdmfaHLSEhAQ2bdrEwIEDbcecnJwIDw9n7dq16V6zdu1aIiMj7Y5FREQwf/78+37+9OnT+fbbbwkICKBVq1YMGjQIT09P23NCQkLw9/e3e07v3r3ZtWsX1apVS/ee8fHxxMfH276PjY0FIDExkcREc1d3S32+2XFIxlGb5iQuUCjcKKEfQexfOJ1ahOXUL1jOrcFyeRdc3gV/fYCLqy+1U0rB9nUkFayJ1TcM8hQx+w3IXbi5QevWRrlxA5Yts/DDD0789JOF06ctnD5dgmXLjLqlSlmpX99K/fopNGxopUQJc2OX+6e/fx2T2tXxZLc2vdc4TEvQzp07R3Jysl0SBODv78+ePXvSvSYmJibd+jExMff17GeeeYYSJUpQtGhRtm/fzoABA9i7dy/z5s2743NSz93OyJEjGTZs2C3Hly5dakv+zBYVFWV2CJLB1KY5VSWgEq6eVyicvAX/pE34J2/GLfEiAWyCvZtgr1HzuqUAl5xKc8mpjPHVuQwJFh8zg5e7cHIyFg5p3drCzp0F2batELt2FeTgQR8OHbJw6JCFadOMQSyFCsVRufI5Klc+T6VK5/D3j9NiIzmE/v51TGpXx5Nd2jQu7t7moOfKVRx79eplex0SEkKRIkVo3LgxBw8epHTp0g9834EDB9r18MXGxhIYGEjTpk3thlCaITExkaioKJo0aYKrq6upsUjGUJs6kg7GF2syN86uZ9/a6VQMiMP50haI3U0e6wXyJF+gSPIG2xXWPIFYC1TH6hv2d6kO7n4mxS930rx52p/V69eTWLPGwqpVFlavtrBxo4WzZz359deH+PXXhwAoXtxKgwZWGjRIoX59K2XKaHXI7EZ//zomtavjyW5tmjq67m5MS9AKFiyIs7Mzp0+ftjt++vRpAgIC0r0mICDgvurfq9q1awNw4MABSpcuTUBAwC2rSaY+907Pcnd3x93d/Zbjrq6u2eKHArJXLJIx1KaOxBUK1+Gw60Uq1G6OxdUVkq7Bxa1wfiNc+LvE7sVy/RiWE8fgxI9pl+ctCX41oEAYFPj7q5uPWW9G/sHV1RVPT1datYJWrYxjV68a+6799husXAkbNsDx4xZmzLAwY4bRw1akiLEfW8OGRilfXglbdqG/fx2T2tXxZJc2vdcYTEvQ3NzcCAsLY/ny5bRp0waAlJQUli9fTt++fdO9pk6dOixfvpxXXnnFdiwqKoo6der8q1hSl+IvUqSI7TnvvvsuZ86coXDhwrbneHt7U7FixX/1LBGR++KSFwo9YpRUiVfg4hb7pO3Kfrh22CjRc9LqepX5O2lLLdXA1dwefUnj5QVNmxoFIC4O1q5NS9jWrYNTp+C774wC4O+flqw1bAgVKyphExFxJKYOcYyMjKRr167UqFGDWrVqMW7cOK5du0b37t0B6NKlC8WKFWPkyJEA9OvXj4YNGzJmzBhatGjBzJkz2bhxI59//rntnhcuXCA6OpqTJ08CsHevMYkjdbXGgwcPMmPGDJo3b46fnx/bt2/n1VdfpUGDBlSpUgWApk2bUrFiRZ599llGjRpFTEwMb7/9Nn369Em3h0xEJEu55oPCDYySKuESXNiclrCd32gka1cPGOXozL8rWsC7/E0JW5iRtLnkNeOdyD94ekLjxkYBuH7dSNJWrjSStrVrjb3YZs82CkChQtCggZGsNWoElSoZc+BERCRnMjVB69ChA2fPnmXw4MHExMRQtWpVFi9ebFuQIzo6Gqeb/pWpW7cuM2bM4O233+bNN9+kbNmyzJ8/n8qVK9vqLFiwwJbgAXTs2BGAIUOGMHToUNzc3Fi2bJktGQwMDKRt27a8/fbbtmucnZ1ZuHAhvXv3pk6dOuTNm5euXbsyfPjwzP5IREQejJsPBDxmlFTx529N2uKiIXaPUY58a9SzOIF3hbSkza+Gsdm2Sx5T3oqkyZPHSLoaNTK+j4+H9evTErY1a4wl/ufONQoYe7XdnLBVqaKETUQkJ7FYrVar2UE4qtjYWPLnz8/ly5ezxSIhixYtonnz5tliDK78e2pTx5Tp7XrjDFzYZD888vrJW+tZnCF/Zfs5bT5VwFmjCO5XZrZpQoIxb+2334zyxx9w7Zp9HR8fqF8/bR5b1arg7JyhYeQ6+vvXMaldHU92a9N7zQ1y5SqOIiK5lkdhKPq4UVLFnTSStgub/k7aNhiJ3KVtRjn4lVHPyRXyh9jPafOpbBwXU7i5wSOPGOXNNyExETZtSkvYVq+GS5fgp5+MAsYG2/XqpSVs1auDi34bEBHJNvRXsohIbudZ1CjF/15a0GqF6yfse9kubDSGTF7cbBT+nvvr5A6+ofZz2vJXBCf982IGV1d4+GGjDBgASUmwZUvaoiOrV0NsLCxaZBQwFiqpVy9t0ZEaNYz7iIiIOfQvqIiI2LNYwLO4UQLbGMesVrh29KaE7e9hkomX4Px6o6RyzgO+Ve3ntOUrD04aV5fVXFygZk2jvP46JCfDtm32CdvFi7B4sVEA8uaFunXTEraaNUHrY4mIZB0laCIicncWC3gFGeWhp41jVitcPWS/CMmFTZB0Bc6tNUoql7zgWz0tYStQA/KVMRYokSzj7GwMaaxeHV59FVJSYMeOtEVHVq2C8+chKsooYCxUUqdOWsJWuzZ4eJj6NkREHJoSNBEReTAWC+QrbZQSHYxj1hRjT7bzN/W0XdxsbLh9drVRUrl6G0nbzXPavEppU68s5OQEoaFG6dfPSNj++istYfvtN2OVyBUrjAJGb9rDD6etEvnww0YSJyIiGUMJmoiIZByLk7HPmnd5KNnZOJaSDFf22s9pu7gFEmPhzEqjpHL1sU/Y/GqA50NK2rKIkxNUrmyUvn2NTtLdu9OStd9+g5iYtNfDhxsLldSqlZaw1aljDJMUEZEHowRNREQyl5OzsXBI/opQqotxLCUJLv9lPzzy0jZjTlvMMqOkci+YttR/atKWp5iStixgsUDFikbp3dtI2PbtS0vQVq6Ekyfh99+N8u67afPeUleJfOQRYyESERG5N0rQREQk6zm5gG8Vo5R+zjiWnACXd/0jadsO8efg1BKjpPLwt0/YCoRBniLmvJdcxGKB8uWN0quXkbAdPGifsB07BmvXGmXkSGPeW1hYWsJWr56x1L+IiKRPCZqIiGQPzm5QoJpR6GkcS74Bl3bctAjJRiOJu3EaTv5slFR5iv4jaasBHoVMeSu5hcUCZcoYpUcPI2E7ciQtWfvtN+P79euNMmqUMYyyevW0RUfq1zc20xYREYMSNBERyb6cPcCvplHK/n0sKQ4ubrtpY+2NELsbrp+EEwuMksrzIfs5bQXCwL2AKW8lN7BYoGRJo3TrZhw7etR+DtvBg7Bxo1HGjDGuqVo1LWFr0AAKqIlEJBdTgiYiIjmLiycUqmOUVIlX4eJW+421Y/dCXLRRjs1Lq+tVyn5OW4Hq4OaT1e8i1yhRArp0MQrA8eP2Cdu+fcZm2lu2wLhxRsIWEpK26EiDBlCwoJnvQEQkaylBExGRnM/VCwrXM0qqxFi4sMV+TtvVA8bebVcPQfSctLr5ytoPj/StBq75sv595ALFi0PnzkYBOHXKPmHbvRu2bzfKhAlGnUqV7BM2f3/TwhcRyXRK0ERExDG5eoN/Q6OkSrgIFzbbz2m7dsTYu+3Kfjj63d8VLeAdnNbT5lcDfKsaG25LhipSBDp2NArA6dPGhtmp89h27Uorn3xi1AkOTlt0pGFD4x4iIo5CCZqIiOQebr4Q0NgoqW6c+3tD7U1pSVvcMWNeW+xuOPKtUc/iBN4V7ee0+VQBF+3SnJH8/aFdO6OAsVH26tVpCdv27bBnj1EmTzbqlC1rn7AVL25W9CIi/54SNBERyd08CkLRCKOkun7afhGS8xvgRgxc3mmUQ18b9Swu4FPZfk6bTwg4u5vyVhxRoULw1FNGAbhwwUjYUleJ3LoV9u83yhdfGHVKlbJP2EqUMCl4EZEHoARNRETkn/L4Q7HmRkkVd/KmRUg2GUlb/FljcZKLW+HgV0Y9J1ejZy01YcsfisWaZMa7cEgFCsATTxgF4NIlY5Ps1IRt82Y4dMgoU6YYdYKC0pK1Ro2M77XPuYhkV0rQRERE7oVnUfBsDcVbG99brRB33H4RkgsbIeHC371vm4DPcAVa4IJTVCXwDQWf0LSvHlqe8N/y8YGWLY0CEBtrJGypi45s3GjsxXbkCEybZtQJDLRP2EqXVsImItmHEjQREZEHYbFA3kCjBD5pHLNajUVHbAnbJqwXNuKceBkubTPKzfIUsU/YfKqAd3lw0j/PD8rbG5o3NwrAlSuwZk1awrZ+PRw7Bt9+axSAokXTkrWGDaFcOSVsImIe/QsgIiKSUSwW8CpplIeMVS6SEhJY+fPXPFqtAC5XdsGl7cZG21cPwvVTRjm1OO0eTu6QP7W3rUpa8qYNth9IvnwQEWEUgGvXYO3atIRt3To4eRK++84oAAEBxnL+qQlbhQpK2EQk6yhBExERyUwWC3FO/liLNQfXp9OOJ16BSzvSErZL24zXSdfg4maj3MyzuJGw3dzjlq8sODln7fvJ4fLmhfBwowBcvw5//pm2SuSff0JMDMyebRQwFiq5OWErV86s6EUkN1CCJiIiYgbXfFCorlFSWVPg6mEjWUtN2i5uh2uHjfluccfh5KK0+s4ekL9yWm+bTyj4VjG2E5B7kicPPPqoUQBu3DCGQaYmbGvXGkv9z51rFAA/PxfKlKnFX385UacOhIUZPXUiIhlBCZqIiEh2YXGCfKWNEvhU2vGEy3/3tm27qcdtByTHpS1ScjPPh9KGR6b2tnmVVm/bPfDwMHrLGjSAQYMgIQE2bEhbJfKPP+D8eQvnzxdh3TrjGosFKlaEWrXSSkgIuLqa+lZEJIdSgiYiIpLdueWHwvWMkiolGa4esu9tu7Qdrh2FuGijnFyYVt/Z09izzefmuW1VjHvLbbm5wSOPGOWttyAxEdatS+LLL/dy5UoFNm50Ijoadu0yytSpxnXu7lC9un3SptUiReReKEETERHJiZycwbusUR66aW5bwqWbetn+/np5p9Hbdn69UW6WN8h+MRLfUPAqZfTmyS1cXaF2bSvnzx+gefNyuLo6ERNj9LKtX59WLl0yhkeuXZt2ra+vfcJWsyb4+5v2VkQkm1KCJiIi4kjcfKBwA6OkSkmGqwdumtf2d/IWd8zYFuDaETixIK2+S17IH3LTEMkqRnHVRKv0BARAq1ZGAWO3hQMH7BO2LVvg4kVYssQoqUqUsE/aqlcHLy9z3oeIZA9K0ERERBydk7Oxv5p3eSjRPu14/AX73rZL2+DSTmMlyfN/GuVmXqXsV5L0DTV64NTbZsdigbJljdK5s3EsIQF27LBP2nbvhqNHjTJnjlHPyQkqVbJP2ipV0nw2kdxECZqIiEhu5V4A/BsZJVVKElzZZ6weeXNv2/UTxpy3q4fg+Py0+i75wCfEfrNtnxBwVTfQzdzcjNUew8Kgd2/jWGwsbNpkn7QdP24kcjt2wFdfGfXy5Ll1PlvJkprPJuKolKCJiIhIGicXyF/RKHRMO37j3E29bKlz23ZB0hU4t8YoNhZj1ch/bradt4Syipt4e9sv8Q/Gptk3z2fbsAEuXzZWj/zjj7R6fn63zmcrVCjr34OIZDwlaCIiInJ3HgUh4DGjpEpJhNi99pttX9wGN2KMOW9XD8CxuWn1Xb3/sdl2FWNlSZe8Wf9+sqmiReGJJ4wCkJIC+/fb97Jt3Qrnz8MvvxglVcmS9klbtWrGxtwikrMoQRMREZEH4+T699L9lSHombTjN86kJW2pQyRj/4LEWDj7u1FsLJCv7D822w4Fz0D1tmHMSStf3ijPPmsci4+H7dvtk7Y9e+DwYaPMmmXUc3aGypXtk7aKFcFFv/2JZGv6IyoiIiIZy6MwBIQbJVVyAsTu+cdm29uMZO7KPqNEz0mr7+oDvjf3toVC/krgkifL30524+5uDGmsWRP69DGOXb4MGzemJWzr1sGpU7Btm1G++MKo5+lpzIO7OWkroZGnItmKEjQRERHJfM5uRsLlW8X++PUY+4Tt0na4vBsSL8GZVUZJZXGCfOXsh0j6hkKeYrk+w8ifHxo3NkqqEyfse9k2bIArV2D1aqOkKlTo1vlsfn5Z/x5ExKAETURERMyTJ8AoRZqmHUuOh9jd9pttX9oG8eeMXrjYPRA9K62+W4Fbh0jmrwjOHln/frKRYsXgySeNAsZ8tr177ZO2bdvg7Fn4+WejpCpd+tb5bHnUeSmSJUzfuGTSpEkEBQXh4eFB7dq1Wb9+/R3rz5kzh+DgYDw8PAgJCWHRokV25+fNm0fTpk3x8/PDYrGwdetWu/MXLlzgpZdeonz58uTJk4eHHnqIl19+mcuXL9vVs1gst5SZM2dmyHsWERGRO3B2B9+qUKorVB8DjZfBU2egzQlo9AtUfR9KdDKSMIszJFyA07/C3vGw7jlYHAazveDnSvDHM/DXB3DyF4g7aewinUs5OUGFCtC1K0yaZPSoxcbCn3/Cxx/Df/4D5coZdQ8ehO++g1dfhUcegXz5jKX+X3gBpkyBnTshOdnc9yPiqEztQZs1axaRkZFMnjyZ2rVrM27cOCIiIti7dy+FCxe+pf6aNWvo1KkTI0eOpGXLlsyYMYM2bdqwefNmKleuDMC1a9eoV68e7du3p2fPnrfc4+TJk5w8eZIPP/yQihUrcvToUV544QVOnjzJ999/b1d36tSpNGvWzPa9j49Pxn4AIiIicm8sFvAsapSiaf82k3wDLv9lP0Ty4jYjabv8l1GOfpdW371g2n5tqZtte1cwksJcyMMDatc2SqqLF2+dz3b6NGzZYpTPPjPq5c0LNWrY97QFam0XkX/N1ARt7Nix9OzZk+7duwMwefJkfv75Z6ZMmcJ///vfW+qPHz+eZs2a0b9/fwBGjBhBVFQUEydOZPLkyQA8+/cSR0eOHEn3mZUrV2bu3LQlf0uXLs27777Lf/7zH5KSknC5aWkjHx8fAgICMuS9ioiISCZw9oAC1Y2Symo1Ntb+5xDJK/uMYZKnlxsllcUFvIPTFiNJHS6ZJ3f+DuDrC02aGAWMj/P4cfuhkRs3wtWr8NtvRknl72+fsNWoAQUKmPM+RHIq0xK0hIQENm3axMCBA23HnJycCA8PZ+3ateles3btWiIjI+2ORUREMH/+/H8Vy+XLl/H29rZLzgD69OnD888/T6lSpXjhhRfo3r07ljv8t1B8fDzx8fG272NjYwFITEwkMTHxX8X4b6U+3+w4JOOoTR2T2tXxqE1N4uoPhZsaJVVSHJbY3XB5O5ZL27Fc3mF8TbwEl3cahem26lb3wlh9qmDNH4LVJwRr/irgHUxisvG7QG5q04AAaN3aKGAMb9yzBzZutLBhg4UNG5zYsQNOn7bw00/w009p15b5//buPTbqMt/j+Oc3l7bTK+2U0paWAoLcFESoWNBVcUUKIcvGxUu6WtQNMQKChMRAdAFxwT0bd91N3O5CXDg5iERNiuyeBSxEMGsOS4HFBRe5CRQpFGiBaaeltJ05f/zoZegUe5PfdHi/kied+f3m8p0+nYQPz/N7nkF+ZWc3t1Gj/IoKwcsD+a6Gn1Dr0/bWYVlAu3jxohoaGtSnT5+A43369NE333wT9Dnnzp0L+vhz5851qY7ly5dr1qxZAcfffPNNTZw4UdHR0frss8/08ssvq6qqSq+88kqbr7Vy5UotW7as1fHPPvtM0dHRna6xOxUVFVldAroZfRqe6NfwQ5+Gkj6SHjOb0y+X46LifSeU4Dt1/edJxfjPyqg9L6Nsm1S2remZPjlUbcvQvUaWSv73Q9UYyaqxpaja6K0aI1k+I8KyT2WF3r2lKVPMVltr04kTCTp6NFFHj/bS0aOJOns2VseOGTp2zNCH12ea2u0+9e/v0eDBlzR48CXdeedlpadXym639rM04rsafkKlT6urq9v1uNt6FUePx6OpU6dq+PDhWrp0acC5N954o+n26NGj5fV69Zvf/OamAW3RokUBI3wej0eZmZmaNGmS4uPju73+jqirq1NRUZEee+wxOZ1OS2tB96BPwxP9Gn7o056pvt4rw/Mf6XLjaNu/ZVw+IFu9Rwm+k0rQSSnIIhn+yD7yx/STovvJH339Z0w/+aMzpegsc3+32+girfLyOu3d2zjKZrYLF2w6fryXjh/vpS1bBkiS4uL8GjPGr7Fjm0fa+t7i3RP4roafUOvTxtl138eygJacnCy73a6ysrKA42VlZW1e95Wamtqhx99MZWWlJk+erLi4OBUWFn5vp40bN07Lly9XbW2tIiODX0gcGRkZ9JzT6QyJPwoptGpB96BPwxP9Gn7o0x7G2UtyjZf6jG8+5vdL3lOqv7hXR4oLNSTTJXvNaclbInlPSQ3VMmrLZNSWSRXFwV/XESfFZEkx/a7/zJKiW9x2pZn7vYWJ1FRp6lSzSeavsKSk9fVslZWGduwwtGNH83PT0lpfz3Yr1mvjuxp+QqVP21uDZQEtIiJCY8aM0fbt2zV9+nRJks/n0/bt2zVnzpygz8nJydH27ds1f/78pmNFRUXKycnp0Ht7PB49/vjjioyM1KZNmxTVjonQ+/fvV2JiYpvhDAAAhDnDkGL7yx/ZV0e/cmjwmCmyN/6Dy++Xasul6uthrbG1vF97UaqvbHG9WxA2p+TKaA5sAUEuS4rJ7NH7uxmGlJVlthkzzGP19dKhQ4Gh7cAB6exZ6dNPzdZoyJDA0DZqlMQ/zRBuLJ3iuGDBAuXn52vs2LG677779O6778rr9Tat6vjcc8+pb9++WrlypSRp3rx5euihh/TOO+9o6tSp2rBhg/bs2aNVq1Y1vWZFRYVKSkpUWloqSTp8+LAkc/QtNTVVHo9HkyZNUnV1tdatWyePx9M03Ni7d2/Z7Xb99a9/VVlZme6//35FRUWpqKhIK1as0MKFC2/lrwcAAPQUhiFFJZut5YqSLdVXN4+2VZ9qvt0Y5Kq/k3x1kveE2doS1af1yFvLMNfDplE6HNLdd5vtxRfNY9XV5pL+LUPbt9+aG20fPiz9z/+Yj3M6pXvuCQxtd95p7vkG9FSWBrSnnnpKFy5c0C9/+UudO3dO99xzj7Zs2dK0EEhJSYlsLb5h48eP1/r16/X6669r8eLFGjx4sDZu3Ni0B5okbdq0qSngSdLTTz8tSVqyZImWLl2qffv26Z///KckadCgQQH1nDhxQv3795fT6dR7772nV199VX6/X4MGDWraEgAAAKBTHNFSwlCzBeOrl2pKr4e2kush7oYg11AtXS0zW/nuNt4nLnDk7cYwF5Uq2UJkRY42REebG2RPmNB87OJFc3PtlqGt8Vhxsbn5tiTFx0vZ2YGhLT3dms8BdIbli4TMmTOnzSmNO1pORL5uxowZmtE4Jh7EzJkzNXPmzDbPP/zww/L7/TetafLkyQEbVAMAAPzgbI7rwapf8PNBp1G2DHItp1F+bbag73OzaZTX3z8Ep1EmJ0u5uWaTzF/HyZOBgW3vXsnjkbZvN1ujvn0DA9uYMVJCgiUfA/helgc0AAAAtEOHp1GWtL4WrkvTKFvcDoFplIYhDRhgtqeeMo/V10tffx0Y2g4elM6ckQoLzdb43KFDA0PbsGHWfRagJQIaAABAuGj3NMo2roXr4dMoHQ5z4ZBRo6TGK1O8XmnfvsDQdvKkuTDJoUPSf/+3+biICIfS0x/WmjV2DR4s3XFHc+vXz3xt4FbgTw0AAOB2ETCN8oHW5/1+6VpF4BTKpiB3/X7thR41jTImRnrwQbM1On++9fVsFRWGTp5M0MmTrV/D4TBXnmwZ2hrbwIHmewDdhYAGAAAAk2FIkW6zfd80yra2FOgB0yhTUlrvz3b4cJ0++GCP3O77dPKkXcePS8ePm6tH1taq6X4wqanBw9sdd5jXzvWgRTURAghoAAAAaL92TaM8G3wvuK5Mo7xxW4FunEZpGGaYGjv2vKZM8cnpbH5dn08qLW0OaDe2S5ekc+fM9uWXrV87Pr7t8JaRIdlDe0FNWICABgAAgO5jc5gbasdk6vunUbZcyKTF/Q5Powx2PVz3TKO02cwglZEhPfRQ6/MVFW2HtzNnzFUl//Uvs93I6TQXOQkW3gYMkFyuLpePHoiABgAAgFunvdMoq0/fMPLWYkuBjkyjbGtD726aRpmUZLbs7NbnamqkEyeCh7cTJ6S6OunIEbMF07dv26NvSUldKhshjIAGAACA0OKIluKHmC0YX0OLTb3b2FKg3ts8jbKiuI33iW0KazZXpu685pHt2CnJ1bs5REYkmT8dcR0Ocy6XNHy42W7U0CB9913bo28ejzkCd+aM9MUXrZ/fq1fw4DZokLkxt83WoVIRQghoAAAA6Fls9k5Oo2xxu/aCVF/VNI3SLmmYJP3rwzbe02mGtcbA1jK8Rdxwv+XtNqZZ2u3mypBZWdLEia3LLy9vO7ydPStdvmxuzL13b+vXjow0V5cMFuD69zfPI3QR0AAAABBe2jWNsiYgsDVUfqvTR/epX58Y2eouSdfKpdoK82fDVXNKZeOIXEfYo6XIpOYQ1yrYJbUKeEZEopKTHUpOlsaNa/2SXm/z1MljxwLD26lT5qqTjfu8BfvVZGa2PXUyIaFjHw/dj4AGAACA24/DFTCN0ldXp69K/q6+46fI5nQGPra+2hyRqy03W+PtazfcDzhXIfkbzBUrq6vN6+Y6wtkraHhTpFsxEUm6K9atu7Ld0gMtQp4zXvUNhkpK2h5983qlkhKzff5567d1u9sOb2lpbBlwKxDQAAAAgJtxRJstOqP9z/H7pLrK5hDXZpC74X7dFfP5dZfNpm/b/56GXY6IJA2MdGtgpFuPDUuS7mmegumPSNKVGre+u+DWydIkHTnl1sGjbn1z1KXjx80NvMvLzbY7yO4HLlfrqZODBpk/s7LMVSnRdQQ0AAAAoLsZNikiwWyxA9v/PF+9dO1Si/BWETzk3XiuocYcsau9YLZgJUnqdb3dZZc08Hqb4pIiktTgdKu6wS1PTZIuVrpVWu5WSVmSjp9268hJty5UulVxKUn/t8Ot//1bkhp8zVHCbpf69Wt79C02trO/yNsPAQ0AAAAIFTaHFNXbbB1RX9N2eGtz5K5C8teb4a7mjOw1ZxQnKU5S3xhpVIykfpKCbCEgSd5r8arwunX+slsXK5NUXuVWeaVb5RfcOn0ySfs3ulVe5VZFlTk9s1eKW6mZ8Rp4hy0gvKWkMHWyJQIaAAAA0NM5XJKjrxTdt/3P8fvNDcE7MgWztvz61EspJsKjmAiPMhNvshfdDeob7LrkTVR5mVvlx93aXZUkz1W3Ghxu2aOTFBXvVlyyW+60JPXp51ZqlluOaLdkd902KY6ABgAAANyODENyxpstdkD7n+drMKdhtnMKpq+mXP7actn91XLYG9Q7/qJ6x1+8+XtckXTgepN0rSFS1fVu1dncMiKT5Ix1KybRLUdMG9sbRLglW1xnfzOWIqABAAAAaD+bXYpKNlt7Ht54o+Fqi0Bn/qzzlutyWYU8F8t19YoZ5oy6CkUZ5YqNKJc7plxOR70i7LWKsJdKKpV8kjzX2004JU2RS8bp1dLAvE5/3FuNgAYAAADgh2ePkqLTzXadU1LvoVKwK+58Pqn0jF8nj1Wp9GS5LnxXocvny+WtMINdlFEhd2y53HHlSoqpkDuu3LwfW65e0Zdls/nlVI127YvS/R1Yp8VqBDQAAAAAIcdmkzIyDWVkNi5d0j/gfEVF8/5u+2/Y7+1saYN6xVyWO7Zc//WH9o30hQoCGgAAAIAeJynJbNlBVpmsqbHryJF4ffTRUWWP78D1dSHA9v0PAQAAAICew+WShg+X7ruvTCkpVlfTMQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEOqwsIZ36/X5Lk8XgsrkSqq6tTdXW1PB6PnE6n1eWgG9Cn4Yl+DT/0afihT8MT/Rp+Qq1PGzNBY0ZoCwHtB1RZWSlJyszMtLgSAAAAAKGgsrJSCQkJbZ43/N8X4dBpPp9PpaWliouLk2EYltbi8XiUmZmp06dPKz4+3tJa0D3o0/BEv4Yf+jT80KfhiX4NP6HWp36/X5WVlUpPT5fN1vaVZoyg/YBsNpsyMjKsLiNAfHx8SPyBovvQp+GJfg0/9Gn4oU/DE/0afkKpT282ctaIRUIAAAAAIEQQ0AAAAAAgRBDQbhORkZFasmSJIiMjrS4F3YQ+DU/0a/ihT8MPfRqe6Nfw01P7lEVCAAAAACBEMIIGAAAAACGCgAYAAAAAIYKABgAAAAAhgoAGAAAAACGCgBbmvvjiC02bNk3p6ekyDEMbN260uiR00cqVK5Wdna24uDilpKRo+vTpOnz4sNVloQsKCgo0cuTIpo00c3JytHnzZqvLQjd6++23ZRiG5s+fb3Up6IKlS5fKMIyANnToUKvLQhedOXNGP//5z+V2u+VyuXT33Xdrz549VpeFLujfv3+r76phGJo9e7bVpbULAS3Meb1ejRo1Su+9957VpaCb7Ny5U7Nnz9auXbtUVFSkuro6TZo0SV6v1+rS0EkZGRl6++23tXfvXu3Zs0cTJ07UT37yE3399ddWl4ZuUFxcrD//+c8aOXKk1aWgG4wYMUJnz55tav/4xz+sLgldcOnSJU2YMEFOp1ObN2/Wf/7zH73zzjtKTEy0ujR0QXFxccD3tKioSJI0Y8YMiytrH4fVBeCHlZubq9zcXKvLQDfasmVLwP21a9cqJSVFe/fu1Y9+9COLqkJXTJs2LeD+r371KxUUFGjXrl0aMWKERVWhO1RVVSkvL0+rV6/WW2+9ZXU56AYOh0OpqalWl4Fu8utf/1qZmZlas2ZN07EBAwZYWBG6Q+/evQPuv/3227rjjjv00EMPWVRRxzCCBvRwV65ckSQlJSVZXAm6Q0NDgzZs2CCv16ucnByry0EXzZ49W1OnTtWPf/xjq0tBNzl69KjS09M1cOBA5eXlqaSkxOqS0AWbNm3S2LFjNWPGDKWkpGj06NFavXq11WWhG127dk3r1q3TCy+8IMMwrC6nXRhBA3own8+n+fPna8KECbrrrrusLgddcODAAeXk5Ojq1auKjY1VYWGhhg8fbnVZ6IINGzZo3759Ki4utroUdJNx48Zp7dq1GjJkiM6ePatly5bpwQcf1MGDBxUXF2d1eeiEb7/9VgUFBVqwYIEWL16s4uJivfLKK4qIiFB+fr7V5aEbbNy4UZcvX9bMmTOtLqXdCGhADzZ79mwdPHiQayDCwJAhQ7R//35duXJFn3zyifLz87Vz505CWg91+vRpzZs3T0VFRYqKirK6HHSTlpcMjBw5UuPGjVNWVpY++ugjvfjiixZWhs7y+XwaO3asVqxYIUkaPXq0Dh48qD/96U8EtDDx/vvvKzc3V+np6VaX0m5McQR6qDlz5uhvf/ubPv/8c2VkZFhdDrooIiJCgwYN0pgxY7Ry5UqNGjVKv//9760uC520d+9enT9/Xvfee68cDoccDod27typP/zhD3I4HGpoaLC6RHSDXr166c4779SxY8esLgWdlJaW1uo/woYNG8bU1TBx6tQpbdu2Tb/4xS+sLqVDGEEDehi/36+5c+eqsLBQO3bs4GLmMOXz+VRbW2t1GeikRx99VAcOHAg49vzzz2vo0KF67bXXZLfbLaoM3amqqkrHjx/Xs88+a3Up6KQJEya02qrmyJEjysrKsqgidKc1a9YoJSVFU6dOtbqUDiGghbmqqqqA/9k7ceKE9u/fr6SkJPXr18/CytBZs2fP1vr16/Xpp58qLi5O586dkyQlJCTI5XJZXB06Y9GiRcrNzVW/fv1UWVmp9evXa8eOHdq6davVpaGT4uLiWl0XGhMTI7fbzfWiPdjChQs1bdo0ZWVlqbS0VEuWLJHdbtczzzxjdWnopFdffVXjx4/XihUr9OSTT2r37t1atWqVVq1aZXVp6CKfz6c1a9YoPz9fDkfPijw9q1p02J49e/TII4803V+wYIEkKT8/X2vXrrWoKnRFQUGBJOnhhx8OOL5mzZoedQEsmp0/f17PPfeczp49q4SEBI0cOVJbt27VY489ZnVpAFr47rvv9Mwzz6i8vFy9e/fWAw88oF27drVa0hs9R3Z2tgoLC7Vo0SK9+eabGjBggN59913l5eVZXRq6aNu2bSopKdELL7xgdSkdZvj9fr/VRQAAAAAAWCQEAAAAAEIGAQ0AAAAAQgQBDQAAAABCBAENAAAAAEIEAQ0AAAAAQgQBDQAAAABCBAENAAAAAEIEAQ0AAAAAQgQBDQCAEGQYhjZu3Gh1GQCAW4yABgDADWbOnCnDMFq1yZMnW10aACDMOawuAACAUDR58mStWbMm4FhkZKRF1QAAbheMoAEAEERkZKRSU1MDWmJioiRz+mFBQYFyc3Plcrk0cOBAffLJJwHPP3DggCZOnCiXyyW3261Zs2apqqoq4DF/+ctfNGLECEVGRiotLU1z5swJOH/x4kX99Kc/VXR0tAYPHqxNmzb9sB8aAGA5AhoAAJ3wxhtv6IknntBXX32lvLw8Pf300zp06JAkyev16vHHH1diYqKKi4v18ccfa9u2bQEBrKCgQLNnz9asWbN04MABbdq0SYMGDQp4j2XLlunJJ5/Uv//9b02ZMkV5eXmqqKi4pZ8TAHBrGX6/3291EQAAhJKZM2dq3bp1ioqKCji+ePFiLV68WIZh6KWXXlJBQUHTufvvv1/33nuv/vjHP2r16tV67bXXdPr0acXExEiS/v73v2vatGkqLS1Vnz591LdvXz3//PN66623gtZgGIZef/11LV++XJIZ+mJjY7V582auhQOAMMY1aAAABPHII48EBDBJSkpKarqdk5MTcC4nJ0f79++XJB06dEijRo1qCmeSNGHCBPl8Ph0+fFiGYai0tFSPPvroTWsYOXJk0+2YmBjFx8fr/Pnznf1IAIAegIAGAEAQMTExraYcdheXy9WuxzmdzoD7hmHI5/P9ECUBAEIE16ABANAJu3btanV/2LBhkqRhw4bpq6++ktfrbTr/5ZdfymazaciQIYqLi1P//v21ffv2W1ozACD0MYIGAEAQtbW1OnfuXMAxh8Oh5ORkSdLHH3+ssWPH6oEHHtAHH3yg3bt36/3335ck5eXlacmSJcrPz9fSpUt14cIFzZ07V88++6z69OkjSVq6dKleeuklpaSkKDc3V5WVlfryyy81d+7cW/tBAQAhhYAGAEAQW7ZsUVpaWsCxIUOG6JtvvpFkrrC4YcMGvfzyy0pLS9OHH36o4cOHS5Kio6O1detWzZs3T9nZ2YqOjtYTTzyh3/72t02vlZ+fr6tXr+p3v/udFi5cqOTkZP3sZz+7dR8QABCSWMURAIAOMgxDhYWFmj59utWlAADCDNegAQAAAECIIKABAAAAQIjgGjQAADqIqwMAAD8URtAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRBDQAAAAACBEENAAAAAAIEQQ0AAAAAAgRPw/jPfYRYri2b0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_dir_name = \"../models/fld0_sfzn1_hd_hl512_srsnxt///\"\n",
    "i = 0\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# loss„Çí„Éó„É≠„ÉÉ„Éà\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\n",
      "ÊúÄÂ§ßË™§Â∑Æ: 0.0\n",
      "Âπ≥ÂùáË™§Â∑Æ: 0.0\n",
      "Ê®ôÊ∫ñÂÅèÂ∑Æ: 0.0\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´Âá∫Âäõ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "\n",
    "# „É¢„Éá„É´„Éë„Çπ\n",
    "# ÊØîËºÉÂÖÉ\n",
    "model_1_path = \"../models/sfzn1_hd_hl512//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_safezone1000_head_hoplength512/model_fold0.pth\"\n",
    "\n",
    "# ÂÖ±ÈÄöË®≠ÂÆöÔºà„Åì„ÅÆcfg_inf„ÅØÂøÖÈ†àÔºâ\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÈñ¢Êï∞\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# Êé®Ë´ñÔºàÂá∫Âäõ„Å´ sigmoid „ÅåÂøÖË¶Å„Å™Â†¥Âêà„ÅØ model „Å´Âê´„Åæ„Çå„Å¶„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶ÈÅ©ÂÆúËøΩÂä†Ôºâ\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# Â∑ÆÂàÜË®àÁÆó\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\")\n",
    "print(f\"ÊúÄÂ§ßË™§Â∑Æ: {np.max(abs_diff)}\")\n",
    "print(f\"Âπ≥ÂùáË™§Â∑Æ: {np.mean(abs_diff)}\")\n",
    "print(f\"Ê®ôÊ∫ñÂÅèÂ∑Æ: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„Éù„ÉÉ„ÇØ1„Åß„Éá„Éê„ÉÉ„Ç∞„Åß„Åç„Çã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
