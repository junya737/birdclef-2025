{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "Device name: NVIDIA H100 PCIe\n",
      "Tensor device: cuda:0\n",
      "['sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Tensor device:\", torch.tensor([1.0], device=\"cuda\").device)\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY_Mixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx_to_label = idx2label\n",
    "        self.species_ids = label2idx.keys() if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        \n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        # === Mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and random.random() < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "        else:\n",
    "            spec = spec1\n",
    "            label = label1\n",
    "\n",
    "        return {\n",
    "            'melspec': spec,\n",
    "            'target': torch.tensor(label, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec\n",
    "\n",
    "\n",
    "\n",
    "class BirdCLEFDatasetWithPseudoMixup(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, pseudo_df=None, pseudo_melspecs=None,\n",
    "                 mode=\"train\", label2idx=None, idx2label=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.pseudo_df = pseudo_df.reset_index(drop=True) if pseudo_df is not None else None\n",
    "        self.pseudo_melspecs = pseudo_melspecs\n",
    "        self.label_to_idx = label2idx\n",
    "        self.idx2label = idx2label\n",
    "        self.species_ids = list(label2idx.keys()) if label2idx else []\n",
    "        self.num_classes = len(self.species_ids)\n",
    "\n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df['filename'].map(\n",
    "                lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row1 = self.df.iloc[idx]\n",
    "        spec1 = self._get_spec(row1['samplename'])\n",
    "        label1 = self._get_label(row1)\n",
    "\n",
    "        rand_val = random.random()\n",
    "\n",
    "        # === real √ó real mixup ===\n",
    "        if self.mode == \"train\" and self.cfg.use_mixup and rand_val < self.cfg.mixup_prob:\n",
    "            idx2 = random.randint(0, len(self.df) - 1)\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            spec2 = self._get_spec(row2['samplename'])\n",
    "            label2 = self._get_label(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === real √ó pseudo mixup ===\n",
    "        if (self.mode == \"train\" and self.cfg.use_pseudo_mixup and\n",
    "            self.pseudo_df is not None and\n",
    "            rand_val < (self.cfg.mixup_prob + self.cfg.pseudo_mixup_prob)):\n",
    "            \n",
    "            idx2 = random.randint(0, len(self.pseudo_df) - 1)\n",
    "            row2 = self.pseudo_df.iloc[idx2]\n",
    "            spec2 = self._get_spec_pseudo(row2['samplename'])\n",
    "            label2 = self._get_label_pseudo(row2)\n",
    "\n",
    "            lam = np.random.beta(self.cfg.mixup_alpha, self.cfg.mixup_alpha)\n",
    "            spec = lam * spec1 + (1 - lam) * spec2\n",
    "            label = lam * label1 + (1 - lam) * label2\n",
    "\n",
    "            return {\n",
    "                'melspec': spec,\n",
    "                'target': torch.tensor(label, dtype=torch.float32),\n",
    "                'filename': row1['filename']\n",
    "            }\n",
    "\n",
    "        # === no mixup ===\n",
    "        return {\n",
    "            'melspec': spec1,\n",
    "            'target': torch.tensor(label1, dtype=torch.float32),\n",
    "            'filename': row1['filename']\n",
    "        }\n",
    "\n",
    "    def _get_spec(self, samplename):\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "\n",
    "        return spec\n",
    "\n",
    "    def _get_spec_pseudo(self, samplename):\n",
    "        if self.pseudo_melspecs and samplename in self.pseudo_melspecs:\n",
    "            spec = self.pseudo_melspecs[samplename]\n",
    "        else:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":\n",
    "                print(f\"Warning: Pseudo spectrogram not found: {samplename}\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec.unsqueeze(0)\n",
    "\n",
    "        return spec  # No augmentation\n",
    "\n",
    "    def _get_label(self, row):\n",
    "        target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        if row['primary_label'] in self.label_to_idx:\n",
    "            target[self.label_to_idx[row['primary_label']]] = 1.0\n",
    "\n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            for label in secondary_labels:\n",
    "                if label in self.label_to_idx:\n",
    "                    target[self.label_to_idx[label]] = 1.0\n",
    "\n",
    "        return target\n",
    "\n",
    "    def _get_label_pseudo(self, row):\n",
    "        values = row[self.species_ids].values.astype(np.float32)\n",
    "        values = np.nan_to_num(values, nan=0.0)\n",
    "        return values\n",
    "\n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFModelForTrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        # Ê¥ªÊÄßÂåñÈñ¢Êï∞‰∏çÂú®Ôºé\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n",
    "                                       logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "class BirdCLEFModelForTrain_Coat(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # CoaTÂ∞ÇÁî®: drop_path_rate„Çí0„Å´„Åô„Çã\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.0  # <= „Åì„Åì„Çí0.0„Å´ÔºÅ\n",
    "        )\n",
    "        \n",
    "        # CoaT„ÅØ reset_classifier „ÅåÂøÖË¶Å\n",
    "        backbone_out = self.backbone.get_classifier().in_features\n",
    "        self.backbone.reset_classifier(0, 'avg')  # <= global_pool='avg'\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BirdCLEFModelForTrain_Swin(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        \n",
    "        backbone_out = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)  # 2D„Éó„Éº„É™„É≥„Ç∞„Å´Â§âÊõ¥ÔºÅÔºÅ\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "\n",
    "        if features.ndim == 4:\n",
    "            # CNNÁ≥ª (B, C, H, W)\n",
    "            features = self.pooling(features)\n",
    "            features = features.flatten(1)\n",
    "        elif features.ndim == 3:\n",
    "            # TransformerÁ≥ª (B, N, C)\n",
    "            features = features.mean(dim=1)\n",
    "        elif features.ndim == 2:\n",
    "            # „ÇÇ„ÅÜ (B, C) „Å´„Å™„Å£„Å¶„ÇãÔºà‰æã„Åà„Å∞ SwinTinyÔºâ\n",
    "            pass  # ‰Ωï„ÇÇÂä†Â∑•„Åó„Å™„ÅÑ\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected feature shape: {features.shape}\")\n",
    "\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self, mode=\"train\", kaggle_notebook=False, debug=False):\n",
    "        assert mode in [\"train\", \"inference\"], \"mode must be 'train' or 'inference'\"\n",
    "        self.mode = mode\n",
    "        self.KAGGLE_NOTEBOOK = kaggle_notebook\n",
    "        self.debug = debug\n",
    "\n",
    "        # ===== Path Settings =====\n",
    "        if self.KAGGLE_NOTEBOOK:\n",
    "            self.OUTPUT_DIR = ''\n",
    "            self.train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "            \n",
    "            self.test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "            self.submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "            self.taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "            self.model_path = '/kaggle/input/birdclef-2025-0330' \n",
    "            self.models_dir = \"\"\n",
    "            \n",
    "            # kaggle notebook„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„ÇãÔºé\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = None\n",
    "            self.spectrogram_npy = None\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = None\n",
    "            self.pseudo_melspec_npy = None\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.OUTPUT_DIR = '../data/result/'\n",
    "            self.RAW_DIR = '../data/raw/'\n",
    "            self.PROCESSED_DIR = '../data/processed/'\n",
    "            self.train_datadir = '../data/raw/train_audio/'\n",
    "            \n",
    "            self.test_soundscapes = '../data/raw/test_soundscapes/'\n",
    "            self.submission_csv = '../data/raw/sample_submission.csv'\n",
    "            self.taxonomy_csv = '../data/raw/taxonomy.csv'\n",
    "            self.models_dir = \"../models/\" # ÂÖ®model„ÅÆ‰øùÂ≠òÂÖà\n",
    "            self.model_path = self.models_dir # ÂêÑ„É¢„Éá„É´„ÅÆ‰øùÂ≠òÂÖàÔºéÂ≠¶ÁøíÊôÇ„Å´ÂãïÁöÑ„Å´Â§âÊõ¥Ôºé\n",
    "            \n",
    "            \n",
    "            # „É≠„Éº„Ç´„É´„Å™„Çâ„Åì„Åì„ÇíÂ§âÊõ¥„Åô„Çã\n",
    "            # „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®≠ÂÆö\n",
    "            self.train_csv = '../data/processed/mel_safezone1000_head_hoplength512//train.csv'\n",
    "            self.spectrogram_npy = '../data/processed/mel_safezone1000_head_hoplength512//birdclef2025_melspec_5sec_256_256.npy'\n",
    "            \n",
    "            # Pseudo Label„ÅÆË®≠ÂÆö\n",
    "            self.pseudo_label_csv = \"../data/processed/pseudo_labels/ensmbl_0850/pseudo_labels.csv\"\n",
    "            self.pseudo_melspec_npy = \"../data/processed/mel_prtl_trn_sndscps_hl512//mel_train_soundscapes.npy\"\n",
    "\n",
    "\n",
    "        # ===== Model Settings =====\n",
    "        self.model_name = \"efficientnet_b0\" # tf_efficientnetv2_b3   efficientnet_b0\n",
    "        self.pretrained = True if mode == \"train\" else False\n",
    "        self.in_channels = 1\n",
    "\n",
    "        # ===== Audio Settings =====\n",
    "        self.FS = 32000\n",
    "        self.TARGET_SHAPE = (256, 256)\n",
    "        \n",
    "        # trainerÂÜÖÈÉ®„ÅßÊ±∫„Åæ„Çã„ÅÆ„Åß„Åì„Åì„Åß„ÅØÊåáÂÆö„Åó„Å™„ÅÑÔºé\n",
    "        self.num_classes = None\n",
    "\n",
    "\n",
    "        # ===== Training Mode =====\n",
    "        if mode == \"train\":\n",
    "            self.seed = 42\n",
    "            self.apex = False\n",
    "            self.print_freq = 100\n",
    "            self.num_workers = 2\n",
    "\n",
    "            self.LOAD_DATA = True\n",
    "            self.epochs = 7\n",
    "            self.batch_size = 32\n",
    "            self.criterion = 'BCEWithLogitsLoss'\n",
    "\n",
    "            self.n_fold = 5\n",
    "            self.selected_folds = [0] # fold„ÅÆÈÅ∏Êäû\n",
    "\n",
    "            self.optimizer = 'AdamW'\n",
    "            self.lr = 5e-4\n",
    "            self.weight_decay = 1e-5\n",
    "            self.scheduler = 'CosineAnnealingLR'\n",
    "            self.min_lr = 1e-6\n",
    "            self.T_max = self.epochs\n",
    "            self.full_train = False\n",
    "            self.is_RareFull = False # „É¨„Ç¢Á®Æ„ÅØÂÖ®ÈÉ®train fold„Å´„Åô„Çã\n",
    "            self.aug_prob = 0.5 # spec augment„ÅÆÁ¢∫Áéá\n",
    "            \n",
    "            # real √ó real„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_mixup = True\n",
    "            self.mixup_alpha =  0.4\n",
    "            self.mixup_prob = 0.5\n",
    "            \n",
    "            self.secondary_labels = True # secondary_labels„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            \n",
    "            \n",
    "            \n",
    "            # real √ó pseudo„ÅÆmixup„ÅÆË®≠ÂÆö\n",
    "            self.use_pseudo_mixup = True # Pseudo mixup„Çí‰Ωø„ÅÜ„Åã„Å©„ÅÜ„Åã\n",
    "            self.pseudo_no_call_threshold = 0.06  # no call„ÅÆÈñæÂÄ§Ôºé‰Ωé„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.08„Åå‰∏äÈôê\n",
    "            self.pseudo_high_conf_threshold = 0.9 # Pseudo Label„ÅÆÈ´ò‰ø°È†ºÂ∫¶„ÅÆÈñæÂÄ§ÔºéÈ´ò„ÅÑ„Åª„ÅÜ„Åå„É©„Éô„É´„ÅåÊ≠£Á¢∫Ôºé0.7„Åå‰∏ãÈôêÔºé\n",
    "            self.pseudo_mixup_prob = 0.1 # Pseudo mixup „Çí‰Ωø„ÅÜÁ¢∫ÁéáÔºéreal √ó real mixup„Å®ÂêåÊôÇ„Å´‰Ωø„Çè„Çå„Çã„Åì„Å®„ÅØ„Å™„ÅÑÔºé\n",
    "            \n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            \n",
    "            if self.debug:\n",
    "                self.epochs = 2\n",
    "                self.selected_folds = [0]\n",
    "                self.batch_size = 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CFG(mode=\"train\", kaggle_notebook=False, debug=True)\n",
    "\n",
    "if cfg.KAGGLE_NOTEBOOK:\n",
    "    sys.path.append(\"/kaggle/input/birdclef-2025-libs/\")\n",
    "from module import  datasets_lib, models_lib, learning_lib, utils_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train„ÅÆÂá¶ÁêÜ„Çí„ÇØ„É©„Çπ„ÅßÂÆüË°åÔºé\n",
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, taxonomy_df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.taxonomy_df = taxonomy_df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.pseudo_df = None\n",
    "        self.pseudo_melspecs = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "        self.num_classes = None\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._build_index_label_mapping()\n",
    "        self._load_spectrograms()\n",
    "        \n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            self._load_pseudo_data()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            current_time = \"debug\"\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "        # dataset-metadata.json„Çí‰øùÂ≠ò\n",
    "        dataset_metadata = {\n",
    "            \"title\": f\"bc25-models-{current_time}\",\n",
    "            \"id\": f\"ihiratch/bc25-models-{current_time}\",\n",
    "            \"licenses\": [\n",
    "                {\n",
    "                    \"name\": \"CC0-1.0\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        metadata_path = os.path.join(self.cfg.model_path, \"dataset-metadata.json\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=2)\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _build_index_label_mapping(self):\n",
    "        species_ids = self.taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # label„Å®index„ÅÆÂØæÂøú\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "        print(self.index2label)\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(f\"Loading pre-computed mel spectrograms from NPY file, from the path: {self.cfg.spectrogram_npy}\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "        \n",
    "    def _load_pseudo_data(self):\n",
    "        print(\"üì• Loading pseudo label CSV and melspecs...\")\n",
    "\n",
    "        # 1. „É©„Éô„É´CSVË™≠„ÅøËæº„Åø\n",
    "        df = pd.read_csv(self.cfg.pseudo_label_csv)\n",
    "        species_cols = df.columns.drop(\"row_id\")\n",
    "        \n",
    "        # 2. soft label ÂâçÂá¶ÁêÜ: „Åó„Åç„ÅÑÂÄ§‰ª•‰∏ã„Çí„Çº„É≠„Å´\n",
    "        df[species_cols] = df[species_cols].where(df[species_cols] >= self.cfg.pseudo_no_call_threshold, 0.0)\n",
    "\n",
    "        # 3. no_call „Å® high_conf „Å´ÂàÜÈ°û\n",
    "        no_call_df = df[df[species_cols].max(axis=1) == 0.0].copy()\n",
    "        no_call_df[\"primary_label\"] = \"no_call\"\n",
    "        no_call_df[\"pseudo_source\"] = \"no_call\"\n",
    "        no_call_df[\"samplename\"] = no_call_df[\"row_id\"]\n",
    "\n",
    "        high_conf_df = df[df[species_cols].max(axis=1) >= self.cfg.pseudo_high_conf_threshold].copy()\n",
    "        high_conf_df[\"primary_label\"] = high_conf_df[species_cols].idxmax(axis=1)\n",
    "        high_conf_df[\"pseudo_source\"] = \"high_conf\"\n",
    "        high_conf_df[\"samplename\"] = high_conf_df[\"row_id\"]\n",
    "\n",
    "        # 4. Áµ±Âêà\n",
    "        self.pseudo_df = pd.concat([no_call_df, high_conf_df], axis=0).reset_index(drop=True)\n",
    "        print(f\"‚úÖ no_call: {len(no_call_df)}, high_conf: {len(high_conf_df)}, total: {len(self.pseudo_df)}\")\n",
    "\n",
    "        # 5. ÂøÖË¶Å„Å™ row_id „Å†„ÅëÊäΩÂá∫\n",
    "        used_ids = set(self.pseudo_df[\"row_id\"])\n",
    "\n",
    "        # 6. ËæûÊõ∏ÂΩ¢Âºè„ÅÆ .npy „ÇíË™≠„ÅøËæº„ÇÄ\n",
    "        full_mels = np.load(self.cfg.pseudo_melspec_npy, allow_pickle=True).item()\n",
    "        print(f\"üì¶ All pseudo mel specs loaded: {len(full_mels)}\")\n",
    "\n",
    "        # 7. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        self.pseudo_melspecs = {\n",
    "            row_id: full_mels[row_id]\n",
    "            for row_id in used_ids\n",
    "            if row_id in full_mels\n",
    "        }\n",
    "        \n",
    "        del full_mels  # „É°„É¢„É™ÁØÄÁ¥Ñ„ÅÆ„Åü„ÇÅ„Å´ÂâäÈô§\n",
    "        gc.collect()  # „Ç¨„Éº„Éô„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„ÇíÂÆüË°å\n",
    "\n",
    "        print(f\"‚úÖ Filtered mel specs loaded: {len(self.pseudo_melspecs)}\")\n",
    "        \n",
    "    def _create_train_dataset(self, train_df):\n",
    "        if self.cfg.use_pseudo_mixup:\n",
    "            \n",
    "            print(\"Using BirdCLEFDatasetWithPseudoMixup for training...\")\n",
    "            return BirdCLEFDatasetWithPseudoMixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                pseudo_df=self.pseudo_df,\n",
    "                pseudo_melspecs=self.pseudo_melspecs,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "        else:\n",
    "            print(\"Using BirdCLEFDatasetFromNPY_Mixup for training...\")\n",
    "            return BirdCLEFDatasetFromNPY_Mixup(\n",
    "                df=train_df,\n",
    "                cfg=self.cfg,\n",
    "                spectrograms=self.spectrograms,\n",
    "                mode=\"train\",\n",
    "                label2idx=self.label2index,\n",
    "                idx2label=self.index2label\n",
    "            )\n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # üëá ROC AUC „ÅØ„Éê„Ç§„Éä„É™„É©„Éô„É´„ÇíÂøÖË¶Å„Å®„Åô„Çã„ÅÆ„Åß„ÄÅsoft label„Çí2ÂÄ§Âåñ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        aucs = [roc_auc_score(targets_bin[:, i], probs[:, i]) \n",
    "                for i in range(targets.shape[1]) if np.sum(targets_bin[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „Éê„Ç§„Éä„É™ÂåñÔºàÈÄ£Á∂öÂÄ§„Åß„ÇÇint„Åß„ÇÇÂÆâÂÖ®Ôºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_auc[i] = roc_auc_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_auc[i] = np.nan  # „Ç®„É©„ÉºÂá∫„Åü„Å®„Åç„ÇÇÂÆâÂøÉ\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "\n",
    "        # „É©„Éô„É´„Çí„Éê„Ç§„Éä„É™ÂåñÔºàsoft labelÂØæÂøúÔºâ\n",
    "        targets_bin = (targets >= 0.5).astype(int)\n",
    "\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets_bin[:, i]) > 0:\n",
    "                try:\n",
    "                    classwise_ap[i] = average_precision_score(targets_bin[:, i], probs[:, i])\n",
    "                except ValueError:\n",
    "                    classwise_ap[i] = np.nan\n",
    "        return classwise_ap\n",
    "    \n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        values = [v for v in classwise_ap.values() if v is not None and not np.isnan(v)]\n",
    "        return np.mean(values) if values else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'train_loss': np.mean(losses),\n",
    "            'train_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"train_map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"train_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"train_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        # print(\"Size of validation:\",  len(all_targets))\n",
    "        self.val_metrics = {\n",
    "            'val_loss': np.mean(losses),\n",
    "            'val_auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"val_map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"val_classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"val_classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        for fold in range(self.cfg.n_fold):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            # train.csv„ÅÆfold„Çí‰Ωø„ÅÜÔºé\n",
    "            \n",
    "            if self.cfg.full_train:\n",
    "                train_df = self.df.reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True)\n",
    "                print(\"Use full train data for training.\")\n",
    "            else:\n",
    "                train_df = self.df[self.df['fold'] != fold].reset_index(drop=True)\n",
    "                val_df = self.df[self.df['fold'] == fold].reset_index(drop=True) \n",
    "            \n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self._create_train_dataset(train_df)\n",
    "            val_dataset = BirdCLEFDatasetFromNPY_Mixup(\n",
    "                        df=val_df,\n",
    "                        cfg=self.cfg,\n",
    "                        spectrograms=self.spectrograms,\n",
    "                        mode='valid',\n",
    "                        label2idx=self.label2index,\n",
    "                        idx2label=self.index2label\n",
    "                    )\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "            # coat„ÅåÊñáÂ≠óÂàó„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„Çå„Å∞\n",
    "            if 'coat' in self.cfg.model_name:\n",
    "                print(\"Using CoaT model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Coat(self.cfg).to(self.cfg.device)\n",
    "            \n",
    "            elif 'swin' in self.cfg.model_name:\n",
    "                print(\"Using Swin model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain_Swin(self.cfg).to(self.cfg.device)\n",
    "            else:\n",
    "                print(\"efficientNet model\")\n",
    "                print(cfg.model_name)\n",
    "                model = BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "                \n",
    "                \n",
    "                \n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                # „Çπ„Ç≥„Ç¢ÂèñÂæó\n",
    "                train_loss = self.train_metrics['train_loss']\n",
    "                train_auc = self.train_metrics['train_auc']\n",
    "                train_auc_map = self.train_metrics['train_map']\n",
    "\n",
    "                val_loss = self.val_metrics['val_loss']\n",
    "                val_auc = self.val_metrics['val_auc']\n",
    "                val_auc_map = self.val_metrics['val_map']\n",
    "                val_classwise_auc = self.val_metrics['val_classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['val_classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "\n",
    "                # classwise„Çπ„Ç≥„Ç¢„ÇíÈô§Â§ñ„Åó„Åü val_metrics „ÅÆ„É≠„Ç∞\n",
    "                train_log = {f\"{k}\": v for k, v in self.train_metrics.items() if not k.startswith(\"train_classwise\")}\n",
    "                val_log = {f\"{k}\": v for k, v in self.val_metrics.items() if not k.startswith(\"val_classwise\")}\n",
    "                \n",
    "                # „É≠„Ç∞Áî®„Çπ„Ç≥„Ç¢„ÅÆÊõ¥Êñ∞Ôºàclasswise„ÅØÈô§Â§ñÔºâ\n",
    "                log_entry.update(train_log)\n",
    "                log_entry.update(val_log)\n",
    "                log_history.append(log_entry)\n",
    "            \n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É¨„Ç¢Á®Æ„ÅØfold=-1„Å´„Åô„ÇãÔºé\n",
    "def overwrite_fold_for_rare_classes(df, rare_threshold=5):\n",
    "    # ÂêÑ„É©„Éô„É´„ÅÆÂá∫ÁèæÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "    label_counts = df.groupby('primary_label').size()\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„Çí„É™„Çπ„Éà„Ç¢„ÉÉ„Éó\n",
    "    rare_labels = label_counts[label_counts < rare_threshold].index.tolist()\n",
    "\n",
    "    print(f\"Rare labels ({len(rare_labels)} classes): {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "\n",
    "    # rare„Å™„É©„Éô„É´„ÅÆ„Éá„Éº„Çø„Å†„Åë fold = -1 „Å´‰∏äÊõ∏„Åç\n",
    "    df.loc[df['primary_label'].isin(rare_labels), 'fold'] = -1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_debug\n",
      "{0: '1139490', 1: '1192948', 2: '1194042', 3: '126247', 4: '1346504', 5: '134933', 6: '135045', 7: '1462711', 8: '1462737', 9: '1564122', 10: '21038', 11: '21116', 12: '21211', 13: '22333', 14: '22973', 15: '22976', 16: '24272', 17: '24292', 18: '24322', 19: '41663', 20: '41778', 21: '41970', 22: '42007', 23: '42087', 24: '42113', 25: '46010', 26: '47067', 27: '476537', 28: '476538', 29: '48124', 30: '50186', 31: '517119', 32: '523060', 33: '528041', 34: '52884', 35: '548639', 36: '555086', 37: '555142', 38: '566513', 39: '64862', 40: '65336', 41: '65344', 42: '65349', 43: '65373', 44: '65419', 45: '65448', 46: '65547', 47: '65962', 48: '66016', 49: '66531', 50: '66578', 51: '66893', 52: '67082', 53: '67252', 54: '714022', 55: '715170', 56: '787625', 57: '81930', 58: '868458', 59: '963335', 60: 'amakin1', 61: 'amekes', 62: 'ampkin1', 63: 'anhing', 64: 'babwar', 65: 'bafibi1', 66: 'banana', 67: 'baymac', 68: 'bbwduc', 69: 'bicwre1', 70: 'bkcdon', 71: 'bkmtou1', 72: 'blbgra1', 73: 'blbwre1', 74: 'blcant4', 75: 'blchaw1', 76: 'blcjay1', 77: 'blctit1', 78: 'blhpar1', 79: 'blkvul', 80: 'bobfly1', 81: 'bobher1', 82: 'brtpar1', 83: 'bubcur1', 84: 'bubwre1', 85: 'bucmot3', 86: 'bugtan', 87: 'butsal1', 88: 'cargra1', 89: 'cattyr', 90: 'chbant1', 91: 'chfmac1', 92: 'cinbec1', 93: 'cocher1', 94: 'cocwoo1', 95: 'colara1', 96: 'colcha1', 97: 'compau', 98: 'compot1', 99: 'cotfly1', 100: 'crbtan1', 101: 'crcwoo1', 102: 'crebob1', 103: 'cregua1', 104: 'creoro1', 105: 'eardov1', 106: 'fotfly', 107: 'gohman1', 108: 'grasal4', 109: 'grbhaw1', 110: 'greani1', 111: 'greegr', 112: 'greibi1', 113: 'grekis', 114: 'grepot1', 115: 'gretin1', 116: 'grnkin', 117: 'grysee1', 118: 'gybmar', 119: 'gycwor1', 120: 'labter1', 121: 'laufal1', 122: 'leagre', 123: 'linwoo1', 124: 'littin1', 125: 'mastit1', 126: 'neocor', 127: 'norscr1', 128: 'olipic1', 129: 'orcpar', 130: 'palhor2', 131: 'paltan1', 132: 'pavpig2', 133: 'piepuf1', 134: 'pirfly1', 135: 'piwtyr1', 136: 'plbwoo1', 137: 'plctan1', 138: 'plukit1', 139: 'purgal2', 140: 'ragmac1', 141: 'rebbla1', 142: 'recwoo1', 143: 'rinkin1', 144: 'roahaw', 145: 'rosspo1', 146: 'royfly1', 147: 'rtlhum', 148: 'rubsee1', 149: 'rufmot1', 150: 'rugdov', 151: 'rumfly1', 152: 'ruther1', 153: 'rutjac1', 154: 'rutpuf1', 155: 'saffin', 156: 'sahpar1', 157: 'savhaw1', 158: 'secfly1', 159: 'shghum1', 160: 'shtfly1', 161: 'smbani', 162: 'snoegr', 163: 'sobtyr1', 164: 'socfly1', 165: 'solsan', 166: 'soulap1', 167: 'spbwoo1', 168: 'speowl1', 169: 'spepar1', 170: 'srwswa1', 171: 'stbwoo2', 172: 'strcuc1', 173: 'strfly1', 174: 'strher', 175: 'strowl1', 176: 'tbsfin1', 177: 'thbeup1', 178: 'thlsch3', 179: 'trokin', 180: 'tropar', 181: 'trsowl', 182: 'turvul', 183: 'verfly', 184: 'watjac1', 185: 'wbwwre1', 186: 'whbant1', 187: 'whbman1', 188: 'whfant1', 189: 'whmtyr1', 190: 'whtdov', 191: 'whttro1', 192: 'whwswa1', 193: 'woosto', 194: 'y00678', 195: 'yebela1', 196: 'yebfly1', 197: 'yebsee1', 198: 'yecspi2', 199: 'yectyr1', 200: 'yehbla2', 201: 'yehcar1', 202: 'yelori1', 203: 'yeofly1', 204: 'yercac1', 205: 'ywcpar'}\n",
      "Loading pre-computed mel spectrograms from NPY file, from the path: ../data/processed/mel_safezone1000_head_hoplength512//birdclef2025_melspec_5sec_256_256.npy\n",
      "Loaded 28558 pre-computed mel spectrograms\n",
      "üì• Loading pseudo label CSV and melspecs...\n",
      "‚úÖ no_call: 1433, high_conf: 1345, total: 2778\n",
      "üì¶ All pseudo mel specs loaded: 10449\n",
      "‚úÖ Filtered mel specs loaded: 2778\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 80 samples\n",
      "Validation set: 20 samples\n",
      "Using BirdCLEFDatasetWithPseudoMixup for training...\n",
      "efficientNet model\n",
      "efficientnet_b0\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9709f99fca4a36b7d9460bd08c8f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dad8b750e184321a9750cfe3212db3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3018, Train AUC: 0.5219, Train MAP: 0.1021\n",
      "Val Loss: 0.0738, Val AUC: 0.3946, Val MAP: 0.1673\n",
      "New best AUC: 0.3946 at epoch 1\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7366f7c1634084b85bd041193a8fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f336773544e54f14a8c3d0db05574cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0287, Train AUC: 0.6166, Train MAP: 0.1398\n",
      "Val Loss: 0.0267, Val AUC: 0.4788, Val MAP: 0.2319\n",
      "New best AUC: 0.4788 at epoch 2\n",
      "\n",
      "Best AUC for fold 0: 0.4788\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.4788\n",
      "Mean AUC: 0.4788\n",
      "============================================================\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´„ÅØmodels_{current_time}„Å´‰øùÂ≠ò„Åï„Çå„ÇãÔºé\n",
    "if __name__ == \"__main__\":\n",
    "    utils_lib.set_seed(cfg.seed)\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    \n",
    "    if not cfg.secondary_labels:\n",
    "        print(\"secondary_labels is not used.\")\n",
    "        train_df[\"secondary_labels\"] = \"['']\"\n",
    "    \n",
    "    if cfg.is_RareFull: \n",
    "        print(\"Rare species are all in train fold.\")\n",
    "        train_df = overwrite_fold_for_rare_classes(train_df, rare_threshold=5)\n",
    "        \n",
    "    # taxonomy„ÅØ„É©„Éô„É´„Å®index„ÅÆÂØæÂøú„ÇíÂèñ„Çã„Åü„ÇÅ„Å´ÂøÖË¶ÅÔºé\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, taxonomy_df,  datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 best epoch: 7, val_auc: 0.959, train_auc: 0.981\n",
      "Missing log for fold 1: ../models/fold0_safezone1000_head_hoplength512//log_fold1.csv\n",
      "Missing log for fold 2: ../models/fold0_safezone1000_head_hoplength512//log_fold2.csv\n",
      "Missing log for fold 3: ../models/fold0_safezone1000_head_hoplength512//log_fold3.csv\n",
      "Missing log for fold 4: ../models/fold0_safezone1000_head_hoplength512//log_fold4.csv\n",
      "\n",
      "```markdown\n",
      "| Note | LB AUC | Avg Val Auc | Avg Train Auc | Avg Val Map | Avg Train Map | Avg Val Loss | Avg Train Loss | Avg Epoch | model_name | batch_size | epochs | optimizer | lr | weight_decay | scheduler | min_lr | tta |\n",
      "|------|--------|-------------|---------------|-------------|---------------|--------------|----------------|-----------|------------|------------|--------|-----------|----|--------------|-----------|--------|-----|\n",
      "|  |  | 0.959 | 0.981 | 0.584 | 0.618 | 0.013 | 0.012 | 7.00 | efficientnet_b0 | 32 | 7 | AdamW | 0.0005 | 1e-05 | CosineAnnealingLR | 1e-06 |  |\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_time_min</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_map</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>0.612382</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.024497</td>\n",
       "      <td>0.825007</td>\n",
       "      <td>0.118424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.848215</td>\n",
       "      <td>0.128472</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>0.922357</td>\n",
       "      <td>0.319098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.916488</td>\n",
       "      <td>0.253882</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.942861</td>\n",
       "      <td>0.427886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.359330</td>\n",
       "      <td>0.014260</td>\n",
       "      <td>0.950880</td>\n",
       "      <td>0.506781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.965777</td>\n",
       "      <td>0.482712</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>0.547844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.976944</td>\n",
       "      <td>0.559817</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.958612</td>\n",
       "      <td>0.574099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.981386</td>\n",
       "      <td>0.617922</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.959248</td>\n",
       "      <td>0.584348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch        lr  epoch_time_min  train_loss  train_auc  train_map  \\\n",
       "0      1  0.000475            1.73    0.036348   0.612382   0.013583   \n",
       "1      2  0.000406            1.72    0.022857   0.848215   0.128472   \n",
       "2      3  0.000306            1.72    0.018890   0.916488   0.253882   \n",
       "3      4  0.000195            1.55    0.016645   0.940541   0.359330   \n",
       "4      5  0.000095            1.87    0.014547   0.965777   0.482712   \n",
       "5      6  0.000026            1.71    0.013259   0.976944   0.559817   \n",
       "6      7  0.000001            1.71    0.012265   0.981386   0.617922   \n",
       "\n",
       "   val_loss   val_auc   val_map  \n",
       "0  0.024497  0.825007  0.118424  \n",
       "1  0.018399  0.922357  0.319098  \n",
       "2  0.015556  0.942861  0.427886  \n",
       "3  0.014260  0.950880  0.506781  \n",
       "4  0.013394  0.954717  0.547844  \n",
       "5  0.012712  0.958612  0.574099  \n",
       "6  0.012616  0.959248  0.584348  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "model_dir = \"../models/fold0_safezone1000_head_hoplength512//\"\n",
    "\n",
    "# „Çπ„Ç≥„Ç¢Ê†ºÁ¥çËæûÊõ∏Ôºàfold„Åî„Å®„ÅÆË®òÈå≤Ôºâ\n",
    "score_lists = {\n",
    "    'val_auc': [],\n",
    "    'train_auc': [],\n",
    "    'val_map': [],\n",
    "    'train_map': [],\n",
    "    'val_loss': [],\n",
    "    'train_loss': [],\n",
    "    'epoch': [],\n",
    "}\n",
    "\n",
    "# ÂêÑfold„ÅÆ„Éô„Çπ„Éà„Çπ„Ç≥„Ç¢ÂèéÈõÜ\n",
    "for fold in range(5):\n",
    "    log_path = os.path.join(model_dir, f\"log_fold{fold}.csv\")\n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"Missing log for fold {fold}: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(log_path)\n",
    "    best_row = df.loc[df['val_auc'].idxmax()]\n",
    "\n",
    "    print(f\"Fold {fold} best epoch: {int(best_row['epoch'])}, val_auc: {best_row['val_auc']:.3f}, train_auc: {best_row['train_auc']:.3f}\")\n",
    "\n",
    "    for key in score_lists:\n",
    "        score_lists[key].append(best_row[key])\n",
    "\n",
    "# Âπ≥Âùá„Çπ„Ç≥„Ç¢„ÇíÊï¥ÂΩ¢Ôºà.3f„ÅßË°®Á§∫„ÄÅepoch„Å†„Åë.2fÔºâ\n",
    "score_means = {}\n",
    "for key, values in score_lists.items():\n",
    "    avg = sum(values) / len(values)\n",
    "    display_key = f\"Avg {key.replace('_', ' ').title()}\"\n",
    "    if \"epoch\" in key:\n",
    "        score_means[display_key] = f\"{avg:.2f}\"\n",
    "    else:\n",
    "        score_means[display_key] = f\"{avg:.3f}\"\n",
    "\n",
    "# config.csv Ë™≠„ÅøËæº„Åø\n",
    "config_path = os.path.join(model_dir, \"config.csv\")\n",
    "config_df = pd.read_csv(config_path)\n",
    "\n",
    "important_keys = [\n",
    "    'model_name','batch_size', 'epochs',\n",
    "    'optimizer', 'lr', 'weight_decay', 'scheduler', 'min_lr', \"tta\",\n",
    "]\n",
    "\n",
    "# configÊÉÖÂ†±„ÅÆÁµ±Âêà\n",
    "config_dict = {\"Note\": \"\", \"LB AUC\": \"\", **score_means }\n",
    "for key in important_keys:\n",
    "    value = config_df.loc[config_df['key'] == key, 'value'].values\n",
    "    config_dict[key] = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "# MarkdownÂá∫Âäõ\n",
    "all_keys = list(config_dict.keys())\n",
    "print(\"\\n```markdown\")\n",
    "print(\"| \" + \" | \".join(all_keys) + \" |\")\n",
    "print(\"|\" + \"|\".join([\"-\" * (len(k)+2) for k in all_keys]) + \"|\")\n",
    "print(\"| \" + \" | \".join(str(config_dict[k]) for k in all_keys) + \" |\")\n",
    "print(\"```\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_dir_name = \"../models/fld0_sfzn1_hd_hl512_OnlyNocall//\"\n",
    "i = 0\n",
    "model_dir = os.path.join(cfg.models_dir, model_dir_name)\n",
    "log_path = os.path.join(model_dir, f\"log_fold{i}.csv\")\n",
    "\n",
    "# loss„Çí„Éó„É≠„ÉÉ„Éà\n",
    "df = pd.read_csv(log_path)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\n",
      "ÊúÄÂ§ßË™§Â∑Æ: 0.0\n",
      "Âπ≥ÂùáË™§Â∑Æ: 0.0\n",
      "Ê®ôÊ∫ñÂÅèÂ∑Æ: 0.0\n"
     ]
    }
   ],
   "source": [
    "# „É¢„Éá„É´Âá∫Âäõ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "\n",
    "# „É¢„Éá„É´„Éë„Çπ\n",
    "# ÊØîËºÉÂÖÉ\n",
    "model_1_path = \"../models/sfzn1_hd_hl512//model_fold0.pth\"\n",
    "model_2_path = \"../models/fold0_safezone1000_head_hoplength512/model_fold0.pth\"\n",
    "\n",
    "# ÂÖ±ÈÄöË®≠ÂÆöÔºà„Åì„ÅÆcfg_inf„ÅØÂøÖÈ†àÔºâ\n",
    "cfg_inf = CFG(mode=\"inference\", kaggle_notebook=False)\n",
    "num_classes = train_df['primary_label'].nunique()\n",
    "\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„ÅøÈñ¢Êï∞\n",
    "def load_model(path):\n",
    "    model = models_lib.BirdCLEFModelForInference(cfg_inf, num_classes)\n",
    "    checkpoint = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
    "model_1 = load_model(model_1_path)\n",
    "model_2 = load_model(model_2_path)\n",
    "\n",
    "# Âêå„Åò„ÉÄ„Éü„ÉºÂÖ•Âäõ\n",
    "dummy_input = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "# Êé®Ë´ñÔºàÂá∫Âäõ„Å´ sigmoid „ÅåÂøÖË¶Å„Å™Â†¥Âêà„ÅØ model „Å´Âê´„Åæ„Çå„Å¶„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶ÈÅ©ÂÆúËøΩÂä†Ôºâ\n",
    "with torch.no_grad():\n",
    "    out_0413 = model_1(dummy_input).numpy()\n",
    "    out_0420 = model_2(dummy_input).numpy()\n",
    "\n",
    "# Â∑ÆÂàÜË®àÁÆó\n",
    "abs_diff = np.abs(out_0413 - out_0420)\n",
    "print(\"üîç PyTorch „É¢„Éá„É´Âá∫ÂäõÊØîËºÉ:\")\n",
    "print(f\"ÊúÄÂ§ßË™§Â∑Æ: {np.max(abs_diff)}\")\n",
    "print(f\"Âπ≥ÂùáË™§Â∑Æ: {np.mean(abs_diff)}\")\n",
    "print(f\"Ê®ôÊ∫ñÂÅèÂ∑Æ: {np.std(abs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„Éù„ÉÉ„ÇØ1„Åß„Éá„Éê„ÉÉ„Ç∞„Åß„Åç„Çã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m log_2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/models_20250422_1826/log_fold0.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m log_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(log_1_path)\n\u001b[0;32m----> 5\u001b[0m log_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_2_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/models_20250422_1826/log_fold0.csv'"
     ]
    }
   ],
   "source": [
    "log_1_path = \"../models/epch1_cleaned_0413/log_fold0.csv\"\n",
    "log_2_path = \"../models/models_20250422_1826/log_fold0.csv\"\n",
    "\n",
    "log_1 = pd.read_csv(log_1_path)\n",
    "log_2 = pd.read_csv(log_2_path)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_loss_1\"] = log_1[\"train_loss\"]\n",
    "df[\"train_loss_2\"] = log_2[\"train_loss\"]\n",
    "\n",
    "df[\"val_loss_1\"] = log_1[\"val_loss\"]\n",
    "df[\"val_loss_2\"] = log_2[\"val_loss\"]\n",
    "\n",
    "df[\"val_auc_1\"] = log_1[\"val_auc\"]\n",
    "df[\"val_auc_2\"] = log_2[\"val_auc\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
