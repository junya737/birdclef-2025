{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'module.config_lib' from '/root/program/birdclef-2025/scripts/module/config_lib.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import librosa\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import timm\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from module import preprocess_lib, datasets_lib, utils_lib, models_lib, learning_lib, config_lib\n",
    "reload(config_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config_lib.CFG(mode=\"train\", kaggle_notebook=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_lib.set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFTrainer:\n",
    "    def __init__(self, cfg, df, datasets_lib, models_lib, learning_lib):\n",
    "        self.cfg = cfg\n",
    "        self.df = df.head(100).reset_index(drop=True) if cfg.debug else df\n",
    "        self.datasets_lib = datasets_lib\n",
    "        self.models_lib = models_lib\n",
    "        self.learning_lib = learning_lib\n",
    "        self.spectrograms = None\n",
    "        self.best_scores = []\n",
    "        self.train_metrics = {}\n",
    "        self.val_metrics = {}\n",
    "        self.label2index = {}\n",
    "        self.index2label = {}\n",
    "\n",
    "        self._setup_model_dir()\n",
    "        self._save_config()\n",
    "        self._load_taxonomy()\n",
    "        self._load_spectrograms()\n",
    "\n",
    "    def _setup_model_dir(self):\n",
    "        if self.cfg.debug:\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, \"models_debug\")\n",
    "        else:\n",
    "            japan_time = datetime.now(timezone(timedelta(hours=9)))\n",
    "            current_time = japan_time.strftime('%Y%m%d_%H%M')\n",
    "            self.cfg.model_path = os.path.join(self.cfg.models_dir, f\"models_{current_time}\")\n",
    "        os.makedirs(self.cfg.model_path, exist_ok=True)\n",
    "        print(f\"[INFO] Models will be saved to: {self.cfg.model_path}\")\n",
    "\n",
    "    def _save_config(self):\n",
    "        cfg_dict = vars(self.cfg)\n",
    "        cfg_df = pd.DataFrame(list(cfg_dict.items()), columns=[\"key\", \"value\"])\n",
    "        cfg_df.to_csv(os.path.join(self.cfg.model_path, \"config.csv\"), index=False)\n",
    "\n",
    "    def _load_taxonomy(self):\n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.cfg.num_classes = len(species_ids)\n",
    "        # labelとindexの対応\n",
    "        self.index2label = {i: label for i, label in enumerate(species_ids)}\n",
    "        self.label2index = {label: i for i, label in enumerate(species_ids)}\n",
    "\n",
    "    def _load_spectrograms(self):\n",
    "        print(\"Loading pre-computed mel spectrograms from NPY file...\")\n",
    "        self.spectrograms = np.load(self.cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(self.spectrograms)} pre-computed mel spectrograms\")\n",
    "\n",
    "    def _calculate_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "        aucs = [roc_auc_score(targets[:, i], probs[:, i]) for i in range(targets.shape[1]) if np.sum(targets[:, i]) > 0]\n",
    "        return np.mean(aucs) if aucs else 0.0\n",
    "\n",
    "    def _calculate_classwise_auc(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "        classwise_auc = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets[:, i]) > 0:\n",
    "                classwise_auc[i] = roc_auc_score(targets[:, i], probs[:, i])\n",
    "        return classwise_auc\n",
    "\n",
    "    def _calculate_classwise_ap(self, targets, outputs):\n",
    "        probs = 1 / (1 + np.exp(-outputs))\n",
    "        classwise_ap = {}\n",
    "        for i in range(targets.shape[1]):\n",
    "            if np.sum(targets[:, i]) > 0:\n",
    "                classwise_ap[i] = average_precision_score(targets[:, i], probs[:, i])\n",
    "        return classwise_ap\n",
    "\n",
    "    def _calculate_map(self, targets, outputs):\n",
    "        classwise_ap = self._calculate_classwise_ap(targets, outputs)\n",
    "        return np.mean(list(classwise_ap.values())) if classwise_ap else 0.0\n",
    "\n",
    "    def _save_classwise_scores_to_csv(self, classwise_auc, classwise_ap, fold, filename_prefix):\n",
    "        rows = []\n",
    "        for i in classwise_auc:\n",
    "            label = self.index2label.get(i, str(i))\n",
    "            auc = classwise_auc[i]\n",
    "            ap = classwise_ap.get(i, np.nan)\n",
    "            rows.append({\"label\": label, \"val_auc\": auc, \"val_ap\": ap})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(os.path.join(self.cfg.model_path, f\"{filename_prefix}_classwise_score_fold{fold}.csv\"), index=False)\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, model, loader, optimizer, criterion, device, scheduler=None):\n",
    "        model.train()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            if isinstance(batch['melspec'], list):\n",
    "                batch_outputs, batch_losses = [], []\n",
    "                for i in range(len(batch['melspec'])):\n",
    "                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                    target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    batch_outputs.append(output.detach().cpu())\n",
    "                    batch_losses.append(loss.item())\n",
    "                optimizer.step()\n",
    "                outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                loss = np.mean(batch_losses)\n",
    "                targets = batch['target'].numpy()\n",
    "            else:\n",
    "                inputs = batch['melspec'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = outputs[1] if isinstance(outputs, tuple) else criterion(outputs, targets)\n",
    "                outputs = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "\n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(targets)\n",
    "            losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'train_loss': np.mean(losses[-10:]) if losses else 0,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.train_metrics = {\n",
    "            'loss': np.mean(losses),\n",
    "            'auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"map\": self._calculate_map(all_targets, all_outputs),   \n",
    "            \"classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),  \n",
    "        }\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        model.eval()\n",
    "        losses, all_targets, all_outputs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=\"Validation\"):\n",
    "                if isinstance(batch['melspec'], list):\n",
    "                    batch_outputs, batch_losses = [], []\n",
    "                    for i in range(len(batch['melspec'])):\n",
    "                        inputs = batch['melspec'][i].unsqueeze(0).to(device)\n",
    "                        target = batch['target'][i].unsqueeze(0).to(device)\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, target)\n",
    "                        batch_outputs.append(output.detach().cpu())\n",
    "                        batch_losses.append(loss.item())\n",
    "                    outputs = torch.cat(batch_outputs, dim=0).numpy()\n",
    "                    loss = np.mean(batch_losses)\n",
    "                    targets = batch['target'].numpy()\n",
    "                else:\n",
    "                    inputs = batch['melspec'].to(device)\n",
    "                    targets = batch['target'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "                losses.append(loss.item() if not isinstance(loss, float) else loss)\n",
    "\n",
    "        all_outputs = np.concatenate(all_outputs)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        self.val_metrics = {\n",
    "            'loss': np.mean(losses),\n",
    "            'auc': self._calculate_auc(all_targets, all_outputs),\n",
    "            \"map\": self._calculate_map(all_targets, all_outputs),\n",
    "            \"classwise_auc\": self._calculate_classwise_auc(all_targets, all_outputs),\n",
    "            \"classwise_ap\": self._calculate_classwise_ap(all_targets, all_outputs),\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        skf = StratifiedKFold(n_splits=self.cfg.n_fold, shuffle=True, random_state=self.cfg.seed)\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(self.df, self.df['primary_label'])):\n",
    "            if fold not in self.cfg.selected_folds:\n",
    "                continue\n",
    "            print(f\"\\n{'='*30} Fold {fold} {'='*30}\")\n",
    "\n",
    "            train_df = self.df.iloc[train_idx].reset_index(drop=True)\n",
    "            val_df = self.df.iloc[val_idx].reset_index(drop=True)\n",
    "            print(f\"Training set: {len(train_df)} samples\")\n",
    "            print(f\"Validation set: {len(val_df)} samples\")\n",
    "\n",
    "            train_dataset = self.datasets_lib.BirdCLEFDatasetFromNPY(train_df, self.cfg, self.spectrograms, mode='train')\n",
    "            val_dataset = self.datasets_lib.BirdCLEFDatasetFromNPY(val_df, self.cfg, self.spectrograms, mode='valid')\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.cfg.batch_size, shuffle=True, \n",
    "                                       num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                       collate_fn=self.datasets_lib.collate_fn, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                     num_workers=self.cfg.num_workers, pin_memory=True,\n",
    "                                     collate_fn=self.datasets_lib.collate_fn)\n",
    "\n",
    "            model = self.models_lib.BirdCLEFModelForTrain(self.cfg).to(self.cfg.device)\n",
    "            optimizer = self.learning_lib.get_optimizer(model, self.cfg)\n",
    "            criterion = self.learning_lib.get_criterion(self.cfg)\n",
    "\n",
    "            scheduler = (lr_scheduler.OneCycleLR(optimizer, max_lr=self.cfg.lr, \n",
    "                        steps_per_epoch=len(train_loader), epochs=self.cfg.epochs, pct_start=0.1)\n",
    "                         if self.cfg.scheduler == 'OneCycleLR'\n",
    "                         else self.learning_lib.get_scheduler(optimizer, self.cfg))\n",
    "\n",
    "            best_auc = 0\n",
    "            log_history = []\n",
    "\n",
    "            for epoch in range(self.cfg.epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{self.cfg.epochs}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                self.train_one_epoch(model, train_loader, optimizer, criterion, self.cfg.device, scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None)\n",
    "                self.validate(model, val_loader, criterion, self.cfg.device)\n",
    "\n",
    "                train_loss = self.train_metrics['loss']\n",
    "                train_auc = self.train_metrics['auc']\n",
    "                train_auc_map = self.train_metrics['map']\n",
    "\n",
    "                val_loss = self.val_metrics['loss']\n",
    "                val_auc = self.val_metrics['auc']\n",
    "                val_auc_map = self.val_metrics['map']\n",
    "                val_classwise_auc = self.val_metrics['classwise_auc']\n",
    "                val_classwise_ap = self.val_metrics['classwise_ap']\n",
    "\n",
    "                if scheduler and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                    scheduler.step(val_loss if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau) else None)\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}, Train MAP: {train_auc_map:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val MAP: {val_auc_map:.4f}\")\n",
    "\n",
    "                if val_auc > best_auc:\n",
    "                    best_auc = val_auc\n",
    "                    print(f\"New best AUC: {best_auc:.4f} at epoch {epoch+1}\")\n",
    "                    \n",
    "                    self._save_classwise_scores_to_csv(val_classwise_auc, val_classwise_ap, fold, filename_prefix=\"best_val\")\n",
    "\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                        'epoch': epoch,\n",
    "                        'val_auc': val_auc,\n",
    "                        'train_auc': train_auc,\n",
    "                        \"index2label\": self.index2label,\n",
    "                        'cfg': self.cfg\n",
    "                    }, f\"{self.cfg.model_path}/model_fold{fold}.pth\")\n",
    "\n",
    "                log_entry = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'lr': scheduler.get_last_lr()[0] if scheduler else self.cfg.lr,\n",
    "                    'epoch_time_min': round((time.time() - start_time) / 60, 2)\n",
    "                }\n",
    "                log_entry.update(self.train_metrics)\n",
    "                log_entry.update({f\"val_{k}\": v for k, v in self.val_metrics.items()})\n",
    "                log_history.append(log_entry)\n",
    "\n",
    "            pd.DataFrame(log_history).to_csv(f\"{self.cfg.model_path}/log_fold{fold}.csv\", index=False)\n",
    "            self.best_scores.append(best_auc)\n",
    "            print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f}\")\n",
    "\n",
    "            del model, optimizer, scheduler, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Cross-Validation Results:\")\n",
    "        for fold, score in enumerate(self.best_scores):\n",
    "            print(f\"Fold {self.cfg.selected_folds[fold]}: {score:.4f}\")\n",
    "        print(f\"Mean AUC: {np.mean(self.best_scores):.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "[INFO] Models will be saved to: ../models/models_debug\n",
      "Loading pre-computed mel spectrograms from NPY file...\n",
      "Loaded 28564 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 80 samples\n",
      "Validation set: 20 samples\n",
      "Found 80 matching spectrograms for train dataset out of 80 samples\n",
      "Found 20 matching spectrograms for valid dataset out of 20 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325596c7dcc9448988cbe2910f8e7ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904993a0aaa146309cc97cff3538635b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3106, Train AUC: 0.4732, Train MAP: 0.1063\n",
      "Val Loss: 0.0350, Val AUC: 0.4761, Val MAP: 0.1406\n",
      "New best AUC: 0.4761 at epoch 1\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ca4b1ec7794a09800f0d7a40880e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a10d873028479d891e269288b7cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339, Train AUC: 0.5403, Train MAP: 0.1363\n",
      "Val Loss: 0.0705, Val AUC: 0.5068, Val MAP: 0.2316\n",
      "New best AUC: 0.5068 at epoch 2\n",
      "\n",
      "Best AUC for fold 0: 0.5068\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results:\n",
      "Fold 0: 0.5068\n",
      "Mean AUC: 0.5068\n",
      "============================================================\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)  # これはtrainer内部でまた読み込むので optional\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer = BirdCLEFTrainer(cfg, train_df, datasets_lib, models_lib, learning_lib)\n",
    "    trainer.run()\n",
    "    print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1139490',\n",
       " 1: '1192948',\n",
       " 2: '1194042',\n",
       " 3: '126247',\n",
       " 4: '1346504',\n",
       " 5: '134933',\n",
       " 6: '135045',\n",
       " 7: '1462711',\n",
       " 8: '1462737',\n",
       " 9: '1564122',\n",
       " 10: '21038',\n",
       " 11: '21116',\n",
       " 12: '21211',\n",
       " 13: '22333',\n",
       " 14: '22973',\n",
       " 15: '22976',\n",
       " 16: '24272',\n",
       " 17: '24292',\n",
       " 18: '24322',\n",
       " 19: '41663',\n",
       " 20: '41778',\n",
       " 21: '41970',\n",
       " 22: '42007',\n",
       " 23: '42087',\n",
       " 24: '42113',\n",
       " 25: '46010',\n",
       " 26: '47067',\n",
       " 27: '476537',\n",
       " 28: '476538',\n",
       " 29: '48124',\n",
       " 30: '50186',\n",
       " 31: '517119',\n",
       " 32: '523060',\n",
       " 33: '528041',\n",
       " 34: '52884',\n",
       " 35: '548639',\n",
       " 36: '555086',\n",
       " 37: '555142',\n",
       " 38: '566513',\n",
       " 39: '64862',\n",
       " 40: '65336',\n",
       " 41: '65344',\n",
       " 42: '65349',\n",
       " 43: '65373',\n",
       " 44: '65419',\n",
       " 45: '65448',\n",
       " 46: '65547',\n",
       " 47: '65962',\n",
       " 48: '66016',\n",
       " 49: '66531',\n",
       " 50: '66578',\n",
       " 51: '66893',\n",
       " 52: '67082',\n",
       " 53: '67252',\n",
       " 54: '714022',\n",
       " 55: '715170',\n",
       " 56: '787625',\n",
       " 57: '81930',\n",
       " 58: '868458',\n",
       " 59: '963335',\n",
       " 60: 'amakin1',\n",
       " 61: 'amekes',\n",
       " 62: 'ampkin1',\n",
       " 63: 'anhing',\n",
       " 64: 'babwar',\n",
       " 65: 'bafibi1',\n",
       " 66: 'banana',\n",
       " 67: 'baymac',\n",
       " 68: 'bbwduc',\n",
       " 69: 'bicwre1',\n",
       " 70: 'bkcdon',\n",
       " 71: 'bkmtou1',\n",
       " 72: 'blbgra1',\n",
       " 73: 'blbwre1',\n",
       " 74: 'blcant4',\n",
       " 75: 'blchaw1',\n",
       " 76: 'blcjay1',\n",
       " 77: 'blctit1',\n",
       " 78: 'blhpar1',\n",
       " 79: 'blkvul',\n",
       " 80: 'bobfly1',\n",
       " 81: 'bobher1',\n",
       " 82: 'brtpar1',\n",
       " 83: 'bubcur1',\n",
       " 84: 'bubwre1',\n",
       " 85: 'bucmot3',\n",
       " 86: 'bugtan',\n",
       " 87: 'butsal1',\n",
       " 88: 'cargra1',\n",
       " 89: 'cattyr',\n",
       " 90: 'chbant1',\n",
       " 91: 'chfmac1',\n",
       " 92: 'cinbec1',\n",
       " 93: 'cocher1',\n",
       " 94: 'cocwoo1',\n",
       " 95: 'colara1',\n",
       " 96: 'colcha1',\n",
       " 97: 'compau',\n",
       " 98: 'compot1',\n",
       " 99: 'cotfly1',\n",
       " 100: 'crbtan1',\n",
       " 101: 'crcwoo1',\n",
       " 102: 'crebob1',\n",
       " 103: 'cregua1',\n",
       " 104: 'creoro1',\n",
       " 105: 'eardov1',\n",
       " 106: 'fotfly',\n",
       " 107: 'gohman1',\n",
       " 108: 'grasal4',\n",
       " 109: 'grbhaw1',\n",
       " 110: 'greani1',\n",
       " 111: 'greegr',\n",
       " 112: 'greibi1',\n",
       " 113: 'grekis',\n",
       " 114: 'grepot1',\n",
       " 115: 'gretin1',\n",
       " 116: 'grnkin',\n",
       " 117: 'grysee1',\n",
       " 118: 'gybmar',\n",
       " 119: 'gycwor1',\n",
       " 120: 'labter1',\n",
       " 121: 'laufal1',\n",
       " 122: 'leagre',\n",
       " 123: 'linwoo1',\n",
       " 124: 'littin1',\n",
       " 125: 'mastit1',\n",
       " 126: 'neocor',\n",
       " 127: 'norscr1',\n",
       " 128: 'olipic1',\n",
       " 129: 'orcpar',\n",
       " 130: 'palhor2',\n",
       " 131: 'paltan1',\n",
       " 132: 'pavpig2',\n",
       " 133: 'piepuf1',\n",
       " 134: 'pirfly1',\n",
       " 135: 'piwtyr1',\n",
       " 136: 'plbwoo1',\n",
       " 137: 'plctan1',\n",
       " 138: 'plukit1',\n",
       " 139: 'purgal2',\n",
       " 140: 'ragmac1',\n",
       " 141: 'rebbla1',\n",
       " 142: 'recwoo1',\n",
       " 143: 'rinkin1',\n",
       " 144: 'roahaw',\n",
       " 145: 'rosspo1',\n",
       " 146: 'royfly1',\n",
       " 147: 'rtlhum',\n",
       " 148: 'rubsee1',\n",
       " 149: 'rufmot1',\n",
       " 150: 'rugdov',\n",
       " 151: 'rumfly1',\n",
       " 152: 'ruther1',\n",
       " 153: 'rutjac1',\n",
       " 154: 'rutpuf1',\n",
       " 155: 'saffin',\n",
       " 156: 'sahpar1',\n",
       " 157: 'savhaw1',\n",
       " 158: 'secfly1',\n",
       " 159: 'shghum1',\n",
       " 160: 'shtfly1',\n",
       " 161: 'smbani',\n",
       " 162: 'snoegr',\n",
       " 163: 'sobtyr1',\n",
       " 164: 'socfly1',\n",
       " 165: 'solsan',\n",
       " 166: 'soulap1',\n",
       " 167: 'spbwoo1',\n",
       " 168: 'speowl1',\n",
       " 169: 'spepar1',\n",
       " 170: 'srwswa1',\n",
       " 171: 'stbwoo2',\n",
       " 172: 'strcuc1',\n",
       " 173: 'strfly1',\n",
       " 174: 'strher',\n",
       " 175: 'strowl1',\n",
       " 176: 'tbsfin1',\n",
       " 177: 'thbeup1',\n",
       " 178: 'thlsch3',\n",
       " 179: 'trokin',\n",
       " 180: 'tropar',\n",
       " 181: 'trsowl',\n",
       " 182: 'turvul',\n",
       " 183: 'verfly',\n",
       " 184: 'watjac1',\n",
       " 185: 'wbwwre1',\n",
       " 186: 'whbant1',\n",
       " 187: 'whbman1',\n",
       " 188: 'whfant1',\n",
       " 189: 'whmtyr1',\n",
       " 190: 'whtdov',\n",
       " 191: 'whttro1',\n",
       " 192: 'whwswa1',\n",
       " 193: 'woosto',\n",
       " 194: 'y00678',\n",
       " 195: 'yebela1',\n",
       " 196: 'yebfly1',\n",
       " 197: 'yebsee1',\n",
       " 198: 'yecspi2',\n",
       " 199: 'yectyr1',\n",
       " 200: 'yehbla2',\n",
       " 201: 'yehcar1',\n",
       " 202: 'yelori1',\n",
       " 203: 'yeofly1',\n",
       " 204: 'yercac1',\n",
       " 205: 'ywcpar'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.index2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
